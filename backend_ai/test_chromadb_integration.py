#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ChromaDB + PageRank Integration Test

Before/After Comparison:
- Before: PyTorch O(n) linear search
- After: ChromaDB O(log n) HNSW + PageRank re-ranking
"""

import os
import sys
import time
import json

# Fix Windows console encoding
if sys.platform == "win32":
    import codecs
    sys.stdout = codecs.getwriter("utf-8")(sys.stdout.detach())

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from app.saju_astro_rag import GraphRAG

def test_query(use_chromadb: bool = False):
    """GraphRAG ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸."""
    print("=" * 70)
    print(f"í…ŒìŠ¤íŠ¸ ëª¨ë“œ: {'ChromaDB + PageRank' if use_chromadb else 'Legacy PyTorch'}")
    print("=" * 70)

    # í™˜ê²½ë³€ìˆ˜ ì„¤ì •
    os.environ["USE_CHROMADB"] = "1" if use_chromadb else "0"

    # GraphRAG ì´ˆê¸°í™”
    print("\n[1/3] GraphRAG ì´ˆê¸°í™” ì¤‘...")
    start = time.time()
    graph_rag = GraphRAG()
    init_time = time.time() - start
    print(f"âœ“ ì´ˆê¸°í™” ì™„ë£Œ ({init_time:.2f}s)")
    print(f"  - ë…¸ë“œ: {len(graph_rag.node_ids)}")
    print(f"  - ê·¸ë˜í”„ ì—£ì§€: {graph_rag.graph.number_of_edges()}")

    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    test_queries = [
        {"query": "ê°‘ëª© ì¼ê°„ ì„±ê²©", "type": "saju"},
        {"query": "ì„ìˆ˜ì™€ ê°‘ëª© ê¶í•©", "type": "compatibility"},
        {"query": "ë³‘í™”ê°€ ê°•í•œ ì‚¬ëŒ", "type": "saju"},
    ]

    print(f"\n[2/3] ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸ ({len(test_queries)}ê°œ)")
    print("-" * 70)

    results = []
    for i, query_data in enumerate(test_queries, 1):
        question = query_data["query"]
        print(f"\nì§ˆë¬¸ {i}: {question}")

        start = time.time()
        result = graph_rag.query(
            {"query": question, "type": query_data["type"]},
            top_k=8,
            domain_priority="saju"
        )
        elapsed_ms = (time.time() - start) * 1000

        matched_count = len(result.get("matched_nodes", []))
        backend = result.get("stats", {}).get("backend", "legacy")

        print(f"  âœ“ {matched_count} contexts, {elapsed_ms:.0f}ms, backend={backend}")

        # ìƒìœ„ 3ê°œ ê²°ê³¼ ì¶œë ¥
        for j, node in enumerate(result.get("matched_nodes", [])[:3], 1):
            preview = node[:80] + "..." if len(node) > 80 else node
            print(f"    [{j}] {preview}")

        results.append({
            "question": question,
            "latency_ms": elapsed_ms,
            "contexts_count": matched_count,
            "backend": backend,
        })

    # í†µê³„
    print(f"\n[3/3] ì„±ëŠ¥ í†µê³„")
    print("-" * 70)
    avg_latency = sum(r["latency_ms"] for r in results) / len(results)
    avg_contexts = sum(r["contexts_count"] for r in results) / len(results)

    print(f"  í‰ê·  ë ˆì´í„´ì‹œ  : {avg_latency:.0f}ms")
    print(f"  í‰ê·  contexts  : {avg_contexts:.1f}ê°œ")
    print(f"  ë°±ì—”ë“œ         : {results[0]['backend']}")

    return {
        "mode": "chromadb" if use_chromadb else "legacy",
        "avg_latency_ms": avg_latency,
        "avg_contexts": avg_contexts,
        "results": results,
    }


def run_comparison():
    """Before/After ë¹„êµ ì‹¤í–‰."""
    print("\n" + "=" * 70)
    print(" ChromaDB + PageRank í†µí•© í…ŒìŠ¤íŠ¸ - Before/After ë¹„êµ")
    print("=" * 70)

    # Before (Legacy)
    print("\n\n[BEFORE] Legacy PyTorch O(n) ê²€ìƒ‰")
    before = test_query(use_chromadb=False)

    # After (ChromaDB + PageRank)
    print("\n\n[AFTER] ChromaDB O(log n) + PageRank")
    after = test_query(use_chromadb=True)

    # ë¹„êµ ë¦¬í¬íŠ¸
    print("\n\n" + "=" * 70)
    print(" ğŸ“Š ìµœì¢… ë¹„êµ ë¦¬í¬íŠ¸")
    print("=" * 70)

    latency_improvement = ((before["avg_latency_ms"] - after["avg_latency_ms"])
                          / before["avg_latency_ms"] * 100)

    print(f"\nâš¡ ì„±ëŠ¥ ê°œì„ :")
    print(f"  Before: {before['avg_latency_ms']:.0f}ms")
    print(f"  After : {after['avg_latency_ms']:.0f}ms")
    print(f"  ê°œì„ ìœ¨: {latency_improvement:+.1f}%")

    print(f"\nğŸ“š ê²€ìƒ‰ ê²°ê³¼:")
    print(f"  Before: {before['avg_contexts']:.1f} contexts")
    print(f"  After : {after['avg_contexts']:.1f} contexts")

    # ê²°ê³¼ ì €ì¥
    output_path = "data/chromadb_comparison.json"
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump({
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "before": before,
            "after": after,
            "improvement_pct": latency_improvement,
        }, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… ê²°ê³¼ ì €ì¥: {output_path}")

    # ì„±ê³µ ì—¬ë¶€ íŒì •
    if latency_improvement > 0:
        print(f"\nğŸ‰ SUCCESS: {latency_improvement:.1f}% ì„±ëŠ¥ í–¥ìƒ!")
    else:
        print(f"\nâš ï¸  WARNING: ì„±ëŠ¥ì´ {-latency_improvement:.1f}% ì €í•˜ë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument("--mode", choices=["legacy", "chromadb", "compare"],
                       default="compare", help="í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
    args = parser.parse_args()

    if args.mode == "compare":
        run_comparison()
    elif args.mode == "chromadb":
        test_query(use_chromadb=True)
    else:
        test_query(use_chromadb=False)
