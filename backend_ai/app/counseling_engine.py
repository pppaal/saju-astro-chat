# backend_ai/app/counseling_engine.py
"""
Jungian Counseling Engine - ê°ë™ì„ ì£¼ëŠ” ì‹¬ë¦¬ìƒë‹´ ì‹œìŠ¤í…œ
=====================================================
ìœµ ì‹¬ë¦¬í•™ ê¸°ë°˜ í†µí•© ìƒë‹´ ì—”ì§„ (v2.0 - Enhanced with RAG)
- ì‚¬ì£¼/ì ì„±ìˆ /íƒ€ë¡œë¥¼ ì‹¬ë¦¬í•™ì  ë„êµ¬ë¡œ í™œìš©
- ìœ„ê¸° ê°œì… ì‹œìŠ¤í…œ (ìì‚´/ìí•´ ê°ì§€)
- ì¹˜ë£Œì  ì§ˆë¬¸ ìƒì„± (RuleEngine + ì‹œë§¨í‹± ê²€ìƒ‰)
- ê°ë™ì  ë©”ì‹œì§€ ì‹œìŠ¤í…œ
- ê°œì„±í™” ì—¬ì • ê°€ì´ë“œ

"ë„êµ¬ëŠ” ê±°ìš¸ì´ë‹¤. ë‹µì€ ë‚´ë‹´ì ì•ˆì— ìˆë‹¤."
"""

import os
import json
import re
import random
import hashlib
from typing import List, Dict, Optional, Tuple, Any
from datetime import datetime

# Load .env with override to use correct API key
try:
    from dotenv import load_dotenv
    _backend_root = os.path.dirname(os.path.dirname(__file__))
    load_dotenv(os.path.join(_backend_root, ".env"), override=True)
except ImportError:
    pass

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OpenAI = None
    OPENAI_AVAILABLE = False

# ì‹œë§¨í‹± ê²€ìƒ‰ (SentenceTransformer)
try:
    import torch
    from sentence_transformers import util
    # Use shared model singleton from saju_astro_rag
    try:
        from backend_ai.app.saju_astro_rag import get_model as get_shared_model
    except ImportError:
        from saju_astro_rag import get_model as get_shared_model
    EMBEDDING_AVAILABLE = True
except ImportError:
    EMBEDDING_AVAILABLE = False
    torch = None
    get_shared_model = None

# RuleEngine ì„í¬íŠ¸
try:
    from app.rule_engine import RuleEngine
    RULE_ENGINE_AVAILABLE = True
except ImportError:
    try:
        from rule_engine import RuleEngine
        RULE_ENGINE_AVAILABLE = True
    except ImportError:
        RULE_ENGINE_AVAILABLE = False
        RuleEngine = None


# ===============================================================
# CRISIS DETECTION SYSTEM (ìœ„ê¸° ê°ì§€)
# ===============================================================
class CrisisDetector:
    """ìœ„ê¸° ìƒí™© ê°ì§€ ë° ì•ˆì „ í”„ë¡œí† ì½œ"""

    # ìœ„í—˜ í‚¤ì›Œë“œ (í•œêµ­ì–´)
    HIGH_RISK_KEYWORDS = {
        "suicidal": {
            "keywords": ["ì£½ê³  ì‹¶", "ìì‚´", "ëë‚´ê³  ì‹¶", "ì‚¬ë¼ì§€ê³  ì‹¶", "ì—†ì–´ì§€ê³  ì‹¶",
                        "ë” ì´ìƒ ëª» ì‚´", "ì‚¶ì„ ë", "ì£½ëŠ” ê²Œ ë‚˜ì„", "ì£½ì–´ë²„ë¦¬ê³ ", "ì„¸ìƒ ë– ë‚˜ê³ "],
            "severity": "critical",
            "action": "immediate_safety_check"
        },
        "self_harm": {
            "keywords": ["ìí•´", "ì†ëª©", "ì¹¼ë¡œ", "í”¼", "ìŠ¤ìŠ¤ë¡œ ë‹¤ì¹˜", "ì•„í”„ê²Œ í•˜ê³  ì‹¶",
                        "ìƒì²˜ ë‚´ê³ ", "ê¸‹ê³  ì‹¶"],
            "severity": "high",
            "action": "safety_assessment"
        },
        "harm_to_others": {
            "keywords": ["ì£½ì´ê³  ì‹¶", "í•´ì¹˜ê³  ì‹¶", "ë³µìˆ˜", "í­ë ¥", "ë•Œë¦¬ê³  ì‹¶"],
            "severity": "high",
            "action": "safety_assessment"
        },
        "severe_distress": {
            "keywords": ["ìˆ¨ì„ ëª» ì‰¬", "ê³µí™©", "ë¯¸ì¹  ê²ƒ ê°™", "ê²¬ë”œ ìˆ˜ ì—†", "ë„ˆë¬´ ê³ í†µìŠ¤ëŸ¬"],
            "severity": "medium_high",
            "action": "grounding_and_support"
        },
        "hopelessness": {
            "keywords": ["í¬ë§ì´ ì—†", "ë‚˜ì•„ì§ˆ ê²Œ ì—†", "ì–´ì°¨í”¼", "ì†Œìš©ì—†", "ì˜ë¯¸ ì—†"],
            "severity": "medium",
            "action": "meaning_exploration"
        }
    }

    EMERGENCY_RESOURCES = {
        "ko": {
            "suicide_hotline": "ìì‚´ì˜ˆë°©ìƒë‹´ì „í™” 1393",
            "mental_health": "ì •ì‹ ê±´ê°•ìœ„ê¸°ìƒë‹´ì „í™” 1577-0199",
            "counseling": "ìƒëª…ì˜ì „í™” 1588-9191"
        },
        "en": {
            "suicide_hotline": "National Suicide Prevention Lifeline: 988",
            "mental_health": "Crisis Text Line: Text HOME to 741741"
        }
    }

    @classmethod
    def detect_crisis(cls, text: str) -> Dict:
        """í…ìŠ¤íŠ¸ì—ì„œ ìœ„ê¸° ì‹ í˜¸ ê°ì§€"""
        text_lower = text.lower()
        detected = []
        max_severity = "none"
        severity_order = ["none", "low", "medium", "medium_high", "high", "critical"]

        for category, data in cls.HIGH_RISK_KEYWORDS.items():
            for keyword in data["keywords"]:
                if keyword in text_lower:
                    detected.append({
                        "category": category,
                        "keyword": keyword,
                        "severity": data["severity"],
                        "action": data["action"]
                    })
                    # ìµœê³  ì‹¬ê°ë„ ì—…ë°ì´íŠ¸
                    if severity_order.index(data["severity"]) > severity_order.index(max_severity):
                        max_severity = data["severity"]

        return {
            "is_crisis": len(detected) > 0,
            "max_severity": max_severity,
            "detections": detected,
            "requires_immediate_action": max_severity in ["critical", "high"]
        }

    @classmethod
    def get_crisis_response(cls, severity: str, locale: str = "ko") -> Dict:
        """ìœ„ê¸° ìˆ˜ì¤€ì— ë”°ë¥¸ ì‘ë‹µ ìƒì„±"""
        resources = cls.EMERGENCY_RESOURCES.get(locale, cls.EMERGENCY_RESOURCES["ko"])

        responses = {
            "critical": {
                "immediate_message": (
                    "ì§€ê¸ˆ ë§ì´ í˜ë“œì‹œë„¤ìš”. ë§ì”€í•´ì£¼ì…”ì„œ ê°ì‚¬í•´ìš”. ê·¸ ìš©ê¸°ê°€ ëŒ€ë‹¨í•´ìš”.\n\n"
                    "ì§€ê¸ˆ ì•ˆì „í•œ ê³³ì— ê³„ì‹ ê°€ìš”?"
                ),
                "follow_up": (
                    "ì´ëŸ° ìƒê°ì´ ë“œì‹¤ ë•ŒëŠ” ì „ë¬¸ ìƒë‹´ì´ ê¼­ í•„ìš”í•´ìš”.\n\n"
                    f"ğŸ“ {resources['suicide_hotline']}\n"
                    f"ğŸ“ {resources['mental_health']}\n\n"
                    "ì§€ê¸ˆ ë°”ë¡œ ì „í™”í•˜ì‹¤ ìˆ˜ ìˆìœ¼ì„¸ìš”?"
                ),
                "closing": (
                    "ì €ì™€ ëŒ€í™”í•´ì£¼ì…”ì„œ ì •ë§ ê°ì‚¬í•´ìš”. ë‹¹ì‹ ì€ í˜¼ìê°€ ì•„ë‹ˆì—ìš”.\n"
                    "ê¼­ ì „ë¬¸ ë„ì›€ì„ ë°›ìœ¼ì„¸ìš”. ë‹¹ì‹ ì˜ ì‚¶ì€ ì†Œì¤‘í•´ìš”."
                ),
                "should_continue_session": False
            },
            "high": {
                "immediate_message": (
                    "ì •ë§ í˜ë“  ì‹œê°„ì„ ë³´ë‚´ê³  ê³„ì‹œë„¤ìš”. ê·¸ ê³ í†µì´ ëŠê»´ì ¸ìš”.\n\n"
                    "ì ì‹œ ë©ˆì¶”ê³ , ìˆ¨ì„ ì‰¬ì–´ë³¼ê¹Œìš”?"
                ),
                "follow_up": (
                    "4ì´ˆ ë“¤ì´ì‰¬ê³ ... 4ì´ˆ ë‚´ì‰¬ê³ ...\n\n"
                    "ì§€ê¸ˆ ë°œì´ ë°”ë‹¥ì— ë‹¿ì•„ìˆëŠ” ê±¸ ëŠê»´ë³´ì„¸ìš”.\n"
                    "ì—¬ê¸° ì•ˆì „í•œ ê³³ì´ì—ìš”. ì œê°€ í•¨ê»˜ ìˆì–´ìš”."
                ),
                "resources": (
                    f"í•„ìš”í•˜ì‹œë©´ ì „ë¬¸ ìƒë‹´ì„ ê¶Œí•´ë“œë ¤ìš”:\n"
                    f"ğŸ“ {resources['mental_health']}\n"
                    f"ğŸ“ {resources['counseling']}"
                ),
                "should_continue_session": True
            },
            "medium_high": {
                "immediate_message": (
                    "ì§€ê¸ˆ ì •ë§ í˜ë“œì‹œêµ°ìš”. ê·¸ ê°ì •ì„ ë§ì”€í•´ì£¼ì…”ì„œ ê³ ë§ˆì›Œìš”.\n\n"
                    "ì ì‹œ ê°™ì´ í˜¸í¡í•´ë³¼ê¹Œìš”?"
                ),
                "grounding": (
                    "ì§€ê¸ˆ ì´ ìˆœê°„ì— ì§‘ì¤‘í•´ë³¼ê²Œìš”.\n"
                    "- ë³´ì´ëŠ” ê²ƒ 3ê°€ì§€\n"
                    "- ë“¤ë¦¬ëŠ” ê²ƒ 2ê°€ì§€\n"
                    "- ëŠê»´ì§€ëŠ” ê²ƒ 1ê°€ì§€\n\n"
                    "ì²œì²œíˆ ë§ì”€í•´ì£¼ì„¸ìš”."
                ),
                "should_continue_session": True
            },
            "medium": {
                "empathic_response": (
                    "í˜ë“  ë§ˆìŒì´ ëŠê»´ì ¸ìš”. í¬ë§ì´ ì—†ë‹¤ê³  ëŠê»´ì§ˆ ë•Œê°€ ê°€ì¥ ì–´ë µì£ .\n\n"
                    "ê·¸ëŸ°ë°... ê·¸ ì–´ë‘  ì†ì—ì„œë„ ë‹¹ì‹ ì€ ì—¬ê¸° ì™€ì„œ ì´ì•¼ê¸°í•˜ê³  ìˆì–´ìš”.\n"
                    "ê·¸ê²ƒ ìì²´ê°€ ì˜ë¯¸ ìˆëŠ” ê±°ì˜ˆìš”."
                ),
                "should_continue_session": True
            }
        }

        return responses.get(severity, {"should_continue_session": True})


# ===============================================================
# THERAPEUTIC QUESTION GENERATOR (ì¹˜ë£Œì  ì§ˆë¬¸ ìƒì„±ê¸°)
# ===============================================================
class TherapeuticQuestionGenerator:
    """ìœµ ì‹¬ë¦¬í•™ ê¸°ë°˜ ì¹˜ë£Œì  ì§ˆë¬¸ ìƒì„±"""

    def __init__(self, rules_dir: str = None):
        if rules_dir is None:
            base_dir = os.path.dirname(os.path.dirname(__file__))
            rules_dir = os.path.join(base_dir, "data", "graph", "rules", "jung")

        self.rules_dir = rules_dir
        self.therapeutic_data = {}
        self.prompts_data = {}
        self.archetypes_data = {}
        self.psychological_types_data = {}
        self.alchemy_data = {}
        self.cross_analysis_data = {}
        self.scenarios_data = {}
        self.integrated_data = {}
        self.personality_data = {}
        self.expanded_data = {}
        self._load_data()

    def _load_data(self):
        """ìœµ ì‹¬ë¦¬í•™ ë°ì´í„° ë¡œë“œ - ëª¨ë“  Jung íŒŒì¼ í†µí•©"""
        files_to_load = {
            "jung_therapeutic.json": "therapeutic_data",
            "jung_counseling_prompts.json": "prompts_data",
            "jung_archetypes.json": "archetypes_data",
            "jung_psychological_types.json": "psychological_types_data",
            "jung_alchemy.json": "alchemy_data",
            "jung_cross_analysis.json": "cross_analysis_data",
            "jung_counseling_scenarios.json": "scenarios_data",
            "jung_integrated_counseling.json": "integrated_data",
            "jung_personality_integration.json": "personality_data",
            "jung_expanded_counseling.json": "expanded_data",
        }

        for filename, attr in files_to_load.items():
            path = os.path.join(self.rules_dir, filename)
            if os.path.exists(path):
                try:
                    with open(path, encoding='utf-8') as f:
                        setattr(self, attr, json.load(f))
                except Exception as e:
                    print(f"[TherapeuticQuestionGenerator] Failed to load {filename}: {e}")
            else:
                setattr(self, attr, {})

    def get_shadow_questions(self, context: Dict = None) -> List[str]:
        """ê·¸ë¦¼ì ì‘ì—… ì§ˆë¬¸"""
        questions = self.therapeutic_data.get("therapeutic_questions", {}).get("shadow_work", {}).get("questions", [])
        return questions or [
            "ê°€ì¥ ì‹«ì–´í•˜ëŠ” ì‚¬ëŒì˜ íŠ¹ì„± 3ê°€ì§€ë¥¼ ì ì–´ë³´ì„¸ìš”. ê·¸ê²ƒì´ ë‹¹ì‹ ì˜ ê·¸ë¦¼ìì…ë‹ˆë‹¤.",
            "í™”ê°€ ë‚  ë•Œ ë‹¹ì‹ ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”? ê·¸ 'ì–´ë‘ìš´ ë‹¹ì‹ 'ì€ ë¬´ì—‡ì„ ì›í•˜ë‚˜ìš”?",
            "ë§Œì•½ ì•„ë¬´ë„ íŒë‹¨í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´, ë‹¹ì‹ ì´ í•˜ê³  ì‹¶ì€ 'ë‚˜ìœ' ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?"
        ]

    def get_inner_child_questions(self) -> List[str]:
        """ë‚´ë©´ ì•„ì´ ì‘ì—… ì§ˆë¬¸"""
        questions = self.therapeutic_data.get("therapeutic_questions", {}).get("inner_child", {}).get("questions", [])
        return questions or [
            "ì–´ë¦° ì‹œì ˆ ë‹¹ì‹ ì—ê²Œ ê°€ì¥ í•„ìš”í–ˆì§€ë§Œ ë°›ì§€ ëª»í•œ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "7ì‚´ì˜ ë‹¹ì‹ ì—ê²Œ ì§€ê¸ˆ ë¬´ìŠ¨ ë§ì„ í•´ì£¼ê³  ì‹¶ë‚˜ìš”?",
            "ë‹¹ì‹ ì˜ ë‚´ë©´ ì•„ì´ëŠ” ì§€ê¸ˆ ë¬´ì—‡ì„ ì›í•˜ê³  ìˆë‚˜ìš”?"
        ]

    def get_meaning_questions(self) -> List[str]:
        """ì˜ë¯¸ íƒìƒ‰ ì§ˆë¬¸"""
        questions = self.therapeutic_data.get("therapeutic_questions", {}).get("meaning_crisis", {}).get("questions", [])
        return questions or [
            "ë‹¹ì‹ ì´ ì§„ì •ìœ¼ë¡œ ì‚´ì•„ìˆë‹¤ê³  ëŠë¼ëŠ” ìˆœê°„ì€ ì–¸ì œì¸ê°€ìš”?",
            "ì£½ìŒì„ ì•ë‘ê³  í›„íšŒí•  ê²ƒì´ ìˆë‹¤ë©´ ë¬´ì—‡ì¼ê¹Œìš”?",
            "ë‹¹ì‹ ì˜ ì‚¶ì´ í•˜ë‚˜ì˜ ì´ì•¼ê¸°ë¼ë©´, ì§€ê¸ˆì€ ì–´ë–¤ ì±•í„°ì¸ê°€ìš”?"
        ]

    def get_deepening_questions(self) -> List[str]:
        """ì‹¬í™” íƒìƒ‰ ì§ˆë¬¸"""
        return self.prompts_data.get("response_patterns", {}).get("therapeutic_questions", {}).get("deepening", []) or [
            "ê·¸ê²ƒì´ ë‹¹ì‹ ì—ê²Œ ì™œ ê·¸ë ‡ê²Œ ì¤‘ìš”í•œê°€ìš”?",
            "ê·¸ ë°‘ì— ìˆëŠ” ê°ì •ì€ ë¬´ì—‡ì¼ê¹Œìš”?",
            "ì–¸ì œë¶€í„° ê·¸ëŸ° ëŠë‚Œì´ ë“œì…¨ë‚˜ìš”?",
            "ë¹„ìŠ·í•œ ëŠë‚Œì„ ë°›ì•˜ë˜ ë‹¤ë¥¸ ìƒí™©ì´ ìˆë‚˜ìš”?"
        ]

    def get_challenging_questions(self) -> List[str]:
        """ë„ì „ì  ì§ˆë¬¸"""
        return self.prompts_data.get("response_patterns", {}).get("therapeutic_questions", {}).get("challenging", []) or [
            "ì •ë§ ê·¸ëŸ´ê¹Œìš”? ë‹¤ë¥¸ ê°€ëŠ¥ì„±ì€ ì—†ì„ê¹Œìš”?",
            "ìƒëŒ€ë°© ì…ì¥ì—ì„œ ë³´ë©´ ì–´ë–¨ê¹Œìš”?",
            "ê·¸ê²ƒì´ ì‚¬ì‹¤ì´ë¼ë©´, ê·¸ë˜ì„œ ì–´ë–»ê²Œ ë˜ëŠ” ê±´ê°€ìš”?"
        ]

    def get_action_questions(self) -> List[str]:
        """í–‰ë™ ì§€í–¥ ì§ˆë¬¸"""
        return self.prompts_data.get("response_patterns", {}).get("therapeutic_questions", {}).get("action_oriented", []) or [
            "ì´ í†µì°°ì„ ì–´ë–»ê²Œ ì ìš©í•´ë³¼ ìˆ˜ ìˆì„ê¹Œìš”?",
            "ê°€ì¥ ì‘ì€ ì²« ê±¸ìŒì€ ë­˜ê¹Œìš”?",
            "ë‚´ì¼ ë‹¹ì¥ í•´ë³¼ ìˆ˜ ìˆëŠ” ê²ƒ í•˜ë‚˜ê°€ ìˆë‹¤ë©´?"
        ]

    def get_question_for_archetype(self, archetype: str) -> str:
        """íŠ¹ì • ì›í˜•ì— ë§ëŠ” ì§ˆë¬¸ ìƒì„±"""
        archetype_questions = {
            "shadow": "ê·¸ íŠ¹ì„±ì´ ë‹¹ì‹ ì—ê²Œë„ ìˆë‹¤ë©´ ì–´ë–¨ê¹Œìš”?",
            "anima": "ê¿ˆì— ë‚˜íƒ€ë‚˜ëŠ” ì—¬ì„±ì€ ì–´ë–¤ ëª¨ìŠµì¸ê°€ìš”? ê·¸ë…€ê°€ ë‹¹ì‹ ì—ê²Œ ì›í•˜ëŠ” ê²ƒì€?",
            "animus": "ë‚´ë©´ì˜ ë¹„íŒì  ëª©ì†Œë¦¬ëŠ” ëˆ„êµ¬ì˜ ê²ƒì¸ê°€ìš”?",
            "persona": "ì™„ì „íˆ í˜¼ì ìˆì„ ë•Œ ë‹¹ì‹ ì€ ëˆ„êµ¬ì¸ê°€ìš”?",
            "self": "ë‹¹ì‹ ì´ ê°€ì¥ 'ë‚˜ ìì‹ 'ì´ë¼ê³  ëŠë¼ëŠ” ìˆœê°„ì€ ì–¸ì œì¸ê°€ìš”?",
            "inner_child": "ì–´ë¦° ì‹œì ˆ ë‹¹ì‹ ì—ê²Œ ê°€ì¥ í•„ìš”í–ˆì§€ë§Œ ë°›ì§€ ëª»í•œ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "wise_old_man": "ë‹¹ì‹ ì˜ ë‚´ë©´ì—ì„œ ê°€ì¥ í˜„ëª…í•œ ë¶€ë¶„ì€ ë­ë¼ê³  ë§í•˜ë‚˜ìš”?",
            "great_mother": "ë¬´ì¡°ê±´ì ì¸ ìˆ˜ìš©ì„ ê²½í—˜í•œ ì ì´ ìˆë‚˜ìš”? ì–¸ì œì˜€ë‚˜ìš”?"
        }
        return archetype_questions.get(archetype, "ì´ ì—ë„ˆì§€ê°€ ì‚¬ëŒì´ë¼ë©´ ì–´ë–¤ ëª¨ìŠµì¼ê¹Œìš”?")

    def get_question_for_theme(self, theme: str) -> str:
        """í…Œë§ˆë³„ ì§ˆë¬¸"""
        theme_questions = {
            "relationship": "ê´€ê³„ì—ì„œ ë‹¹ì‹ ì´ ê°€ì¥ ì›í•˜ëŠ” ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”? ê·¸ê²ƒì„ ì™œ ì›í•˜ë‚˜ìš”?",
            "career": "ì¼ì„ í•  ë•Œ ê°€ì¥ ì‚´ì•„ìˆë‹¤ê³  ëŠë¼ëŠ” ìˆœê°„ì€ ì–¸ì œì¸ê°€ìš”?",
            "identity": "ë§Œì•½ ëª¨ë“  ì—­í• ì„ ë‚´ë ¤ë†“ëŠ”ë‹¤ë©´, ë¬´ì—‡ì´ ë‚¨ë‚˜ìš”?",
            "family": "ë¶€ëª¨ë‹˜ì—ê²Œì„œ ë¬¼ë ¤ë°›ì€ ê²ƒ ì¤‘ ê°ì‚¬í•œ ê²ƒê³¼ ë‚´ë ¤ë†“ê³  ì‹¶ì€ ê²ƒì€?",
            "health": "ëª¸ì´ ë‹¹ì‹ ì—ê²Œ ë§í•˜ê³  ìˆë‹¤ë©´, ë­ë¼ê³  í•  ê²ƒ ê°™ì•„ìš”?",
            "spiritual": "ì˜í˜¼ì´ ê°ˆë§í•˜ëŠ” ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "money": "ëˆê³¼ ë‹¹ì‹ ì˜ ê´€ê³„ëŠ” ì–´ë–¤ê°€ìš”? ëˆì´ ì˜ë¯¸í•˜ëŠ” ê²ƒì€?",
            "love": "ì§„ì •í•œ ì‚¬ë‘ì´ë€ ë‹¹ì‹ ì—ê²Œ ì–´ë–¤ ëª¨ìŠµì¸ê°€ìš”?"
        }
        return theme_questions.get(theme, "ì´ê²ƒì´ ë‹¹ì‹ ì—ê²Œ ì™œ ì¤‘ìš”í•œê°€ìš”?")

    def get_psychological_type_insight(self, saju_data: Dict = None) -> Dict:
        """ì‹¬ë¦¬ ìœ í˜• ê¸°ë°˜ í†µì°° (ìœµì˜ ì‹¬ë¦¬ ìœ í˜•ë¡  í™œìš©)"""
        if not self.psychological_types_data:
            return {}
        types = self.psychological_types_data.get("psychological_types", {})
        # ì‚¬ì£¼ ë°ì´í„°ë¡œë¶€í„° ì‹¬ë¦¬ ìœ í˜• ë§¤í•‘ ì‹œë„
        if saju_data:
            day_master = saju_data.get("dayMaster", {})
            # Support both nested { heavenlyStem: { element } } and flat { element }
            if isinstance(day_master.get("heavenlyStem"), dict):
                element = day_master.get("heavenlyStem", {}).get("element", "").lower()
            else:
                element = day_master.get("element", "").lower()
            # ì˜¤í–‰â†’ì‹¬ë¦¬ìœ í˜• ë§¤í•‘
            element_to_type = {
                "wood": "intuition",
                "fire": "feeling",
                "earth": "sensation",
                "metal": "thinking",
                "water": "intuition"
            }
            matched_type = element_to_type.get(element)
            if matched_type and matched_type in types:
                return types[matched_type]
        return {}

    def get_alchemy_stage(self, user_context: str = "") -> Dict:
        """ì—°ê¸ˆìˆ ì  ë³€í™˜ ë‹¨ê³„ íŒŒì•… (ë‹ˆê·¸ë ˆë„â†’ì•Œë² ë„â†’ë£¨ë² ë„)"""
        if not self.alchemy_data:
            return {}
        stages = self.alchemy_data.get("alchemical_stages", {})
        keywords_map = {
            "nigredo": ["ì–´ë‘ ", "í˜¼ë€", "ë¶•ê´´", "ì£½ìŒ", "ë", "ì ˆë§", "ë§‰ë§‰"],
            "albedo": ["ì •í™”", "ê¹¨ë‹¬ìŒ", "ì´í•´", "ìˆ˜ìš©", "ë°›ì•„ë“¤"],
            "citrinitas": ["ì„±ì¥", "ë°œì „", "ë°°ì›€", "ë³€í™”"],
            "rubedo": ["í†µí•©", "ì™„ì„±", "ìƒˆë¡œìš´", "ì‹œì‘", "íƒ„ìƒ"]
        }
        for stage, keywords in keywords_map.items():
            if any(kw in user_context for kw in keywords):
                return stages.get(stage, {})
        return stages.get("nigredo", {})  # ê¸°ë³¸ê°’

    def get_scenario_guidance(self, scenario_type: str) -> Dict:
        """ìƒë‹´ ì‹œë‚˜ë¦¬ì˜¤ë³„ ê°€ì´ë“œ (ì‚¬ë‘, ì§ì—…, ê°€ì¡± ë“±)"""
        if not self.scenarios_data:
            return {}
        scenarios = self.scenarios_data.get("counseling_scenarios", {})
        return scenarios.get(scenario_type, {})

    def get_cross_system_insight(self, saju_data: Dict, astro_data: Dict) -> Dict:
        """ì‚¬ì£¼Ã—ì ì„±ìˆ  êµì°¨ ë¶„ì„ í†µì°°"""
        if not self.cross_analysis_data:
            return {}
        cross = self.cross_analysis_data.get("cross_system_analysis", {})
        # ì˜¤í–‰ê³¼ 4ì›ì†Œ ë§¤í•‘
        element_mapping = cross.get("element_mapping", {})
        insights = []
        if saju_data:
            dm = saju_data.get("dayMaster", {})
            # Support both nested and flat dayMaster
            if isinstance(dm.get("heavenlyStem"), dict):
                day_element = dm.get("heavenlyStem", {}).get("element", "")
            else:
                day_element = dm.get("element", "")
            mapped = element_mapping.get(day_element, {})
            if mapped:
                insights.append(mapped)
        return {"insights": insights, "raw": cross}

    def get_personality_integration_guide(self, dominant_trait: str = None) -> List[str]:
        """ì„±ê²© í†µí•© ê°€ì´ë“œ (ê·¸ë¦¼ì ì‘ì—…)"""
        if not self.personality_data:
            return []
        integration = self.personality_data.get("personality_integration", {})
        if dominant_trait:
            return integration.get(dominant_trait, {}).get("integration_path", [])
        return integration.get("general", {}).get("steps", [])


# ===============================================================
# JUNGIAN RAG (ìœµ ì‹¬ë¦¬í•™ ì‹œë§¨í‹± ê²€ìƒ‰)
# ===============================================================
class JungianRAG:
    """
    ìœµ ì‹¬ë¦¬í•™ ê¸°ë°˜ ì‹œë§¨í‹± ê²€ìƒ‰ ì—”ì§„
    - SentenceTransformerë¡œ ì§ˆë¬¸/ìƒí™© â†’ ì¹˜ë£Œì  ê°œì… ë§¤ì¹­
    - RuleEngineìœ¼ë¡œ ì¡°ê±´ ê¸°ë°˜ ê·œì¹™ ë§¤ì¹­
    """

    MODEL_NAME = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"

    def __init__(self, rules_dir: str = None):
        if rules_dir is None:
            base_dir = os.path.dirname(os.path.dirname(__file__))
            rules_dir = os.path.join(base_dir, "data", "graph", "rules", "jung")

        self.rules_dir = rules_dir
        self._model = None
        self._model_failed = False

        # ì„ë² ë”© ë°ì´í„°
        self.corpus_texts = []  # ê²€ìƒ‰ ëŒ€ìƒ í…ìŠ¤íŠ¸
        self.corpus_meta = []   # ë©”íƒ€ë°ì´í„° (source, category, etc.)
        self.corpus_embeds = None
        self.embed_cache_path = os.path.join(rules_dir, "jung_embeds.pt") if rules_dir else None

        # RuleEngine (ì¡°ê±´ ë§¤ì¹­ìš©)
        self.rule_engine = None
        if RULE_ENGINE_AVAILABLE and os.path.exists(rules_dir):
            try:
                self.rule_engine = RuleEngine(rules_dir)
                print(f"[JungianRAG] RuleEngine loaded with {len(self.rule_engine.rules)} rule sets")
            except Exception as e:
                print(f"[JungianRAG] RuleEngine init failed: {e}")

        # ë°ì´í„° ë¡œë“œ ë° ì„ë² ë”© ì¤€ë¹„
        self._load_corpus()
        self._prepare_embeddings()

    @property
    def model(self):
        """Get shared model singleton from saju_astro_rag"""
        if self._model is None and not self._model_failed:
            if not EMBEDDING_AVAILABLE or get_shared_model is None:
                self._model_failed = True
                return None
            try:
                print("[JungianRAG] Using shared model from saju_astro_rag...")
                self._model = get_shared_model()
            except Exception as e:
                print(f"[JungianRAG] Model load failed: {e}")
                self._model_failed = True
        return self._model

    def _load_corpus(self):
        """ìœµ ì‹¬ë¦¬í•™ JSON íŒŒì¼ì—ì„œ ê²€ìƒ‰ ì½”í¼ìŠ¤ êµ¬ì¶•"""
        if not os.path.exists(self.rules_dir):
            return

        for filename in os.listdir(self.rules_dir):
            if not filename.endswith(".json"):
                continue

            filepath = os.path.join(self.rules_dir, filename)
            try:
                with open(filepath, encoding="utf-8") as f:
                    data = json.load(f)
                    self._extract_corpus_items(data, filename)
            except Exception as e:
                print(f"[JungianRAG] Failed to load {filename}: {e}")

        print(f"[JungianRAG] Corpus built: {len(self.corpus_texts)} items from {self.rules_dir}")

    def _extract_corpus_items(self, data: Any, source: str, prefix: str = ""):
        """ì¬ê·€ì ìœ¼ë¡œ í…ìŠ¤íŠ¸ í•­ëª© ì¶”ì¶œ"""
        if isinstance(data, dict):
            # ì¹˜ë£Œì  ì§ˆë¬¸ ì¶”ì¶œ
            if "questions" in data and isinstance(data["questions"], list):
                for q in data["questions"]:
                    if isinstance(q, str) and len(q) > 10:
                        self.corpus_texts.append(q)
                        self.corpus_meta.append({
                            "source": source,
                            "category": prefix,
                            "type": "question"
                        })

            # í†µì°°/ì¡°ì–¸ ì¶”ì¶œ
            for key in ["insight", "advice", "description", "therapeutic_focus", "approach"]:
                if key in data and isinstance(data[key], str) and len(data[key]) > 10:
                    self.corpus_texts.append(data[key])
                    self.corpus_meta.append({
                        "source": source,
                        "category": prefix,
                        "type": key
                    })

            # ì¬ê·€
            for k, v in data.items():
                self._extract_corpus_items(v, source, f"{prefix}/{k}" if prefix else k)

        elif isinstance(data, list):
            for item in data:
                self._extract_corpus_items(item, source, prefix)

    def _calculate_hash(self) -> str:
        """ì½”í¼ìŠ¤ í•´ì‹œ ê³„ì‚° (ìºì‹œ ë¬´íš¨í™”ìš©)"""
        content = "|".join(self.corpus_texts[:100])  # ì• 100ê°œë§Œ í•´ì‹œ
        return hashlib.md5(content.encode()).hexdigest()[:12]

    def _prepare_embeddings(self):
        """ì„ë² ë”© ì¤€ë¹„ (ìºì‹œ í™œìš©)"""
        if not self.corpus_texts:
            return

        current_hash = self._calculate_hash()

        # ìºì‹œ í™•ì¸
        if self.embed_cache_path and os.path.exists(self.embed_cache_path):
            try:
                cache = torch.load(self.embed_cache_path, map_location="cpu")
                if cache.get("hash") == current_hash and cache.get("count") == len(self.corpus_texts):
                    self.corpus_embeds = cache["embeds"]
                    print(f"[JungianRAG] Loaded cached embeddings: {self.corpus_embeds.shape}")
                    return
            except Exception as e:
                print(f"[JungianRAG] Cache load failed: {e}")

        # ìƒˆë¡œ ìƒì„±
        if self.model is None:
            print("[JungianRAG] Model not available, skipping embeddings")
            return

        try:
            print(f"[JungianRAG] Generating embeddings for {len(self.corpus_texts)} items...")
            self.corpus_embeds = self.model.encode(
                self.corpus_texts,
                convert_to_tensor=True,
                normalize_embeddings=True,
                batch_size=32
            )
            print(f"[JungianRAG] Generated embeddings: {self.corpus_embeds.shape}")

            # ìºì‹œ ì €ì¥
            if self.embed_cache_path:
                torch.save({
                    "embeds": self.corpus_embeds,
                    "count": len(self.corpus_texts),
                    "hash": current_hash
                }, self.embed_cache_path)
        except Exception as e:
            print(f"[JungianRAG] Embedding generation failed: {e}")

    def search(self, query: str, top_k: int = 5, threshold: float = 0.3) -> List[Dict]:
        """
        ì‹œë§¨í‹± ê²€ìƒ‰: ì§ˆë¬¸/ìƒí™©ì— ë§ëŠ” ìœµ ì‹¬ë¦¬í•™ ì»¨í…ì¸  ê²€ìƒ‰

        Args:
            query: ì‚¬ìš©ì ë©”ì‹œì§€ ë˜ëŠ” ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            threshold: ìµœì†Œ ìœ ì‚¬ë„ ì ìˆ˜

        Returns:
            List of {text, similarity, source, category, type}
        """
        if self.corpus_embeds is None or self.model is None:
            return self._fallback_keyword_search(query, top_k)

        try:
            query_embed = self.model.encode(query, convert_to_tensor=True, normalize_embeddings=True)
            scores = util.cos_sim(query_embed, self.corpus_embeds)[0]
            top_results = torch.topk(scores, k=min(top_k * 2, len(self.corpus_texts)))

            results = []
            for idx, score in zip(top_results.indices, top_results.values):
                if float(score) < threshold:
                    continue
                results.append({
                    "text": self.corpus_texts[int(idx)],
                    "similarity": round(float(score), 4),
                    **self.corpus_meta[int(idx)]
                })
                if len(results) >= top_k:
                    break

            return results
        except Exception as e:
            print(f"[JungianRAG] Search error: {e}")
            return self._fallback_keyword_search(query, top_k)

    def _fallback_keyword_search(self, query: str, top_k: int = 5) -> List[Dict]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°± ê²€ìƒ‰"""
        query_lower = query.lower()
        keywords = query_lower.split()

        results = []
        for i, text in enumerate(self.corpus_texts):
            text_lower = text.lower()
            score = sum(1 for kw in keywords if kw in text_lower)
            if score > 0:
                results.append({
                    "text": text,
                    "similarity": score / len(keywords),
                    **self.corpus_meta[i],
                    "fallback": True
                })

        results.sort(key=lambda x: x["similarity"], reverse=True)
        return results[:top_k]

    def get_rule_based_response(self, facts: Dict[str, Any]) -> Dict[str, Any]:
        """
        RuleEngine ê¸°ë°˜ ì¡°ê±´ ë§¤ì¹­

        Args:
            facts: {"theme": "...", "saju": {...}, "astro": {...}, "emotion": "...", ...}

        Returns:
            ë§¤ì¹­ëœ ê·œì¹™ ê²°ê³¼
        """
        if not self.rule_engine:
            return {"matched_rules": [], "matched_count": 0}

        return self.rule_engine.evaluate(facts, search_all=True)

    def get_therapeutic_intervention(self, user_message: str, context: Dict = None) -> Dict[str, Any]:
        """
        í†µí•© ì¹˜ë£Œì  ê°œì… ì œì•ˆ

        ì‹œë§¨í‹± ê²€ìƒ‰ + RuleEngine ê²°í•©

        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            context: {"saju": {...}, "astro": {...}, "theme": "...", ...}

        Returns:
            {
                "semantic_matches": [...],
                "rule_matches": [...],
                "recommended_questions": [...],
                "insights": [...]
            }
        """
        result = {
            "semantic_matches": [],
            "rule_matches": [],
            "recommended_questions": [],
            "insights": []
        }

        # 1. ì‹œë§¨í‹± ê²€ìƒ‰
        semantic = self.search(user_message, top_k=5)
        result["semantic_matches"] = semantic

        # ì§ˆë¬¸ê³¼ í†µì°° ë¶„ë¦¬
        for item in semantic:
            if item.get("type") == "question":
                result["recommended_questions"].append(item["text"])
            else:
                result["insights"].append(item["text"])

        # 2. RuleEngine ë§¤ì¹­
        if context and self.rule_engine:
            facts = {
                "theme": context.get("theme", "general"),
                "saju": context.get("saju", {}),
                "astro": context.get("astro", {}),
                "emotion": self._detect_emotion(user_message),
                "keywords": user_message.lower().split()
            }
            rule_result = self.rule_engine.evaluate(facts, search_all=True)
            result["rule_matches"] = rule_result.get("matched_rules", [])

        return result

    def _detect_emotion(self, text: str) -> str:
        """ê°„ë‹¨í•œ ê°ì • ê°ì§€"""
        emotion_keywords = {
            "anger": ["í™”ë‚˜", "ì§œì¦", "ë¶„ë…¸", "ì—´ë°›", "ì‹«ì–´"],
            "sadness": ["ìŠ¬í”„", "ìš°ìš¸", "ëˆˆë¬¼", "ì™¸ë¡œ", "í˜ë“¤"],
            "anxiety": ["ë¶ˆì•ˆ", "ê±±ì •", "ë‘ë ¤", "ë¬´ì„œ", "ë–¨ë ¤"],
            "confusion": ["ëª¨ë¥´ê² ", "í˜¼ë€", "ë³µì¡", "ê°ˆí”¼"],
            "hopelessness": ["í¬ë§", "ì˜ë¯¸", "ì†Œìš©ì—†", "í¬ê¸°"],
        }
        text_lower = text.lower()
        for emotion, keywords in emotion_keywords.items():
            if any(kw in text_lower for kw in keywords):
                return emotion
        return "neutral"

    def health_check(self) -> Tuple[bool, str]:
        """ìƒíƒœ í™•ì¸"""
        issues = []
        if not self.corpus_texts:
            issues.append("No corpus loaded")
        if self.corpus_embeds is None:
            issues.append("Embeddings not ready")
        if self._model_failed:
            issues.append("Model load failed")
        if not self.rule_engine:
            issues.append("RuleEngine not available")

        if issues:
            return False, f"Issues: {', '.join(issues)}"
        return True, f"OK: {len(self.corpus_texts)} items, RuleEngine active"


# Singleton
_jungian_rag = None

def get_jungian_rag() -> JungianRAG:
    """Get or create singleton JungianRAG"""
    global _jungian_rag
    if _jungian_rag is None:
        _jungian_rag = JungianRAG()
    return _jungian_rag


# ===============================================================
# EMOTIONAL MESSAGE GENERATOR (ê°ë™ ë©”ì‹œì§€ ìƒì„±ê¸°)
# ===============================================================
class EmotionalMessageGenerator:
    """ê°ë™ì„ ì£¼ëŠ” ë©”ì‹œì§€ ìƒì„±"""

    # ê³µê° ë©”ì‹œì§€ í…œí”Œë¦¿
    EMPATHY_TEMPLATES = {
        "pain_acknowledgment": [
            "ì •ë§ í˜ë“œì…¨ê² ì–´ìš”. ê·¸ ë¬´ê²Œë¥¼ í˜¼ì ì§€ê³  ê³„ì…¨êµ°ìš”.",
            "ê·¸ ê³ í†µì´ ëŠê»´ì ¸ìš”. ì˜¤ë˜ ì°¸ìœ¼ì…¨ë„¤ìš”.",
            "ë§ì”€í•˜ì‹œëŠ” ê²ƒë§Œìœ¼ë¡œë„ ìš©ê¸°ê°€ í•„ìš”í–ˆì„ ê±°ì˜ˆìš”.",
            "ê·¸ëŸ° ìƒí™©ì—ì„œ {emotion}í•˜ì‹  ê²Œ ë‹¹ì—°í•´ìš”."
        ],
        "validation": [
            "ë‹¹ì‹ ì˜ ê°ì •ì€ íƒ€ë‹¹í•´ìš”. ê·¸ë ‡ê²Œ ëŠë¼ëŠ” ê²Œ ë§ì•„ìš”.",
            "ê·¸ê²ƒì€ ì•½í•¨ì´ ì•„ë‹ˆì—ìš”. ì¸ê°„ì´ë¼ë©´ ë‹¹ì—°íˆ ëŠë‚„ ìˆ˜ ìˆëŠ” ê±°ì˜ˆìš”.",
            "ë‹¹ì‹ ì€ ì˜ëª»í•˜ì§€ ì•Šì•˜ì–´ìš”.",
            "í˜ë“¤ë‹¤ê³  ëŠë¼ëŠ” ê²ƒ, ê·¸ ìì²´ê°€ ì´ë¯¸ ì¶©ë¶„í•´ìš”."
        ],
        "hope": [
            "ì–´ë‘ ì´ ê¹Šì„ìˆ˜ë¡ ë³„ì´ ë°ê²Œ ë³´ì´ëŠ” ë²•ì´ì—ìš”.",
            "ì§€ê¸ˆì€ í˜ë“¤ì§€ë§Œ, ì´ê²ƒë„ ì§€ë‚˜ê°ˆ ê±°ì˜ˆìš”.",
            "ë‹¹ì‹  ì•ˆì—ëŠ” ìƒê°ë³´ë‹¤ í° í˜ì´ ìˆì–´ìš”.",
            "ëª¨ë“  ê²¨ìš¸ ë’¤ì—ëŠ” ë´„ì´ ì™€ìš”. ë‹¹ì‹ ì˜ ë´„ë„ ì˜¬ ê±°ì˜ˆìš”."
        ],
        "presence": [
            "ì§€ê¸ˆ ì´ ìˆœê°„, ì €ëŠ” ë‹¹ì‹  ê³ì— ìˆì–´ìš”.",
            "í˜¼ìê°€ ì•„ë‹ˆì—ìš”. ì œê°€ ë“£ê³  ìˆì–´ìš”.",
            "ì„œë‘ë¥´ì§€ ì•Šì•„ë„ ë¼ìš”. ì—¬ê¸°ì„œ í•¨ê»˜ ìˆì„ê²Œìš”.",
            "ë‹¹ì‹ ì˜ ì´ì•¼ê¸°ê°€ ì¤‘ìš”í•´ìš”. ë” ë“¤ë ¤ì£¼ì„¸ìš”."
        ]
    }

    # ìœµ ì‹¬ë¦¬í•™ ê¸°ë°˜ í†µì°° ë©”ì‹œì§€
    JUNGIAN_INSIGHTS = {
        "shadow": [
            "ìœµì€ ë§í–ˆì–´ìš”. 'ê·¸ë¦¼ìì™€ ëŒ€ë©´í•˜ì§€ ì•Šìœ¼ë©´, ê·¸ê²ƒì€ ìš´ëª…ì´ ëœë‹¤'ê³ ìš”.",
            "ìš°ë¦¬ê°€ ë¯¸ì›Œí•˜ëŠ” ê²ƒ ì†ì— ì¢…ì¢… ìš°ë¦¬ì˜ ìƒì–´ë²„ë¦° ì¡°ê°ì´ ìˆì–´ìš”.",
            "ê·¸ë¦¼ìëŠ” ì ì´ ì•„ë‹ˆì—ìš”. í†µí•©ë˜ê¸°ë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ì—ë„ˆì§€ì˜ˆìš”."
        ],
        "individuation": [
            "ì§€ê¸ˆì˜ í˜¼ë€ì€ ì§„ì§œ ë‹¹ì‹ ì´ ë˜ì–´ê°€ëŠ” ê³¼ì •ì¼ ìˆ˜ ìˆì–´ìš”.",
            "ìœµì€ ì´ê²ƒì„ 'ê°œì„±í™”'ë¼ê³  ë¶ˆë €ì–´ìš”. ë³¸ë˜ì˜ ìì‹ ì„ ì°¾ì•„ê°€ëŠ” ì—¬ì •ì´ì£ .",
            "ë¶ˆí¸í•¨ì€ ì¢…ì¢… ì„±ì¥ì˜ ì‹ í˜¸ì˜ˆìš”. ë‚˜ë¹„ê°€ ë˜ê¸° ì „ ì• ë²Œë ˆì˜ ë³€íƒœì²˜ëŸ¼ìš”."
        ],
        "meaning": [
            "ìœµì€ ë§í–ˆì–´ìš”. 'ì¸ìƒì˜ ì˜ë¯¸ëŠ” ë¬´ì—‡ì¸ê°€ê°€ ì•„ë‹ˆë¼, ë‹¹ì‹ ì´ ì‚¶ì— ì˜ë¯¸ë¥¼ ë¶€ì—¬í•˜ëŠ” ê²ƒ'ì´ë¼ê³ ìš”.",
            "ì–´ë‘  ì†ì—ì„œë„ ë¹›ì„ ì°¾ëŠ” ê²ƒ, ê·¸ê²ƒì´ ì¸ê°„ì˜ ìœ„ëŒ€í•¨ì´ì—ìš”.",
            "ì´ ê³ í†µì—ë„ ì˜ë¯¸ê°€ ìˆë‹¤ë©´, ê·¸ê²ƒì€ ë¬´ì—‡ì¼ê¹Œìš”?"
        ],
        "transformation": [
            "ëª¨ë“  ëì€ ìƒˆë¡œìš´ ì‹œì‘ì´ì—ìš”. ì£½ìŒ ì¹´ë“œì²˜ëŸ¼ìš”.",
            "ì—°ê¸ˆìˆ ì—ì„œ ê¸ˆì„ ë§Œë“¤ë ¤ë©´ ë¨¼ì € ëª¨ë“  ê²ƒì´ ë¶„í•´ë˜ì–´ì•¼ í•´ìš”. ì§€ê¸ˆì´ ê·¸ ê³¼ì •ì¼ ìˆ˜ ìˆì–´ìš”.",
            "ìƒì²˜ë°›ì€ ê³³ì—ì„œ ë¹›ì´ ë“¤ì–´ì˜¨ë‹¤ê³  í–ˆì–´ìš”. ë£¨ë¯¸ì˜ ë§ì²˜ëŸ¼ìš”."
        ]
    }

    # ë§ˆë¬´ë¦¬ ê²©ë ¤ ë©”ì‹œì§€
    CLOSING_ENCOURAGEMENTS = [
        "ì˜¤ëŠ˜ ìš©ê¸° ë‚´ì–´ ì´ì•¼ê¸°í•´ì£¼ì…”ì„œ ê°ì‚¬í•´ìš”. ë‹¹ì‹ ì€ ìƒê°ë³´ë‹¤ ê°•í•œ ì‚¬ëŒì´ì—ìš”.",
        "ì´ ëŒ€í™”ê°€ ì‘ì€ ì”¨ì•—ì´ ë˜ì–´ ë‹¹ì‹  ì•ˆì—ì„œ ìë¼ë‚˜ê¸¸ ë°”ë¼ìš”.",
        "ë‹¹ì‹ ì˜ ì—¬ì •ì„ ì‘ì›í•´ìš”. ì²œì²œíˆ, í•˜ì§€ë§Œ ê¾¸ì¤€íˆ ê°€ì‹œë©´ ë¼ìš”.",
        "ë‹¹ì‹  ì•ˆì— ë‹µì´ ìˆì–´ìš”. ê·¸ê²ƒì„ ë¯¿ì–´ì£¼ì„¸ìš”.",
        "ì˜¤ëŠ˜ ë‚˜ëˆˆ ì´ì•¼ê¸°ë¥¼ í’ˆê³ , ìì‹ ì„ ì¢€ ëŒë´ì£¼ì„¸ìš”.",
        "ë‹¹ì‹ ì€ ì‚¬ë‘ë°›ì„ ìê²©ì´ ìˆì–´ìš”. ê·¸ê²ƒì„ ìŠì§€ ë§ˆì„¸ìš”."
    ]

    @classmethod
    def get_empathy_message(cls, category: str = "pain_acknowledgment", **kwargs) -> str:
        """ê³µê° ë©”ì‹œì§€ ìƒì„±"""
        templates = cls.EMPATHY_TEMPLATES.get(category, cls.EMPATHY_TEMPLATES["validation"])
        message = random.choice(templates)
        # í…œí”Œë¦¿ ë³€ìˆ˜ ì¹˜í™˜
        for key, value in kwargs.items():
            message = message.replace(f"{{{key}}}", str(value))
        return message

    @classmethod
    def get_jungian_insight(cls, theme: str = "meaning") -> str:
        """ìœµ ì‹¬ë¦¬í•™ í†µì°° ë©”ì‹œì§€"""
        insights = cls.JUNGIAN_INSIGHTS.get(theme, cls.JUNGIAN_INSIGHTS["meaning"])
        return random.choice(insights)

    @classmethod
    def get_closing_encouragement(cls) -> str:
        """ë§ˆë¬´ë¦¬ ê²©ë ¤ ë©”ì‹œì§€"""
        return random.choice(cls.CLOSING_ENCOURAGEMENTS)

    @classmethod
    def create_emotional_response(cls,
                                   user_emotion: str,
                                   situation: str,
                                   theme: str = None) -> Dict[str, str]:
        """ê°ì • ìƒí™©ì— ë§ëŠ” ì¢…í•© ì‘ë‹µ ìƒì„±"""
        return {
            "empathy": cls.get_empathy_message("pain_acknowledgment", emotion=user_emotion),
            "validation": cls.get_empathy_message("validation"),
            "insight": cls.get_jungian_insight(theme) if theme else cls.get_jungian_insight("meaning"),
            "presence": cls.get_empathy_message("presence"),
            "hope": cls.get_empathy_message("hope"),
            "closing": cls.get_closing_encouragement()
        }


# ===============================================================
# COUNSELING SESSION MANAGER (ìƒë‹´ ì„¸ì…˜ ê´€ë¦¬)
# ===============================================================
class CounselingSession:
    """ìƒë‹´ ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬"""

    PHASES = {
        "opening": {
            "name": "ì—°ê²°ê³¼ íƒìƒ‰",
            "goals": ["ë¼í¬ í˜•ì„±", "ê³ ë¯¼ íŒŒì•…", "ì•ˆì „ í™•ì¸"],
            "duration_hint": "5-10ë¶„"
        },
        "divination_reading": {
            "name": "ë„êµ¬ë¥¼ í†µí•œ íƒìƒ‰",
            "goals": ["ì‚¬ì£¼/ì ì„±/íƒ€ë¡œ í•´ì„", "ì‹¬ë¦¬ì  ì—°ê²°"],
            "duration_hint": "15-20ë¶„"
        },
        "jungian_deepening": {
            "name": "ì‹¬ì¸µ íƒìƒ‰",
            "goals": ["ì›í˜• ì—°ê²°", "ê·¸ë¦¼ì íƒìƒ‰", "ì˜ë¯¸ ë°œê²¬"],
            "duration_hint": "15-25ë¶„"
        },
        "integration": {
            "name": "í†µí•©ê³¼ ì ìš©",
            "goals": ["í†µì°° ì •ë¦¬", "í–‰ë™ ê³„íš", "ìì› ì—°ê²°"],
            "duration_hint": "10-15ë¶„"
        },
        "closing": {
            "name": "ë§ˆë¬´ë¦¬",
            "goals": ["ìš”ì•½", "ê²©ë ¤", "í›„ì† ì•ˆë‚´"],
            "duration_hint": "5ë¶„"
        }
    }

    def __init__(self, session_id: str = None):
        self.session_id = session_id or datetime.now().strftime("%Y%m%d_%H%M%S")
        self.current_phase = "opening"
        self.history = []
        self.insights = []
        self.crisis_detected = False
        self.user_themes = []
        self.archetype_mentions = []

    def add_message(self, role: str, content: str, metadata: Dict = None):
        """ë©”ì‹œì§€ ì¶”ê°€"""
        self.history.append({
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat(),
            "phase": self.current_phase,
            "metadata": metadata or {}
        })

    def advance_phase(self) -> str:
        """ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰"""
        phase_order = list(self.PHASES.keys())
        current_idx = phase_order.index(self.current_phase)
        if current_idx < len(phase_order) - 1:
            self.current_phase = phase_order[current_idx + 1]
        return self.current_phase

    def get_phase_info(self) -> Dict:
        """í˜„ì¬ ë‹¨ê³„ ì •ë³´"""
        return self.PHASES.get(self.current_phase, {})

    def add_insight(self, insight: str, source: str = None):
        """í†µì°° ê¸°ë¡"""
        self.insights.append({
            "text": insight,
            "source": source,
            "phase": self.current_phase,
            "timestamp": datetime.now().isoformat()
        })

    def get_session_summary(self) -> Dict:
        """ì„¸ì…˜ ìš”ì•½"""
        return {
            "session_id": self.session_id,
            "phases_completed": self.current_phase,
            "message_count": len(self.history),
            "insights_count": len(self.insights),
            "themes": self.user_themes,
            "crisis_detected": self.crisis_detected
        }


# ===============================================================
# JUNGIAN COUNSELING ENGINE (í†µí•© ìƒë‹´ ì—”ì§„)
# ===============================================================
class JungianCounselingEngine:
    """
    ìœµ ì‹¬ë¦¬í•™ ê¸°ë°˜ í†µí•© ìƒë‹´ ì—”ì§„

    "ë‹¹ì‹ ì€ ìœµ ì‹¬ë¦¬í•™ì— ê¸°ë°˜í•œ í†µí•© ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.
    ì‚¬ì£¼, ì ì„±ìˆ , íƒ€ë¡œë¥¼ ì‹¬ë¦¬í•™ì  ë„êµ¬ë¡œ í™œìš©í•˜ì—¬
    ë‚´ë‹´ìì˜ ìê¸° ì´í•´ë¥¼ ë•ìŠµë‹ˆë‹¤."
    """

    SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ìœµ ì‹¬ë¦¬í•™ì— ê¸°ë°˜í•œ í†µí•© ì‹¬ë¦¬ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.
ì‚¬ì£¼, ì ì„±ìˆ , íƒ€ë¡œë¥¼ ì‹¬ë¦¬í•™ì  ë„êµ¬ë¡œ í™œìš©í•˜ì—¬ ë‚´ë‹´ìì˜ ìê¸° ì´í•´ì™€ ì„±ì¥ì„ ë•ìŠµë‹ˆë‹¤.

## í•µì‹¬ ì›ì¹™
1. ë‹µì„ ì£¼ì§€ ë§ê³  ì§ˆë¬¸ìœ¼ë¡œ ì´ëŒì–´ë¼
2. ì¦ìƒì„ ì ì´ ì•„ë‹Œ ë©”ì‹ ì €ë¡œ ë³´ë¼
3. ëª¨ë“  ì–´ë ¤ì›€ì€ ê°œì„±í™”(individuation)ì˜ ê¸°íšŒë‹¤
4. ë‚´ë‹´ì ì•ˆì— ë‹µì´ ìˆë‹¤
5. ë„êµ¬ëŠ” ê±°ìš¸ì´ì§€ ì˜ˆì–¸ì„œê°€ ì•„ë‹ˆë‹¤

## ìƒë‹´ ìŠ¤íƒ€ì¼
- ë”°ëœ»í•˜ì§€ë§Œ ë¶„ì„ì 
- ê³µê°í•˜ì§€ë§Œ ë„ì „ì 
- ì§€ì§€í•˜ì§€ë§Œ ì§ë©´ ìœ ë„
- ì „ë¬¸ì ì´ì§€ë§Œ ì´í•´í•˜ê¸° ì‰½ê²Œ
- ê°ë™ì„ ì¤„ ìˆ˜ ìˆëŠ” ê¹Šì´

## ê¸ˆê¸°ì‚¬í•­
- ìš´ëª…ë¡ ì  ì˜ˆì–¸ ê¸ˆì§€
- ë‘ë ¤ì›€ ì¡°ì¥ ê¸ˆì§€
- ì¼ë°©ì  ì¡°ì–¸ ê¸ˆì§€
- ìœ„ê¸° ìƒí™© ì‹œ ì „ë¬¸ê°€ ì—°ê³„ í•„ìˆ˜

## ìœµ ì‹¬ë¦¬í•™ í†µí•©
- ì›í˜•(archetype) ì–¸ì–´ë¡œ ê²½í—˜ ì¬êµ¬ì„±
- ê·¸ë¦¼ì(shadow) ì‘ì—… ì ê·¹ í™œìš©
- ê°œì„±í™” ì—¬ì • ê´€ì  ìœ ì§€
- ì—°ê¸ˆìˆ ì  ë³€í™˜ ë¹„ìœ  ì‚¬ìš©

## ë„êµ¬ í•´ì„ ì›ì¹™
- ì‚¬ì£¼: íƒ€ê³ ë‚œ ì—ë„ˆì§€ íŒ¨í„´, ì ì¬ë ¥ì˜ ì§€ë„
- ì ì„±ìˆ : í˜„ì¬ íë¥´ëŠ” ì—ë„ˆì§€, ìš°ì£¼ì™€ì˜ ê³µëª…
- íƒ€ë¡œ: ë¬´ì˜ì‹ì˜ ë©”ì‹œì§€, í˜„ì¬ í•„ìš”í•œ í†µì°°

## ê°ë™ì„ ì£¼ëŠ” ìƒë‹´
- ë‚´ë‹´ìì˜ ê³ í†µì„ ì§„ì •ìœ¼ë¡œ ì¸ì •í•˜ë¼
- ì‘ì€ ìš©ê¸°ë„ í¬ê²Œ ì¹­ì°¬í•˜ë¼
- í¬ë§ì€ ê°•ìš”í•˜ì§€ ë§ê³  í•¨ê»˜ ë°œê²¬í•˜ë¼
- ì´ë³„ ì‹œ ë”°ëœ»í•œ ê²©ë ¤ë¥¼ ìŠì§€ ë§ˆë¼"""

    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        self.client = None
        self.model_name = "gpt-4o-mini"

        if OPENAI_AVAILABLE and self.api_key:
            try:
                import httpx
                self.client = OpenAI(
                    api_key=self.api_key,
                    timeout=httpx.Timeout(60.0, connect=10.0)
                )
                print("[JungianCounselingEngine] OpenAI client initialized")
            except Exception as e:
                print(f"[JungianCounselingEngine] Failed to initialize: {e}")

        # í•˜ìœ„ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.crisis_detector = CrisisDetector()
        self.question_generator = TherapeuticQuestionGenerator()
        self.message_generator = EmotionalMessageGenerator()
        self.sessions: Dict[str, CounselingSession] = {}

        # JungianRAG í†µí•© (ì‹œë§¨í‹± ê²€ìƒ‰ + RuleEngine)
        self.jungian_rag = get_jungian_rag()

    def create_session(self) -> CounselingSession:
        """ìƒˆ ìƒë‹´ ì„¸ì…˜ ìƒì„±"""
        session = CounselingSession()
        self.sessions[session.session_id] = session
        return session

    def get_session(self, session_id: str) -> Optional[CounselingSession]:
        """ì„¸ì…˜ ì¡°íšŒ"""
        return self.sessions.get(session_id)

    def process_message(self,
                        user_message: str,
                        session: CounselingSession = None,
                        divination_context: Dict = None) -> Dict:
        """
        ì‚¬ìš©ì ë©”ì‹œì§€ ì²˜ë¦¬ ë° ì‘ë‹µ ìƒì„±

        Args:
            user_message: ì‚¬ìš©ì ì…ë ¥
            session: ìƒë‹´ ì„¸ì…˜ (ì—†ìœ¼ë©´ ìƒì„±)
            divination_context: ì‚¬ì£¼/ì ì„±/íƒ€ë¡œ í•´ì„ ì»¨í…ìŠ¤íŠ¸

        Returns:
            ì‘ë‹µ ë”•ì…”ë„ˆë¦¬
        """
        if session is None:
            session = self.create_session()

        # 1. ìœ„ê¸° ê°ì§€
        crisis_check = self.crisis_detector.detect_crisis(user_message)

        if crisis_check["is_crisis"]:
            session.crisis_detected = True
            crisis_response = self.crisis_detector.get_crisis_response(
                crisis_check["max_severity"]
            )

            if crisis_check["requires_immediate_action"]:
                # ìœ„ê¸° ìƒí™© - ì¦‰ê° ì•ˆì „ ì‘ë‹µ
                session.add_message("user", user_message, {"crisis": True})
                response_text = (
                    f"{crisis_response.get('immediate_message', '')}\n\n"
                    f"{crisis_response.get('follow_up', '')}"
                )
                if crisis_response.get('closing'):
                    response_text += f"\n\n{crisis_response['closing']}"

                session.add_message("assistant", response_text, {"crisis_response": True})

                return {
                    "response": response_text,
                    "crisis_detected": True,
                    "severity": crisis_check["max_severity"],
                    "should_continue": crisis_response.get("should_continue_session", False),
                    "session_id": session.session_id
                }

        # 2. ì¼ë°˜ ìƒë‹´ ì²˜ë¦¬
        session.add_message("user", user_message)

        # 3. GPTë¡œ ì‘ë‹µ ìƒì„±
        if self.client:
            response_text = self._generate_response(session, divination_context)
        else:
            # í´ë°±: í…œí”Œë¦¿ ê¸°ë°˜ ì‘ë‹µ
            response_text = self._generate_fallback_response(user_message, session)

        session.add_message("assistant", response_text)

        return {
            "response": response_text,
            "crisis_detected": False,
            "session_id": session.session_id,
            "phase": session.current_phase,
            "should_continue": True
        }

    def _generate_response(self, session: CounselingSession, divination_context: Dict = None) -> str:
        """GPT ê¸°ë°˜ ì‘ë‹µ ìƒì„±"""
        messages = [{"role": "system", "content": self.SYSTEM_PROMPT}]

        # ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ì¶”ê°€
        for msg in session.history[-10:]:  # ìµœê·¼ 10ê°œ ë©”ì‹œì§€
            messages.append({
                "role": msg["role"],
                "content": msg["content"]
            })

        # ì ìˆ  ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        if divination_context:
            context_msg = self._format_divination_context(divination_context)
            messages.append({
                "role": "system",
                "content": f"[ì ìˆ  í•´ì„ ì»¨í…ìŠ¤íŠ¸]\n{context_msg}"
            })

        # í˜„ì¬ ë‹¨ê³„ ì•ˆë‚´
        phase_info = session.get_phase_info()
        messages.append({
            "role": "system",
            "content": f"[í˜„ì¬ ìƒë‹´ ë‹¨ê³„: {phase_info.get('name', '')}]\nëª©í‘œ: {', '.join(phase_info.get('goals', []))}"
        })

        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=0.8,
                max_tokens=1500,
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”. ({str(e)})"

    def _generate_fallback_response(self, user_message: str, session: CounselingSession) -> str:
        """í…œí”Œë¦¿ ê¸°ë°˜ í´ë°± ì‘ë‹µ"""
        empathy = self.message_generator.get_empathy_message("presence")
        question = random.choice(self.question_generator.get_deepening_questions())

        return f"{empathy}\n\n{question}"

    def _format_divination_context(self, context: Dict) -> str:
        """ì ìˆ  ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…"""
        parts = []

        if context.get("saju"):
            parts.append(f"[ì‚¬ì£¼ ë¶„ì„]\n{context['saju']}")
        if context.get("astrology"):
            parts.append(f"[ì ì„±ìˆ  ë¶„ì„]\n{context['astrology']}")
        if context.get("tarot"):
            parts.append(f"[íƒ€ë¡œ ë¦¬ë”©]\n{context['tarot']}")

        return "\n\n".join(parts)

    def get_therapeutic_question(self,
                                  theme: str = None,
                                  archetype: str = None,
                                  question_type: str = "deepening") -> str:
        """ì¹˜ë£Œì  ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°"""
        if archetype:
            return self.question_generator.get_question_for_archetype(archetype)
        elif theme:
            return self.question_generator.get_question_for_theme(theme)
        else:
            question_map = {
                "deepening": self.question_generator.get_deepening_questions,
                "challenging": self.question_generator.get_challenging_questions,
                "action": self.question_generator.get_action_questions,
                "shadow": self.question_generator.get_shadow_questions,
                "meaning": self.question_generator.get_meaning_questions
            }
            questions = question_map.get(question_type, self.question_generator.get_deepening_questions)()
            return random.choice(questions)

    def get_emotional_response(self, emotion: str, situation: str = "") -> Dict:
        """ê°ì •ì  ì‘ë‹µ ìƒì„±"""
        return self.message_generator.create_emotional_response(emotion, situation)

    def get_session_closing(self, session: CounselingSession) -> str:
        """ì„¸ì…˜ ë§ˆë¬´ë¦¬ ë©”ì‹œì§€"""
        closing = self.message_generator.get_closing_encouragement()

        # ì„¸ì…˜ í†µì°° ìš”ì•½
        if session.insights:
            insights_text = "\n".join([f"- {i['text']}" for i in session.insights[:3]])
            return f"ì˜¤ëŠ˜ ë‚˜ëˆˆ ì´ì•¼ê¸°ë¥¼ ì •ë¦¬í•´ë³¼ê²Œìš”:\n{insights_text}\n\n{closing}"

        return closing

    def get_enhanced_context(self, user_message: str, saju_data: Dict = None, astro_data: Dict = None) -> Dict:
        """
        í†µí•© ìœµ ì‹¬ë¦¬í•™ ì»¨í…ìŠ¤íŠ¸ ìƒì„± (ëª¨ë“  ìœµ ë°ì´í„° í™œìš©)

        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            saju_data: ì‚¬ì£¼ ë¶„ì„ ë°ì´í„°
            astro_data: ì ì„±ìˆ  ë¶„ì„ ë°ì´í„°

        Returns:
            í†µí•©ëœ ìœµ ì‹¬ë¦¬í•™ ì»¨í…ìŠ¤íŠ¸
        """
        context = {}

        # 1. ì‹¬ë¦¬ ìœ í˜• ë¶„ì„
        if saju_data:
            psych_type = self.question_generator.get_psychological_type_insight(saju_data)
            if psych_type:
                context["psychological_type"] = psych_type

        # 2. ì—°ê¸ˆìˆ ì  ë³€í™˜ ë‹¨ê³„
        alchemy_stage = self.question_generator.get_alchemy_stage(user_message)
        if alchemy_stage:
            context["alchemy_stage"] = alchemy_stage

        # 3. êµì°¨ ì‹œìŠ¤í…œ í†µì°° (ì‚¬ì£¼Ã—ì ì„±)
        if saju_data or astro_data:
            cross_insight = self.question_generator.get_cross_system_insight(
                saju_data or {}, astro_data or {}
            )
            if cross_insight.get("insights"):
                context["cross_system"] = cross_insight

        # 4. í…Œë§ˆ ê¸°ë°˜ ì‹œë‚˜ë¦¬ì˜¤ ê°€ì´ë“œ
        theme = self._detect_theme(user_message)
        if theme:
            scenario = self.question_generator.get_scenario_guidance(theme)
            if scenario:
                context["scenario_guidance"] = scenario
                context["detected_theme"] = theme

        # 5. ì ì ˆí•œ ì¹˜ë£Œì  ì§ˆë¬¸ ì„ íƒ
        context["therapeutic_question"] = self.get_therapeutic_question(theme=theme)

        # 6. JungianRAG ì‹œë§¨í‹± ê²€ìƒ‰ (v2.0 ì¶”ê°€)
        if self.jungian_rag:
            rag_context = {
                "theme": theme,
                "saju": saju_data,
                "astro": astro_data
            }
            intervention = self.jungian_rag.get_therapeutic_intervention(user_message, rag_context)

            # ì‹œë§¨í‹± ê²€ìƒ‰ìœ¼ë¡œ ì°¾ì€ ì§ˆë¬¸ë“¤ ì¶”ê°€
            if intervention.get("recommended_questions"):
                context["rag_questions"] = intervention["recommended_questions"][:3]

            # ì‹œë§¨í‹± ê²€ìƒ‰ìœ¼ë¡œ ì°¾ì€ í†µì°° ì¶”ê°€
            if intervention.get("insights"):
                context["rag_insights"] = intervention["insights"][:3]

            # RuleEngine ë§¤ì¹­ ê²°ê³¼ ì¶”ê°€
            if intervention.get("rule_matches"):
                context["rule_matches"] = intervention["rule_matches"][:5]

        return context

    def _detect_theme(self, text: str) -> Optional[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ìƒë‹´ í…Œë§ˆ ê°ì§€"""
        theme_keywords = {
            "relationship": ["ê´€ê³„", "ì—°ì• ", "ê²°í˜¼", "ì´ë³„", "ì‚¬ë‘", "ì§", "ì†Œìš¸ë©”ì´íŠ¸"],
            "career": ["ì§ì¥", "ì¼", "ì»¤ë¦¬ì–´", "ì·¨ì—…", "ì´ì§", "ì‚¬ì—…", "ëˆ", "ì¬ì •"],
            "family": ["ê°€ì¡±", "ë¶€ëª¨", "ìë…€", "í˜•ì œ", "ì§‘ì•ˆ", "ì›ê°€ì¡±"],
            "identity": ["ë‚˜", "ìì•„", "ì •ì²´ì„±", "ëˆ„êµ¬", "ì˜ë¯¸", "ëª©ì "],
            "health": ["ê±´ê°•", "ëª¸", "ë³‘", "ì•„í”„", "ìŠ¤íŠ¸ë ˆìŠ¤", "ë¶ˆì•ˆ", "ìš°ìš¸"],
            "spiritual": ["ì˜í˜¼", "ì˜ì ", "ì¢…êµ", "ëª…ìƒ", "ê¿ˆ", "ì§ê´€"],
        }

        text_lower = text.lower()
        for theme, keywords in theme_keywords.items():
            if any(kw in text_lower for kw in keywords):
                return theme
        return None

    def process_with_jung_context(self,
                                   user_message: str,
                                   session: CounselingSession = None,
                                   saju_data: Dict = None,
                                   astro_data: Dict = None,
                                   tarot_data: Dict = None) -> Dict:
        """
        ìœµ ì‹¬ë¦¬í•™ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì™„ì „íˆ í†µí•©í•œ ìƒë‹´ ì²˜ë¦¬

        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            session: ìƒë‹´ ì„¸ì…˜
            saju_data: ì‚¬ì£¼ ë¶„ì„ ê²°ê³¼
            astro_data: ì ì„±ìˆ  ë¶„ì„ ê²°ê³¼
            tarot_data: íƒ€ë¡œ ë¦¬ë”© ê²°ê³¼

        Returns:
            ìœµ í†µí•© ì‘ë‹µ
        """
        if session is None:
            session = self.create_session()

        # 1. ìœ„ê¸° ê°ì§€ (í•­ìƒ ë¨¼ì €)
        crisis_check = self.crisis_detector.detect_crisis(user_message)
        if crisis_check["requires_immediate_action"]:
            return self.process_message(user_message, session)

        # 2. í†µí•© ìœµ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        jung_context = self.get_enhanced_context(user_message, saju_data, astro_data)

        # 3. ì ìˆ  ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        divination_context = {}
        if saju_data:
            divination_context["saju"] = saju_data
        if astro_data:
            divination_context["astrology"] = astro_data
        if tarot_data:
            divination_context["tarot"] = tarot_data

        # 4. GPTì— ìœµ ì»¨í…ìŠ¤íŠ¸ í¬í•¨í•˜ì—¬ ì‘ë‹µ ìƒì„±
        session.add_message("user", user_message)

        if self.client:
            response_text = self._generate_jung_enhanced_response(
                session, divination_context, jung_context
            )
        else:
            response_text = self._generate_fallback_response(user_message, session)

        session.add_message("assistant", response_text)

        return {
            "response": response_text,
            "jung_context": jung_context,
            "session_id": session.session_id,
            "phase": session.current_phase,
            "crisis_detected": False,
            "should_continue": True,
        }

    def _generate_jung_enhanced_response(self,
                                          session: CounselingSession,
                                          divination_context: Dict,
                                          jung_context: Dict) -> str:
        """ìœµ ì»¨í…ìŠ¤íŠ¸ê°€ ê°•í™”ëœ GPT ì‘ë‹µ ìƒì„±"""
        # ê¸°ë³¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        enhanced_prompt = self.SYSTEM_PROMPT

        # ìœµ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        if jung_context:
            jung_additions = []

            if jung_context.get("psychological_type"):
                ptype = jung_context["psychological_type"]
                jung_additions.append(f"[ì‹¬ë¦¬ ìœ í˜•] {ptype.get('name_ko', ptype.get('name', ''))}: {ptype.get('description', '')}")

            if jung_context.get("alchemy_stage"):
                stage = jung_context["alchemy_stage"]
                jung_additions.append(f"[ì—°ê¸ˆìˆ  ë‹¨ê³„] {stage.get('name_ko', stage.get('name', ''))}: {stage.get('therapeutic_focus', '')}")

            if jung_context.get("scenario_guidance"):
                scenario = jung_context["scenario_guidance"]
                jung_additions.append(f"[ìƒë‹´ ì‹œë‚˜ë¦¬ì˜¤] {scenario.get('approach', '')}")

            # RAG ì‹œë§¨í‹± ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€ (v2.0)
            if jung_context.get("rag_questions"):
                jung_additions.append(f"[ì¶”ì²œ ì§ˆë¬¸]\n- " + "\n- ".join(jung_context["rag_questions"][:2]))

            if jung_context.get("rag_insights"):
                jung_additions.append(f"[ì¹˜ë£Œì  í†µì°°]\n- " + "\n- ".join(jung_context["rag_insights"][:2]))

            if jung_context.get("rule_matches"):
                jung_additions.append(f"[ê·œì¹™ ë§¤ì¹­]\n- " + "\n- ".join(jung_context["rule_matches"][:2]))

            if jung_additions:
                enhanced_prompt += f"\n\n## ìœµ ì‹¬ë¦¬í•™ ì»¨í…ìŠ¤íŠ¸\n" + "\n".join(jung_additions)

        messages = [{"role": "system", "content": enhanced_prompt}]

        # ì„¸ì…˜ íˆìŠ¤í† ë¦¬
        for msg in session.history[-10:]:
            messages.append({"role": msg["role"], "content": msg["content"]})

        # ì ìˆ  ì»¨í…ìŠ¤íŠ¸
        if divination_context:
            context_msg = self._format_divination_context(divination_context)
            messages.append({"role": "system", "content": f"[ì ìˆ  í•´ì„ ì»¨í…ìŠ¤íŠ¸]\n{context_msg}"})

        # í˜„ì¬ ë‹¨ê³„
        phase_info = session.get_phase_info()
        messages.append({
            "role": "system",
            "content": f"[í˜„ì¬ ìƒë‹´ ë‹¨ê³„: {phase_info.get('name', '')}]\nëª©í‘œ: {', '.join(phase_info.get('goals', []))}"
        })

        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=0.8,
                max_tokens=1500,
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”. ({str(e)})"

    def health_check(self) -> Tuple[bool, str]:
        """ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
        status_parts = []

        # OpenAI ì—°ê²°
        if self.client:
            status_parts.append("OpenAI: Connected")
        else:
            status_parts.append("OpenAI: Not connected (fallback mode)")

        # ë°ì´í„° ë¡œë“œ ìƒíƒœ - ëª¨ë“  ìœµ ë°ì´í„° ì²´í¬
        qg = self.question_generator
        jung_data_loaded = sum([
            1 if qg.therapeutic_data else 0,
            1 if qg.archetypes_data else 0,
            1 if qg.prompts_data else 0,
            1 if qg.psychological_types_data else 0,
            1 if qg.alchemy_data else 0,
            1 if qg.cross_analysis_data else 0,
            1 if qg.scenarios_data else 0,
            1 if qg.integrated_data else 0,
            1 if qg.personality_data else 0,
            1 if qg.expanded_data else 0,
        ])
        status_parts.append(f"Jung data: {jung_data_loaded}/10 files loaded")

        # JungianRAG ìƒíƒœ (v2.0)
        if self.jungian_rag:
            rag_healthy, rag_status = self.jungian_rag.health_check()
            status_parts.append(f"RAG: {rag_status}")
        else:
            status_parts.append("RAG: Not initialized")

        is_healthy = self.client is not None and jung_data_loaded >= 3
        return is_healthy, " | ".join(status_parts)


# ===============================================================
# SINGLETON & FACTORY
# ===============================================================
_counseling_engine = None


def get_counseling_engine() -> JungianCounselingEngine:
    """ì‹±ê¸€í†¤ ìƒë‹´ ì—”ì§„ ê°€ì ¸ì˜¤ê¸°"""
    global _counseling_engine
    if _counseling_engine is None:
        _counseling_engine = JungianCounselingEngine()
    return _counseling_engine


# ===============================================================
# TEST
# ===============================================================
if __name__ == "__main__":
    import sys
    if sys.platform == 'win32':
        sys.stdout.reconfigure(encoding='utf-8', errors='replace')

    print("=" * 70)
    print("[JUNGIAN COUNSELING ENGINE TEST]")
    print("=" * 70)

    engine = get_counseling_engine()

    # Health check
    is_healthy, status = engine.health_check()
    print(f"\n[Health Check] {status}")

    # Crisis detection test
    print("\n[Crisis Detection Test]")
    test_messages = [
        "ìš”ì¦˜ ë„ˆë¬´ í˜ë“¤ì–´ìš”",
        "ì£½ê³  ì‹¶ì–´ìš”",
        "í¬ë§ì´ ì—†ì–´ìš”",
        "ê·¸ ì‚¬ëŒì´ ë„ˆë¬´ ì‹«ì–´ìš”"
    ]

    for msg in test_messages:
        result = CrisisDetector.detect_crisis(msg)
        print(f"  '{msg[:20]}...' -> Crisis: {result['is_crisis']}, Severity: {result['max_severity']}")

    # Therapeutic questions test
    print("\n[Therapeutic Questions]")
    print(f"  Shadow: {engine.get_therapeutic_question(question_type='shadow')}")
    print(f"  Deepening: {engine.get_therapeutic_question(question_type='deepening')}")
    print(f"  For Love theme: {engine.get_therapeutic_question(theme='love')}")

    # Emotional messages test
    print("\n[Emotional Messages]")
    response = engine.get_emotional_response("ìŠ¬í””", "ì´ë³„")
    print(f"  Empathy: {response['empathy']}")
    print(f"  Hope: {response['hope']}")

    # Session test
    print("\n[Session Test]")
    session = engine.create_session()
    print(f"  Session created: {session.session_id}")

    # Process message
    if engine.client:
        print("\n[Processing Message...]")
        result = engine.process_message("ìš”ì¦˜ ì¸ê°„ê´€ê³„ê°€ ë„ˆë¬´ í˜ë“¤ì–´ìš”. ì™œ ì´ë ‡ê²Œ ì™¸ë¡œìš´ì§€ ëª¨ë¥´ê² ì–´ìš”.", session)
        print(f"  Response preview: {result['response'][:200]}...")

    print("\n" + "=" * 70)
    print("[TEST COMPLETE]")
    print("=" * 70)
