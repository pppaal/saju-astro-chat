import sys
import os
import json

# Load environment variables from backend_ai/.env file (explicit path with override)
from dotenv import load_dotenv
_backend_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
load_dotenv(os.path.join(_backend_root, ".env"), override=True)

# Add project root to Python path for standalone execution
_project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
if _project_root not in sys.path:
    sys.path.insert(0, _project_root)

import logging
import time
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
from pathlib import Path
from typing import Dict, Optional, Tuple
from uuid import uuid4

from flask import Flask, jsonify, g, request, Response, stream_with_context
from flask_cors import CORS
from flask_compress import Compress

from backend_ai.app.astro_parser import calculate_astrology_data
from backend_ai.app.fusion_logic import interpret_with_ai
from backend_ai.app.saju_parser import calculate_saju_data
from backend_ai.app.dream_logic import interpret_dream
from backend_ai.app.redis_cache import get_cache
# Lazy import fusion_generate to avoid loading SentenceTransformer on startup
# This prevents OOM on Railway free tier (512MB limit)
_fusion_generate_module = None

def _get_fusion_generate():
    """Lazy load fusion_generate module to save memory."""
    global _fusion_generate_module
    if _fusion_generate_module is None:
        from backend_ai.model import fusion_generate as _fg
        _fusion_generate_module = _fg
    return _fusion_generate_module

def _generate_with_gpt4(*args, **kwargs):
    """Lazy wrapper for _generate_with_gpt4."""
    return _get_fusion_generate()._generate_with_gpt4(*args, **kwargs)

def refine_with_gpt5mini(*args, **kwargs):
    """Lazy wrapper for refine_with_gpt5mini."""
    return _get_fusion_generate().refine_with_gpt5mini(*args, **kwargs)

from backend_ai.app.performance_optimizer import (
    track_performance,
    get_performance_stats,
    get_cache_health,
    suggest_optimizations,
)

# Gemini-level features
try:
    from backend_ai.app.realtime_astro import get_current_transits, get_transit_interpretation
    HAS_REALTIME = True
except ImportError:
    HAS_REALTIME = False

try:
    from backend_ai.app.chart_generator import (
        generate_saju_table_svg,
        generate_natal_chart_svg,
        generate_full_chart_html,
        svg_to_base64,
    )
    HAS_CHARTS = True
except ImportError:
    HAS_CHARTS = False

try:
    from backend_ai.app.user_memory import get_user_memory, generate_user_id
    HAS_USER_MEMORY = True
except ImportError:
    HAS_USER_MEMORY = False

# I-Ching RAG - Lazy loaded to avoid OOM (uses saju_astro_rag -> SentenceTransformer)
HAS_ICHING = True  # Assume available, will fail gracefully if not
_iching_rag_module = None

def _get_iching_rag():
    """Lazy load iching_rag module."""
    global _iching_rag_module, HAS_ICHING
    if _iching_rag_module is None:
        try:
            from backend_ai.app import iching_rag as _ir
            _iching_rag_module = _ir
        except ImportError:
            HAS_ICHING = False
            print("[app.py] I-Ching RAG not available (lazy load)")
            return None
    return _iching_rag_module

def cast_hexagram(*args, **kwargs):
    m = _get_iching_rag()
    return m.cast_hexagram(*args, **kwargs) if m else None

def get_hexagram_interpretation(*args, **kwargs):
    m = _get_iching_rag()
    return m.get_hexagram_interpretation(*args, **kwargs) if m else None

def perform_iching_reading(*args, **kwargs):
    m = _get_iching_rag()
    return m.perform_iching_reading(*args, **kwargs) if m else None

def search_iching_wisdom(*args, **kwargs):
    m = _get_iching_rag()
    return m.search_iching_wisdom(*args, **kwargs) if m else None

def get_all_hexagrams_summary(*args, **kwargs):
    m = _get_iching_rag()
    return m.get_all_hexagrams_summary(*args, **kwargs) if m else None

# Persona Embeddings - Lazy loaded (uses SentenceTransformer)
HAS_PERSONA_EMBED = True  # Assume available
_persona_embed_module = None

def _get_persona_embed_module():
    global _persona_embed_module, HAS_PERSONA_EMBED
    if _persona_embed_module is None:
        try:
            from backend_ai.app import persona_embeddings as _pe
            _persona_embed_module = _pe
        except ImportError:
            HAS_PERSONA_EMBED = False
            return None
    return _persona_embed_module

def get_persona_embed_rag(*args, **kwargs):
    m = _get_persona_embed_module()
    return m.get_persona_embed_rag(*args, **kwargs) if m else None

try:
    # This import is safe (no SentenceTransformer dependency at module level)
    pass  # Placeholder - persona_embeddings now lazy loaded above
    HAS_PERSONA_EMBED = True  # Already set above
except ImportError:
    HAS_PERSONA_EMBED = False

# Tarot Hybrid RAG - Lazy loaded (uses tarot_rag -> SentenceTransformer)
HAS_TAROT = True  # Assume available
_tarot_hybrid_rag_module = None

def _get_tarot_hybrid_rag_module():
    global _tarot_hybrid_rag_module, HAS_TAROT
    if _tarot_hybrid_rag_module is None:
        try:
            from backend_ai.app import tarot_hybrid_rag as _thr
            _tarot_hybrid_rag_module = _thr
        except ImportError:
            HAS_TAROT = False
            return None
    return _tarot_hybrid_rag_module

def get_tarot_hybrid_rag(*args, **kwargs):
    m = _get_tarot_hybrid_rag_module()
    return m.get_tarot_hybrid_rag(*args, **kwargs) if m else None

# RLHF Feedback Learning System
try:
    from backend_ai.app.feedback_learning import get_feedback_learning
    HAS_RLHF = True
except ImportError:
    HAS_RLHF = False

# Badge System
try:
    from backend_ai.app.badge_system import get_badge_system, get_midjourney_prompts
    HAS_BADGES = True
except ImportError:
    HAS_BADGES = False

# Domain RAG - Lazy loaded (uses SentenceTransformer)
HAS_DOMAIN_RAG = True  # Assume available
DOMAIN_RAG_DOMAINS = []  # Will be populated on first access
_domain_rag_module = None

def _get_domain_rag_module():
    global _domain_rag_module, HAS_DOMAIN_RAG, DOMAIN_RAG_DOMAINS
    if _domain_rag_module is None:
        try:
            from backend_ai.app import domain_rag as _dr
            _domain_rag_module = _dr
            DOMAIN_RAG_DOMAINS = _dr.DOMAINS
        except ImportError:
            HAS_DOMAIN_RAG = False
            print("[app.py] DomainRAG not available (lazy load)")
            return None
    return _domain_rag_module

def get_domain_rag(*args, **kwargs):
    m = _get_domain_rag_module()
    return m.get_domain_rag(*args, **kwargs) if m else None

# Compatibility (Saju + Astrology fusion) - Lazy loaded (uses saju_astro_rag)
HAS_COMPATIBILITY = True  # Assume available
_compatibility_logic_module = None

def _get_compatibility_logic():
    global _compatibility_logic_module, HAS_COMPATIBILITY
    if _compatibility_logic_module is None:
        try:
            from backend_ai.app import compatibility_logic as _cl
            _compatibility_logic_module = _cl
        except ImportError:
            HAS_COMPATIBILITY = False
            print("[app.py] Compatibility logic not available (lazy load)")
            return None
    return _compatibility_logic_module

def interpret_compatibility(*args, **kwargs):
    m = _get_compatibility_logic()
    return m.interpret_compatibility(*args, **kwargs) if m else None

def interpret_compatibility_group(*args, **kwargs):
    m = _get_compatibility_logic()
    return m.interpret_compatibility_group(*args, **kwargs) if m else None

# Hybrid RAG (Vector + BM25 + Graph + rerank) - Lazy loaded
HAS_HYBRID_RAG = True  # Assume available
_hybrid_rag_module = None

def _get_hybrid_rag_module():
    global _hybrid_rag_module, HAS_HYBRID_RAG
    if _hybrid_rag_module is None:
        try:
            from backend_ai.app import hybrid_rag as _hr
            _hybrid_rag_module = _hr
        except ImportError:
            HAS_HYBRID_RAG = False
            print("[app.py] Hybrid RAG not available (lazy load)")
            return None
    return _hybrid_rag_module

def hybrid_search(*args, **kwargs):
    m = _get_hybrid_rag_module()
    return m.hybrid_search(*args, **kwargs) if m else None

def build_rag_context(*args, **kwargs):
    m = _get_hybrid_rag_module()
    return m.build_rag_context(*args, **kwargs) if m else None

# Agentic RAG System (Next Level Features) - Lazy loaded to avoid OOM
# Import deferred to first use to prevent loading SentenceTransformer on startup
HAS_AGENTIC = True  # Assume available, will fail gracefully if not
_agentic_rag_module = None

def _get_agentic_rag():
    """Lazy load agentic_rag module."""
    global _agentic_rag_module, HAS_AGENTIC
    if _agentic_rag_module is None:
        try:
            from backend_ai.app import agentic_rag as _ar
            _agentic_rag_module = _ar
        except ImportError:
            HAS_AGENTIC = False
            print("[app.py] Agentic RAG not available (lazy load)")
            return None
    return _agentic_rag_module

def agentic_query(*args, **kwargs):
    """Lazy wrapper for agentic_query."""
    m = _get_agentic_rag()
    return m.agentic_query(*args, **kwargs) if m else None

def get_agent_orchestrator(*args, **kwargs):
    """Lazy wrapper for get_agent_orchestrator."""
    m = _get_agentic_rag()
    return m.get_agent_orchestrator(*args, **kwargs) if m else None

def get_entity_extractor(*args, **kwargs):
    """Lazy wrapper for get_entity_extractor."""
    m = _get_agentic_rag()
    return m.get_entity_extractor(*args, **kwargs) if m else None

def get_deep_traversal(*args, **kwargs):
    """Lazy wrapper for get_deep_traversal."""
    m = _get_agentic_rag()
    return m.get_deep_traversal(*args, **kwargs) if m else None

# Classes are accessed as properties
EntityExtractor = property(lambda self: _get_agentic_rag().EntityExtractor if _get_agentic_rag() else None)
DeepGraphTraversal = property(lambda self: _get_agentic_rag().DeepGraphTraversal if _get_agentic_rag() else None)
AgentOrchestrator = property(lambda self: _get_agentic_rag().AgentOrchestrator if _get_agentic_rag() else None)

# Jungian Counseling Engine - Lazy loaded (uses SentenceTransformer)
HAS_COUNSELING = True  # Assume available
_counseling_engine_module = None

def _get_counseling_engine_module():
    global _counseling_engine_module, HAS_COUNSELING
    if _counseling_engine_module is None:
        try:
            from backend_ai.app import counseling_engine as _ce
            _counseling_engine_module = _ce
        except ImportError:
            HAS_COUNSELING = False
            print("[app.py] Counseling engine not available (lazy load)")
            return None
    return _counseling_engine_module

def get_counseling_engine(*args, **kwargs):
    m = _get_counseling_engine_module()
    return m.get_counseling_engine(*args, **kwargs) if m else None

CrisisDetector = property(lambda self: _get_counseling_engine_module().CrisisDetector if _get_counseling_engine_module() else None)

# Prediction Engine (v5.0)
try:
    from backend_ai.app.prediction_engine import (
        get_prediction_engine,
        predict_luck,
        find_best_date,
        get_full_forecast,
        EventType,
    )
    HAS_PREDICTION = True
except ImportError:
    HAS_PREDICTION = False
    print("[app.py] Prediction engine not available")

# Theme Cross-Reference Filter (v5.1)
try:
    from backend_ai.app.theme_cross_filter import (
        get_theme_filter,
        filter_data_by_theme,
        get_theme_prompt_context,
    )
    HAS_THEME_FILTER = True
except ImportError:
    HAS_THEME_FILTER = False
    print("[app.py] Theme cross filter not available")

# Fortune Score Engine (v1.0) - Real-time saju+astrology scoring
try:
    from backend_ai.app.fortune_score_engine import (
        get_fortune_score_engine,
        calculate_fortune_score,
    )
    HAS_FORTUNE_SCORE = True
except ImportError:
    HAS_FORTUNE_SCORE = False
    print("[app.py] Fortune score engine not available")

# GraphRAG System - Lazy loaded (uses SentenceTransformer)
HAS_GRAPH_RAG = True  # Assume available
_saju_astro_rag_module = None

def _get_saju_astro_rag_module():
    global _saju_astro_rag_module, HAS_GRAPH_RAG
    if _saju_astro_rag_module is None:
        try:
            from backend_ai.app import saju_astro_rag as _sar
            _saju_astro_rag_module = _sar
        except ImportError:
            HAS_GRAPH_RAG = False
            print("[app.py] GraphRAG not available (lazy load)")
            return None
    return _saju_astro_rag_module

def get_graph_rag(*args, **kwargs):
    m = _get_saju_astro_rag_module()
    return m.get_graph_rag(*args, **kwargs) if m else None

def get_model(*args, **kwargs):
    m = _get_saju_astro_rag_module()
    return m.get_model(*args, **kwargs) if m else None

# OpenAI Client for streaming endpoints
try:
    from openai import OpenAI
    openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    OPENAI_AVAILABLE = True
except Exception:
    openai_client = None
    OPENAI_AVAILABLE = False
    print("[app.py] OpenAI client not available")

# CorpusRAG System - Lazy loaded (uses SentenceTransformer)
HAS_CORPUS_RAG = True  # Assume available
_corpus_rag_module = None

def _get_corpus_rag_module():
    global _corpus_rag_module, HAS_CORPUS_RAG
    if _corpus_rag_module is None:
        try:
            from backend_ai.app import corpus_rag as _cr
            _corpus_rag_module = _cr
        except ImportError:
            HAS_CORPUS_RAG = False
            print("[app.py] CorpusRAG not available (lazy load)")
            return None
    return _corpus_rag_module

def get_corpus_rag(*args, **kwargs):
    m = _get_corpus_rag_module()
    return m.get_corpus_rag(*args, **kwargs) if m else None

# Numerology System
try:
    from backend_ai.app.numerology_logic import (
        analyze_numerology,
        analyze_numerology_compatibility,
        calculate_full_numerology,
    )
    HAS_NUMEROLOGY = True
except ImportError:
    HAS_NUMEROLOGY = False
    print("[app.py] Numerology not available")

# ICP (Interpersonal Circumplex) System
try:
    from backend_ai.app.icp_logic import (
        analyze_icp_style,
        analyze_icp_compatibility,
        get_icp_questions,
        ICPAnalyzer,
    )
    HAS_ICP = True
except ImportError:
    HAS_ICP = False
    print("[app.py] ICP not available")

# Flask Application
app = Flask(__name__)

# Gzip compression - reduces response size by 30-50%
Compress(app)
app.config['COMPRESS_MIMETYPES'] = [
    'text/html', 'text/css', 'text/xml', 'text/plain',
    'application/json', 'application/javascript', 'application/xml'
]
app.config['COMPRESS_LEVEL'] = 6  # Balance between compression ratio and CPU usage
app.config['COMPRESS_MIN_SIZE'] = 500  # Only compress responses > 500 bytes

# CORS configuration - restrict to specific origins for security
CORS_ORIGINS = [
    "http://localhost:3000",
    "http://127.0.0.1:3000",
    "https://destinypal.com",
    "https://www.destinypal.com",
]
# Allow custom origins from environment variable
if os.getenv("CORS_ALLOWED_ORIGINS"):
    CORS_ORIGINS.extend(os.getenv("CORS_ALLOWED_ORIGINS").split(","))

CORS(
    app,
    origins=CORS_ORIGINS,
    allow_headers=["Content-Type", "Authorization", "X-API-KEY", "X-Request-ID"],
    methods=["GET", "POST", "OPTIONS"],
    supports_credentials=True,
    max_age=3600,
)

# Basic logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s %(message)s")
logger = logging.getLogger("backend_ai")

# Optional Sentry (no-op if DSN missing)
try:
    import sentry_sdk

    if os.getenv("SENTRY_DSN"):
        sentry_sdk.init(dsn=os.getenv("SENTRY_DSN"))
        logger.info("Sentry initialized for Flask backend.")
except Exception as e:  # pragma: no cover
    logger.warning(f"Sentry init skipped: {e}")


# ===============================================================
# ğŸš€ CROSS-ANALYSIS CACHE - Pre-loaded for instant lookups
# ===============================================================
_CROSS_ANALYSIS_CACHE = {}

# ===============================================================
# ğŸ”— INTEGRATION ENGINE CACHE - Multimodal analysis data
# ===============================================================
_INTEGRATION_DATA_CACHE = {
    "multimodal_engine": None,
    "career_mapping": None,
    "numerology_core": None,
    "numerology_compatibility": None,
    "numerology_saju": None,
    "numerology_astro": None,
    "numerology_therapeutic": None,
}


def _load_integration_data():
    """Load integration engine and numerology data."""
    global _INTEGRATION_DATA_CACHE

    if _INTEGRATION_DATA_CACHE.get("multimodal_engine") is not None:
        return _INTEGRATION_DATA_CACHE

    base_dir = os.path.dirname(os.path.dirname(__file__))

    # Integration engine files
    integration_dir = os.path.join(base_dir, "data", "graph", "rules", "integration")
    integration_files = {
        "multimodal_engine": "multimodal_integration_engine.json",
        "career_mapping": "modern_career_mapping.json",
    }

    for key, filename in integration_files.items():
        filepath = os.path.join(integration_dir, filename)
        try:
            if os.path.exists(filepath):
                with open(filepath, "r", encoding="utf-8") as f:
                    _INTEGRATION_DATA_CACHE[key] = json.load(f)
                    logger.info(f"  âœ… Loaded integration: {filename}")
        except Exception as e:
            logger.warning(f"  âš ï¸ Failed to load {filename}: {e}")
            _INTEGRATION_DATA_CACHE[key] = {}

    # Numerology files
    numerology_dir = os.path.join(base_dir, "data", "graph", "rules", "numerology")
    numerology_files = {
        "numerology_core": "numerology_core_rules.json",
        "numerology_compatibility": "numerology_compatibility_rules.json",
        "numerology_saju": "numerology_saju_mapping.json",
        "numerology_astro": "numerology_astro_mapping.json",
        "numerology_therapeutic": "numerology_therapeutic_questions.json",
    }

    for key, filename in numerology_files.items():
        filepath = os.path.join(numerology_dir, filename)
        try:
            if os.path.exists(filepath):
                with open(filepath, "r", encoding="utf-8") as f:
                    _INTEGRATION_DATA_CACHE[key] = json.load(f)
                    logger.info(f"  âœ… Loaded numerology: {filename}")
        except Exception as e:
            logger.warning(f"  âš ï¸ Failed to load {filename}: {e}")
            _INTEGRATION_DATA_CACHE[key] = {}

    loaded_count = sum(1 for v in _INTEGRATION_DATA_CACHE.values() if v)
    logger.info(f"[INTEGRATION-CACHE] Loaded {loaded_count}/7 integration/numerology files")
    return _INTEGRATION_DATA_CACHE


def get_integration_context(theme: str = "life") -> Dict:
    """Get theme-specific integration context for multimodal analysis."""
    data = _load_integration_data()
    engine = data.get("multimodal_engine", {})

    result = {
        "correlation_matrix": engine.get("correlation_matrix", {}),
        "theme_focus": {},
    }

    # Get theme-specific focus areas
    question_router = engine.get("question_router", {})
    if theme in question_router:
        result["theme_focus"] = question_router[theme]

    return result


# ===============================================================
# ğŸ§  JUNG PSYCHOLOGY CACHE - Enhanced therapeutic data
# ===============================================================
_JUNG_DATA_CACHE = {
    "active_imagination": None,
    "lifespan_individuation": None,
    "crisis_intervention": None,
    "archetypes": None,
    "therapeutic": None,
    "cross_analysis": None,
    "psychological_types": None,
    "alchemy": None,
    "counseling_scenarios": None,
    "integrated_counseling": None,
    "counseling_prompts": None,
    "personality_integration": None,
    "expanded_counseling": None,
}


def _load_jung_data():
    """Load extended Jung psychology data for deeper therapeutic sessions."""
    global _JUNG_DATA_CACHE

    # Return cached data if already loaded
    if _JUNG_DATA_CACHE.get("active_imagination") is not None:
        return _JUNG_DATA_CACHE

    jung_dir = os.path.join(os.path.dirname(__file__), "..", "data", "graph", "rules", "jung")
    jung_dir = os.path.abspath(jung_dir)

    files_to_load = {
        "active_imagination": "jung_active_imagination.json",
        "lifespan_individuation": "jung_lifespan_individuation.json",
        "crisis_intervention": "jung_crisis_intervention.json",
        "archetypes": "jung_archetypes.json",
        "therapeutic": "jung_therapeutic.json",
        "cross_analysis": "jung_cross_analysis.json",
        "psychological_types": "jung_psychological_types.json",
        "alchemy": "jung_alchemy.json",
        "counseling_scenarios": "jung_counseling_scenarios.json",
        "integrated_counseling": "jung_integrated_counseling.json",
        "counseling_prompts": "jung_counseling_prompts.json",
        "personality_integration": "jung_personality_integration.json",
        "expanded_counseling": "jung_expanded_counseling.json",
    }

    for key, filename in files_to_load.items():
        filepath = os.path.join(jung_dir, filename)
        try:
            if os.path.exists(filepath):
                with open(filepath, "r", encoding="utf-8") as f:
                    _JUNG_DATA_CACHE[key] = json.load(f)
                    logger.info(f"  âœ… Loaded Jung data: {filename}")
        except Exception as e:
            logger.warning(f"  âš ï¸ Failed to load {filename}: {e}")
            _JUNG_DATA_CACHE[key] = {}

    logger.info(f"[JUNG-CACHE] Loaded {sum(1 for v in _JUNG_DATA_CACHE.values() if v)} Jung psychology files")
    return _JUNG_DATA_CACHE


def get_lifespan_guidance(birth_year: int) -> dict:
    """Get age-appropriate psychological guidance based on Jung's lifespan individuation."""
    jung_data = _load_jung_data()
    lifespan = jung_data.get("lifespan_individuation", {})

    if not lifespan:
        return {}

    from datetime import datetime
    current_year = datetime.now().year
    age = current_year - birth_year

    life_stages = lifespan.get("life_stages", {})

    # Determine life stage
    if age <= 12:
        stage = "childhood"
    elif age <= 22:
        stage = "adolescence"
    elif age <= 35:
        stage = "early_adulthood"
    elif age <= 55:
        stage = "midlife"
    elif age <= 70:
        stage = "mature_adulthood"
    else:
        stage = "elder"

    stage_data = life_stages.get(stage, {})

    return {
        "age": age,
        "stage_name": stage_data.get("name_ko", stage),
        "psychological_tasks": stage_data.get("psychological_tasks", []),
        "archetypal_themes": stage_data.get("archetypal_themes", {}),
        "developmental_crises": stage_data.get("developmental_crises", []),
        "shadow_challenges": stage_data.get("shadow_challenges", stage_data.get("shadow_manifestations", [])),
        "saju_parallel": stage_data.get("saju_parallel", {}),
        "astro_parallel": stage_data.get("astro_parallel", {}),
        "guidance": stage_data.get("guidance", stage_data.get("saturn_return_guidance", stage_data.get("uranus_opposition_guidance", {}))),
    }


def get_active_imagination_prompts(context: str) -> list:
    """Get appropriate active imagination exercise prompts based on context."""
    jung_data = _load_jung_data()
    ai_data = jung_data.get("active_imagination", {})

    if not ai_data:
        return []

    prompts = []
    facilitation = ai_data.get("ai_facilitation_guide", {})

    # Get opening prompts based on context
    context_lower = context.lower()

    if any(k in context_lower for k in ["ê¿ˆ", "ì•…ëª½", "ê¿ˆì—ì„œ"]):
        prompts = facilitation.get("opening_prompts", {}).get("after_dream_sharing", [])
    elif any(k in context_lower for k in ["ì‚¬ì£¼", "ìš´ì„¸", "ì¼ê°„"]):
        prompts = facilitation.get("opening_prompts", {}).get("after_saju_analysis", [])
    elif any(k in context_lower for k in ["ì ì„±", "ë³„ìë¦¬", "í•˜ìš°ìŠ¤"]):
        prompts = facilitation.get("opening_prompts", {}).get("after_astro_analysis", [])
    else:
        prompts = facilitation.get("opening_prompts", {}).get("general", [])

    # Add deepening and integration prompts
    deepening = facilitation.get("deepening_prompts", [])
    integration = facilitation.get("integration_prompts", [])

    return {
        "opening": prompts[:2],
        "deepening": deepening[:3],
        "integration": integration[:2],
    }


def get_crisis_resources(locale: str = "ko") -> dict:
    """Get crisis intervention resources and scripts."""
    jung_data = _load_jung_data()
    crisis = jung_data.get("crisis_intervention", {})

    if not crisis:
        return {}

    resources = crisis.get("response_protocols", {}).get("suicidal_ideation", {}).get("resources_korea", {})
    limitations = crisis.get("ai_limitations_and_boundaries", {})
    deescalation = crisis.get("de_escalation_techniques", {})

    return {
        "resources": resources,
        "limitations": limitations,
        "deescalation": deescalation,
    }

def _load_cross_analysis_cache():
    """Load cross-analysis JSON files for instant lookups (no embedding search)."""
    global _CROSS_ANALYSIS_CACHE
    if _CROSS_ANALYSIS_CACHE:
        return _CROSS_ANALYSIS_CACHE

    import json
    fusion_dir = os.path.join(os.path.dirname(__file__), "..", "data", "graph", "fusion")
    fusion_dir = os.path.abspath(fusion_dir)

    if not os.path.exists(fusion_dir):
        logger.warning(f"[CROSS-CACHE] Fusion dir not found: {fusion_dir}")
        return {}

    for fname in os.listdir(fusion_dir):
        if fname.endswith(".json") and "cross" in fname.lower():
            try:
                with open(os.path.join(fusion_dir, fname), "r", encoding="utf-8") as f:
                    data = json.load(f)
                    key = fname.replace(".json", "")
                    _CROSS_ANALYSIS_CACHE[key] = data
                    logger.info(f"  âœ… Loaded cross-analysis: {fname}")
            except Exception as e:
                logger.warning(f"  âš ï¸ Failed to load {fname}: {e}")

    logger.info(f"[CROSS-CACHE] Loaded {len(_CROSS_ANALYSIS_CACHE)} cross-analysis files")
    return _CROSS_ANALYSIS_CACHE


def normalize_day_master(saju_data: dict) -> dict:
    """
    Normalize dayMaster to flat structure { name, element }.
    Handles both:
    - Nested: { heavenlyStem: { name: "åºš", element: "ê¸ˆ" }, element: "..." }
    - Flat: { name: "åºš", element: "ê¸ˆ" } or { heavenlyStem: "åºš", element: "ê¸ˆ" }
    Returns normalized saju_data with flat dayMaster.
    """
    if not saju_data or not saju_data.get("dayMaster"):
        return saju_data

    dm = saju_data.get("dayMaster", {})
    if not isinstance(dm, dict):
        return saju_data

    # Check if heavenlyStem is a nested object
    hs = dm.get("heavenlyStem")
    if isinstance(hs, dict):
        # Nested structure: { heavenlyStem: { name, element } }
        normalized_dm = {
            "name": hs.get("name", ""),
            "heavenlyStem": hs.get("name", ""),
            "element": hs.get("element") or dm.get("element", ""),
        }
        saju_data = dict(saju_data)  # Copy to avoid mutation
        saju_data["dayMaster"] = normalized_dm
        logger.debug(f"[NORMALIZE] dayMaster: nested -> flat: {normalized_dm}")
    elif isinstance(hs, str):
        # Already flat but with heavenlyStem as string
        normalized_dm = {
            "name": hs,
            "heavenlyStem": hs,
            "element": dm.get("element", ""),
        }
        saju_data = dict(saju_data)
        saju_data["dayMaster"] = normalized_dm
    # else: already in { name, element } format or empty

    return saju_data


def get_cross_analysis_for_chart(saju_data: dict, astro_data: dict, theme: str = "chat", locale: str = "ko") -> str:
    """
    Get detailed cross-analysis based on user's chart data.
    Enhanced v3: Uses ALL fusion rules with:
    - Planet + House combinations with timing/advice
    - Saju Ten Gods (ì‹­ì‹ ) analysis
    - Element cross-matching (ì‚¬ì£¼ ì˜¤í–‰ Ã— ì ì„± ì›ì†Œ)
    - Health, Wealth, Family, Life Path analysis
    - Actionable insights with specific timing
    - Supports both new (text_ko/advice) and legacy (text only) rule formats
    """
    cache = _load_cross_analysis_cache()
    results = []
    detailed_insights = []

    # Get chart elements (support both "heavenlyStem" and "name" for dayMaster)
    dm_data = saju_data.get("dayMaster", {})
    daymaster = dm_data.get("heavenlyStem") or dm_data.get("name", "")
    dm_element = dm_data.get("element", "")
    sun_sign = astro_data.get("sun", {}).get("sign", "")
    moon_sign = astro_data.get("moon", {}).get("sign", "")
    dominant = saju_data.get("dominantElement", "")

    # Extract Ten Gods (ì‹­ì‹ ) from saju data
    ten_gods = saju_data.get("tenGods", {})
    dominant_god = ten_gods.get("dominant", "")  # e.g., "ì •ê´€", "í¸ê´€", "ì •ì¬", "ìƒê´€"

    # Get element counts for imbalance detection
    element_counts = saju_data.get("elementCounts", {})

    # Map Korean sign names to English and element
    sign_map = {
        "ì–‘ìë¦¬": "Aries", "í™©ì†Œìë¦¬": "Taurus", "ìŒë‘¥ì´ìë¦¬": "Gemini",
        "ê²Œìë¦¬": "Cancer", "ì‚¬ììë¦¬": "Leo", "ì²˜ë…€ìë¦¬": "Virgo",
        "ì²œì¹­ìë¦¬": "Libra", "ì „ê°ˆìë¦¬": "Scorpio", "ê¶ìˆ˜ìë¦¬": "Sagittarius",
        "ì—¼ì†Œìë¦¬": "Capricorn", "ë¬¼ë³‘ìë¦¬": "Aquarius", "ë¬¼ê³ ê¸°ìë¦¬": "Pisces",
    }
    sign_element_map = {
        "Aries": "fire", "Leo": "fire", "Sagittarius": "fire",
        "Taurus": "earth", "Virgo": "earth", "Capricorn": "earth",
        "Gemini": "air", "Libra": "air", "Aquarius": "air",
        "Cancer": "water", "Scorpio": "water", "Pisces": "water",
    }
    # Map saju elements to flags for health rules
    element_to_flag = {
        "æœ¨": "wood", "ç«": "fire", "åœŸ": "earth", "é‡‘": "metal", "æ°´": "water"
    }

    sun_sign_en = sign_map.get(sun_sign, sun_sign)
    moon_sign_en = sign_map.get(moon_sign, moon_sign)
    sun_element = sign_element_map.get(sun_sign_en, "")

    # Planet-house combinations to check (used in multiple sections)
    planet_house_checks = []
    for planet in ["sun", "moon", "mercury", "venus", "mars", "jupiter", "saturn"]:
        p_data = astro_data.get(planet, {})
        house = p_data.get("house")
        if house:
            planet_house_checks.append((planet, str(house)))

    # Load ALL fusion rules (not just career/love)
    fusion_rules = {}
    try:
        rules_dir = Path(__file__).parent.parent / "data" / "graph" / "rules" / "fusion"
        # Load all theme-specific fusion rules
        all_rule_files = [
            "career.json", "love.json", "health.json", "wealth.json",
            "family.json", "life_path.json", "daily.json", "monthly.json",
            "compatibility.json", "new_year.json", "next_year.json"
        ]
        for rule_file in all_rule_files:
            rule_path = rules_dir / rule_file
            if rule_path.exists():
                with open(rule_path, "r", encoding="utf-8") as f:
                    rules = json.load(f)
                    fusion_rules[rule_file.replace(".json", "")] = rules
        logger.debug(f"[CROSS-ANALYSIS] Loaded {len(fusion_rules)} fusion rule sets")
    except Exception as e:
        logger.warning(f"[CROSS-ANALYSIS] Failed to load fusion rules: {e}")

    # 1. Cross-analysis cache lookup (daymaster Ã— sun sign) - INSTANT
    if cache:
        advanced_cross = cache.get("saju_astro_advanced_cross", {})
        dm_data = advanced_cross.get("daymaster_sun_complete", {}).get(daymaster, {})
        if dm_data:
            sun_combo = dm_data.get("sun_signs", {}).get(sun_sign_en, {})
            if sun_combo:
                results.append(f"[{daymaster}+{sun_sign_en}] {sun_combo.get('insight', '')} | ì¶”ì²œ: {', '.join(sun_combo.get('best_for', []))} | ì£¼ì˜: {sun_combo.get('caution', '')}")

            # Moon cross-analysis
            if moon_sign_en and moon_sign_en != sun_sign_en:
                moon_combo = dm_data.get("sun_signs", {}).get(moon_sign_en, {})
                if moon_combo:
                    results.append(f"[{daymaster}+ë‹¬:{moon_sign_en}] ê°ì •: {moon_combo.get('insight', '')[:80]}")

        # 1-2. ì‹­ì‹ -í–‰ì„± êµì°¨ ë¶„ì„ (cross_sipsin_planets.json)
        sipsin_planets = cache.get("cross_sipsin_planets", {})
        if sipsin_planets and dominant_god:
            sipsin_mapping = sipsin_planets.get("sipsin_planet_mapping", {})
            if dominant_god in sipsin_mapping:
                sp_data = sipsin_mapping[dominant_god]
                planet = sp_data.get("planet", "")
                life_areas = sp_data.get("life_areas", {})
                psych = sp_data.get("psychological_theme", "")
                # Theme-specific insight from sipsin-planet mapping
                area_text = ""
                if theme in ["focus_career", "career"] and life_areas.get("career"):
                    area_text = life_areas["career"]
                elif theme in ["focus_love", "love"] and life_areas.get("relationship"):
                    area_text = life_areas["relationship"]
                elif theme in ["focus_wealth", "wealth"] and life_areas.get("wealth"):
                    area_text = life_areas["wealth"]
                elif theme in ["focus_health", "health"] and life_areas.get("health"):
                    area_text = life_areas["health"]
                if area_text:
                    detailed_insights.append((7, f"ğŸ”— ì‹­ì‹ Ã—í–‰ì„± [{dominant_god}â†”{planet}]: {area_text} ({psych})"))

        # 1-3. ì§€ì§€-í•˜ìš°ìŠ¤ êµì°¨ ë¶„ì„ (cross_branch_house.json)
        branch_house = cache.get("cross_branch_house", {})
        if branch_house:
            branch_mapping = branch_house.get("branch_house_mapping", {})
            # Check year, month, day, hour branches
            for pillar_key in ["yearPillar", "monthPillar", "dayPillar", "hourPillar"]:
                pillar = saju_data.get(pillar_key, {})
                branch = pillar.get("earthlyBranch", "")
                branch_ko = {"å­": "ì", "ä¸‘": "ì¶•", "å¯…": "ì¸", "å¯": "ë¬˜", "è¾°": "ì§„", "å·³": "ì‚¬",
                             "åˆ": "ì˜¤", "æœª": "ë¯¸", "ç”³": "ì‹ ", "é…‰": "ìœ ", "æˆŒ": "ìˆ ", "äº¥": "í•´"}.get(branch, "")
                if branch_ko and branch_ko in branch_mapping:
                    bh_data = branch_mapping[branch_ko]
                    primary_house = bh_data.get("primary_house")
                    # Check if user has a planet in this house
                    for planet, house in planet_house_checks:
                        if str(primary_house) == house:
                            life_themes = bh_data.get("life_themes", {})
                            shared = bh_data.get("shared_energy", "")
                            pillar_names = {"yearPillar": "ë…„ì§€", "monthPillar": "ì›”ì§€", "dayPillar": "ì¼ì§€", "hourPillar": "ì‹œì§€"}
                            detailed_insights.append((6, f"âš¡ ì§€ì§€Ã—í•˜ìš°ìŠ¤ [{pillar_names[pillar_key]} {branch}â†”{planet} {house}H]: {shared}"))
                            break

        # 1-4. ì²œê°„í•©/ì§€ì§€í•© ë¶„ì„ (cross_relations_aspects.json)
        relations_aspects = cache.get("cross_relations_aspects", {})
        if relations_aspects:
            major_aspects = relations_aspects.get("major_aspects", {})
            conj = major_aspects.get("conjunction_0", {})
            # Check for ì²œê°„í•© in user's chart
            cheongan_hap = conj.get("cheongan_hap_details", {})
            year_stem = saju_data.get("yearPillar", {}).get("heavenlyStem", "")
            day_stem = saju_data.get("dayPillar", {}).get("heavenlyStem", "")
            # Common í•© combinations
            hap_pairs = {"ê°‘": "ê¸°", "ì„": "ê²½", "ë³‘": "ì‹ ", "ì •": "ì„", "ë¬´": "ê³„",
                         "ê¸°": "ê°‘", "ê²½": "ì„", "ì‹ ": "ë³‘", "ì„": "ì •", "ê³„": "ë¬´"}
            for stem in [year_stem, day_stem]:
                if stem and stem in hap_pairs:
                    hap_key = f"{stem}{hap_pairs[stem]}í•©"
                    if hap_key in cheongan_hap:
                        hap_info = cheongan_hap[hap_key]
                        detailed_insights.append((5, f"â˜¯ï¸ ì²œê°„í•© [{hap_key}]: {hap_info.get('meaning', '')} â†’ {hap_info.get('result', '')}ê¸°ìš´ í˜•ì„±"))

        # 1-5. ì‹ ì‚´Ã—ì†Œí–‰ì„± ë§¤í•‘ (cross_shinsal_asteroids.json)
        shinsal_asteroids = cache.get("cross_shinsal_asteroids", {})
        if shinsal_asteroids:
            shinsal_mapping = shinsal_asteroids.get("major_shinsal_mapping", {})
            # Check user's shinsal from saju_data
            user_shinsals = saju_data.get("sinsal", []) or saju_data.get("shinsals", []) or []
            if isinstance(user_shinsals, dict):
                user_shinsals = list(user_shinsals.keys())
            for shinsal_name in user_shinsals[:3]:  # Top 3 shinsals
                if shinsal_name in shinsal_mapping:
                    ss_data = shinsal_mapping[shinsal_name]
                    astro_par = ss_data.get("astro_parallel", {})
                    primary = astro_par.get("primary", "")
                    effect = ss_data.get("effect", "")
                    house_act = ss_data.get("house_activation", [])
                    # Check if user has matching planet in activated house
                    if primary and effect:
                        detailed_insights.append((6, f"â­ ì‹ ì‚´Ã—ì ì„± [{shinsal_name}â†”{primary}]: {effect}"))

        # 1-6. ê²©êµ­Ã—í•˜ìš°ìŠ¤ íŒ¨í„´ (cross_geokguk_house.json)
        geokguk_house = cache.get("cross_geokguk_house", {})
        if geokguk_house:
            junggyeok = geokguk_house.get("junggyeok_8types", {})
            user_geokguk = saju_data.get("geokguk", "") or saju_data.get("gyeokguk", "")
            if user_geokguk and user_geokguk in junggyeok:
                gk_data = junggyeok[user_geokguk]
                astro_par = gk_data.get("astro_parallel", {})
                chart_sig = gk_data.get("chart_signature", "")
                life_exp = gk_data.get("life_expression", "")
                primary = astro_par.get("primary", "")
                if primary and chart_sig:
                    detailed_insights.append((7, f"ğŸ›ï¸ ê²©êµ­Ã—ì°¨íŠ¸ [{user_geokguk}â†”{primary}]: {chart_sig}"))
                    if life_exp and theme in ["career", "focus_career", "life"]:
                        detailed_insights.append((6, f"   â†’ ì ì„±: {life_exp}"))

        # 1-7. ëŒ€ìš´Ã—í”„ë¡œê·¸ë ˆì…˜ (cross_luck_progression.json)
        luck_prog = cache.get("cross_luck_progression", {})
        if luck_prog:
            daeun_mapping = luck_prog.get("daeun_progression_mapping", {})
            sipsin_daeun = daeun_mapping.get("sipsin_daeun_astro", {})
            # Get current daeun sipsin
            current_daeun = saju_data.get("currentDaeun", {}) or saju_data.get("daeWoon", {})
            if isinstance(current_daeun, list) and len(current_daeun) > 0:
                current_daeun = current_daeun[0]
            daeun_sipsin = ""
            if isinstance(current_daeun, dict):
                daeun_sipsin = current_daeun.get("sipsin", "") or current_daeun.get("heavenlyGod", "")
                if daeun_sipsin and "ìš´" not in daeun_sipsin:
                    daeun_sipsin = daeun_sipsin + "ìš´"
            if daeun_sipsin and daeun_sipsin in sipsin_daeun:
                ld_data = sipsin_daeun[daeun_sipsin]
                saju_theme = ld_data.get("saju_theme", "")
                astro_par = ld_data.get("astro_parallel", "")
                if saju_theme:
                    detailed_insights.append((5, f"ğŸ“… ëŒ€ìš´Ã—í”„ë¡œê·¸ë ˆì…˜ [{daeun_sipsin}]: {saju_theme}"))

        # 1-8. 60ê°‘ìÃ—í•˜ëª¨ë‹‰/ë‚©ìŒ (cross_60ganji_harmonic.json)
        ganji_harmonic = cache.get("cross_60ganji_harmonic", {})
        if ganji_harmonic:
            naeum_types = ganji_harmonic.get("naeum_30_types", {})
            # Get user's day pillar naeum
            day_pillar = saju_data.get("dayPillar", {})
            day_ganji = day_pillar.get("fullStem", "") or f"{day_pillar.get('heavenlyStem', '')}{day_pillar.get('earthlyBranch', '')}"
            for naeum_name, naeum_data in naeum_types.items():
                if not isinstance(naeum_data, dict):
                    continue
                ganji_list = naeum_data.get("ganji", [])
                if any(day_ganji in g for g in ganji_list):
                    harmonic = naeum_data.get("harmonic_parallel", {})
                    personality = naeum_data.get("personality", "")
                    life_theme = naeum_data.get("life_theme", "")
                    h_primary = harmonic.get("primary", "")
                    if personality:
                        detailed_insights.append((6, f"ğŸµ ë‚©ìŒÃ—í•˜ëª¨ë‹‰ [{naeum_name}â†”{h_primary}]: {personality}"))
                    if life_theme:
                        detailed_insights.append((5, f"   â†’ ì‚¶ì˜ í…Œë§ˆ: {life_theme}"))
                    break

        # 1-9. ê³µë§Ã—ë“œë¼ì½”ë‹‰ ì¹´ë¥´ë§ˆ (cross_draconic_karma.json)
        draconic_karma = cache.get("cross_draconic_karma", {})
        if draconic_karma:
            gongmang_sn = draconic_karma.get("gongmang_south_node", {})
            branch_void = gongmang_sn.get("cross_mapping", {}).get("branch_house_void", {})
            user_gongmang = saju_data.get("gongmang", []) or saju_data.get("kongmang", [])
            if isinstance(user_gongmang, str):
                user_gongmang = [user_gongmang]
            for gm in user_gongmang[:2]:
                gm_key = f"{gm}_ê³µë§"
                if gm_key in branch_void:
                    gm_data = branch_void[gm_key]
                    theme = gm_data.get("theme", "")
                    draconic = gm_data.get("draconic", "")
                    if theme:
                        detailed_insights.append((5, f"ğŸŒ™ ê³µë§Ã—ë“œë¼ì½”ë‹‰ [{gm} ê³µë§]: {theme}"))

    # 2. Planet-House detailed analysis from ALL fusion rules
    is_ko = locale == "ko"
    text_key = "text_ko" if is_ko else "text_en"

    # Determine which domains to use based on theme (expanded for all themes)
    theme_to_domain = {
        # General chat uses multiple domains
        "chat": ["career", "love", "health", "wealth"],
        "life": ["career", "love", "life_path", "wealth"],
        "life_path": ["life_path", "career", "love"],
        # Focus themes use specific domains
        "focus_career": ["career"], "career": ["career"],
        "focus_love": ["love"], "love": ["love"],
        "focus_health": ["health"], "health": ["health"],
        "focus_wealth": ["wealth"], "wealth": ["wealth"],
        "focus_family": ["family"], "family": ["family"],
        # Time-based themes
        "daily": ["daily", "health"],
        "monthly": ["monthly", "career", "love"],
        "new_year": ["new_year", "career", "love", "health"],
        "next_year": ["next_year", "career", "wealth"],
        # Compatibility
        "compatibility": ["compatibility", "love"],
    }
    domains = theme_to_domain.get(theme, ["career", "love", "health"])

    # Helper to extract text from rule (supports both new and legacy formats)
    def get_rule_text(rule: dict, prefer_ko: bool = True) -> str:
        """Extract text from rule, supporting both new (text_ko/text_en) and legacy (text) formats."""
        if prefer_ko:
            return rule.get("text_ko", rule.get("text", rule.get("text_en", "")))
        else:
            return rule.get("text_en", rule.get("text", rule.get("text_ko", "")))

    # Theme-specific emoji mapping
    domain_emoji = {
        "career": "ğŸ’¼", "love": "ğŸ’•", "health": "ğŸ¥", "wealth": "ğŸ’°",
        "family": "ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦", "life_path": "ğŸŒŸ", "daily": "ğŸ“…", "monthly": "ğŸ“†",
        "compatibility": "ğŸ’‘", "new_year": "ğŸŠ", "next_year": "ğŸ”®"
    }

    # Apply detailed fusion rules for ALL domains
    for domain in domains:
        if domain not in fusion_rules:
            continue
        rules = fusion_rules[domain]
        emoji = domain_emoji.get(domain, "âœ¨")

        # A. Check planet-house rules (e.g., rule_sun_10, rule_venus_7)
        # Also check legacy format: rule_1, rule_2, etc. with "when" arrays
        for planet, house in planet_house_checks:
            # New format: rule_{planet}_{house}
            rule_key = f"rule_{planet}_{house}"
            if rule_key in rules:
                rule = rules[rule_key]
                text = get_rule_text(rule, is_ko)
                advice = rule.get("advice_ko", "")
                timing = rule.get("timing", "")
                saju_link = rule.get("saju_link", "")
                weight = rule.get("weight", 5)

                if text:
                    insight = f"{emoji} {text[:150]}"
                    if timing and is_ko:
                        insight += f"\nâ° ì‹œê¸°: {timing}"
                    if advice and is_ko:
                        insight += f"\nğŸ’¡ ì¡°ì–¸: {advice}"
                    if saju_link and dominant_god and dominant_god in saju_link:
                        insight += f"\nğŸ”— ì‚¬ì£¼ì—°ê²°: {saju_link}"
                    detailed_insights.append((weight, insight))

            # Legacy format: search for rules with "when" arrays containing planet and house
            for rule_key, rule in rules.items():
                if not isinstance(rule, dict):
                    continue
                when = rule.get("when", [])
                if isinstance(when, list) and planet in when and house in when:
                    text = get_rule_text(rule, is_ko)
                    weight = rule.get("weight", 4)
                    if text and len(text) > 10:
                        # Translate common English patterns to Korean if needed
                        if is_ko and text.startswith(planet.capitalize()):
                            text = f"{planet.capitalize()} {house}í•˜ìš°ìŠ¤: {text.split(':', 1)[-1].strip() if ':' in text else text}"
                        insight = f"{emoji} {text[:120]}"
                        detailed_insights.append((weight, insight))
                        break  # Only one match per planet-house combo per domain

        # B. Health-specific: Element imbalance analysis
        if domain == "health" and element_counts:
            for elem_ko, elem_en in element_to_flag.items():
                count = element_counts.get(elem_ko, 0)
                # Check for depleted elements (0 count)
                if count == 0:
                    flag_key = f"{elem_en}_zero"
                    for rule_key, rule in rules.items():
                        when = rule.get("when", [])
                        if isinstance(when, list) and flag_key in when:
                            text = get_rule_text(rule, is_ko)
                            weight = rule.get("weight", 4)
                            if text:
                                ko_elem_names = {"wood": "ëª©(æœ¨)", "fire": "í™”(ç«)", "earth": "í† (åœŸ)", "metal": "ê¸ˆ(é‡‘)", "water": "ìˆ˜(æ°´)"}
                                elem_name = ko_elem_names.get(elem_en, elem_en)
                                insight = f"ğŸ¥ {elem_name} ë¶€ì¡±: {text[:100]}" if is_ko else f"ğŸ¥ {elem_en} depleted: {text[:100]}"
                                detailed_insights.append((weight, insight))
                                break
                # Check for excess elements (high count, e.g., >= 3)
                elif count >= 3:
                    flag_key = f"{elem_en}_high"
                    for rule_key, rule in rules.items():
                        when = rule.get("when", [])
                        if isinstance(when, list) and flag_key in when:
                            text = get_rule_text(rule, is_ko)
                            weight = rule.get("weight", 3)
                            if text:
                                ko_elem_names = {"wood": "ëª©(æœ¨)", "fire": "í™”(ç«)", "earth": "í† (åœŸ)", "metal": "ê¸ˆ(é‡‘)", "water": "ìˆ˜(æ°´)"}
                                elem_name = ko_elem_names.get(elem_en, elem_en)
                                insight = f"ğŸ¥ {elem_name} ê³¼ë‹¤: {text[:100]}" if is_ko else f"ğŸ¥ {elem_en} excess: {text[:100]}"
                                detailed_insights.append((weight, insight))
                                break

        # C. Wealth-specific: Money house analysis (2, 8, 10, 11)
        if domain == "wealth":
            money_houses = ["2", "8", "10", "11"]
            for planet, house in planet_house_checks:
                if house in money_houses:
                    for rule_key, rule in rules.items():
                        when = rule.get("when", [])
                        if isinstance(when, list) and planet in when and house in when:
                            text = get_rule_text(rule, is_ko)
                            weight = rule.get("weight", 5)
                            if text:
                                insight = f"ğŸ’° {text[:120]}"
                                detailed_insights.append((weight, insight))
                                break

        # D. Check Ten Gods rules (ì‹­ì‹  ê¸°ë°˜ ë¶„ì„) - for career/love domains
        if dominant_god and domain in ["career", "love"]:
            god_mapping = {
                "ì •ê´€": "jeonggwan", "í¸ê´€": "pyeongwan",
                "ì •ì¬": "jeongje", "í¸ì¬": "pyeonje",
                "ìƒê´€": "sangwan", "ì‹ì‹ ": "sikshin",
                "ì •ì¸": "jeongin", "í¸ì¸": "pyeonin",
                "ë¹„ê²¬": "bigyeon", "ê²ì¬": "geopje",
            }
            mapped_god = god_mapping.get(dominant_god, "")
            if mapped_god:
                for rule_key, rule in rules.items():
                    if mapped_god in rule_key.lower():
                        text = get_rule_text(rule, is_ko)
                        advice = rule.get("advice_ko", "")
                        weight = rule.get("weight", 5)
                        if text:
                            insight = f"ğŸ“Š ì‹­ì‹ ë¶„ì„ [{dominant_god}]: {text[:120]}"
                            if advice:
                                insight += f"\nğŸ’¡ {advice}"
                            detailed_insights.append((weight, insight))
                            break

        # E. Check element cross-rules (ì‚¬ì£¼ ì˜¤í–‰ Ã— ì ì„± ì›ì†Œ)
        if dm_element and sun_element:
            for rule_key, rule in rules.items():
                if "cross" in rule_key and dm_element in rule_key and sun_element in rule_key:
                    text = get_rule_text(rule, is_ko)
                    advice = rule.get("advice_ko", "")
                    weight = rule.get("weight", 6)
                    if text:
                        insight = f"ğŸ”® ìœµí•©ë¶„ì„ [{dm_element}+{sun_element}]: {text[:120]}"
                        if advice:
                            insight += f"\nğŸ’¡ {advice}"
                        detailed_insights.append((weight, insight))
                        break

    # 3. GraphRAG theme rules (keyword match, no embedding) - INSTANT
    if HAS_GRAPH_RAG:
        try:
            graph_rag = get_graph_rag()

            # Build facts string for rule matching
            facts_parts = [theme, daymaster, dm_element, dominant]
            if sun_sign_en:
                facts_parts.append(sun_sign_en.lower())
            if moon_sign_en:
                facts_parts.append(moon_sign_en.lower())

            # Add planets in houses
            for planet, house in planet_house_checks:
                facts_parts.extend([planet, house, f"{planet} {house}"])

            facts_str = " ".join(filter(None, facts_parts))

            # Apply rules from each domain (instant keyword match)
            for domain in domains:
                if hasattr(graph_rag, '_apply_rules'):
                    matched = graph_rag._apply_rules(domain, facts_str)
                    if matched:
                        results.extend(matched[:2])

        except Exception as e:
            logger.warning(f"[CROSS-ANALYSIS] GraphRAG rules failed: {e}")

    # Sort detailed insights by weight (highest first) and deduplicate
    detailed_insights.sort(key=lambda x: -x[0])
    seen_texts = set()
    unique_insights = []
    for weight, insight in detailed_insights:
        # Use first 50 chars as dedup key
        key = insight[:50]
        if key not in seen_texts:
            seen_texts.add(key)
            unique_insights.append(insight)
        if len(unique_insights) >= 5:  # Take top 5 unique insights
            break

    # Combine all results: basic cross-analysis + detailed insights
    all_results = results + unique_insights

    # Log summary
    logger.info(f"[CROSS-ANALYSIS] Generated {len(all_results)} insights for theme={theme}, domains={domains}")

    return "\n\n".join(all_results[:8]) if all_results else ""


# ===============================================================
# ğŸ¯ THEME-SPECIFIC FUSION RULES - Daily/Monthly/Yearly guidance
# ===============================================================

def get_theme_fusion_rules(saju_data: dict, astro_data: dict, theme: str, locale: str = "ko", birth_year: int = None) -> str:
    """
    Get theme-specific fusion rules based on counselor theme.
    Applies rules from daily.json, monthly.json, new_year.json, next_year.json, family.json, life_path.json.

    Returns actionable insights tailored to the specific counseling theme.
    """
    from pathlib import Path
    from datetime import datetime

    results = []
    is_ko = locale == "ko"
    now = datetime.now()

    # Theme to rule file mapping
    theme_file_map = {
        "focus_overall": ["daily", "monthly", "life_path", "new_year"],
        "focus_career": ["daily", "monthly", "career"],
        "focus_love": ["daily", "monthly", "love", "family"],
        "focus_health": ["daily", "monthly", "health"],
        "focus_wealth": ["daily", "monthly", "wealth"],
        "focus_family": ["daily", "monthly", "family"],
        "focus_2025": ["new_year", "next_year", "monthly"],
        "focus_compatibility": ["compatibility", "love", "family"],
        "chat": ["daily", "life_path"],
    }

    rule_files = theme_file_map.get(theme, ["daily", "life_path"])

    # Load fusion rules
    rules_dir = Path(__file__).parent.parent / "data" / "graph" / "rules" / "fusion"
    loaded_rules = {}
    for rf in rule_files:
        rule_path = rules_dir / f"{rf}.json"
        if rule_path.exists():
            try:
                with open(rule_path, "r", encoding="utf-8") as f:
                    loaded_rules[rf] = json.load(f)
            except Exception as e:
                logger.warning(f"[THEME-FUSION] Failed to load {rf}.json: {e}")

    # Extract chart data
    dm_data = saju_data.get("dayMaster", {})
    daymaster = dm_data.get("heavenlyStem") or dm_data.get("name", "")
    dm_element = dm_data.get("element", "")
    ten_gods = saju_data.get("tenGods", {})
    dominant_god = ten_gods.get("dominant", "")

    # Astrology data
    sun_sign = astro_data.get("sun", {}).get("sign", "")
    moon_sign = astro_data.get("moon", {}).get("sign", "")

    # Calculate age if birth_year provided
    current_age = now.year - birth_year if birth_year else None

    # Helper to get localized text
    def get_text(rule):
        if is_ko:
            return rule.get("text_ko", rule.get("text", ""))
        return rule.get("text_en", rule.get("text", ""))

    def get_advice(rule):
        return rule.get("advice_ko", "") if is_ko else rule.get("advice_en", "")

    # ===============================================================
    # 1. DAILY RULES - Moon phases, planetary transits, day energy
    # ===============================================================
    if "daily" in loaded_rules:
        daily_rules = loaded_rules["daily"]

        # Check moon phase (simplified - use current day of lunar month)
        lunar_day = now.day % 30
        if lunar_day <= 3:  # New moon period
            rule = daily_rules.get("rule_new_moon_day")
            if rule:
                results.append(f"ğŸŒ‘ {get_text(rule)}\nğŸ’¡ {get_advice(rule)}")
        elif 13 <= lunar_day <= 17:  # Full moon period
            rule = daily_rules.get("rule_full_moon_day")
            if rule:
                results.append(f"ğŸŒ• {get_text(rule)}\nğŸ’¡ {get_advice(rule)}")

        # Check daily Ten God energy (ilgan)
        if dominant_god:
            god_category = ""
            if dominant_god in ["ë¹„ê²¬", "ê²ì¬"]:
                god_category = "bigyeop"
            elif dominant_god in ["ì‹ì‹ ", "ìƒê´€"]:
                god_category = "siksang"
            elif dominant_god in ["ì •ì¬", "í¸ì¬"]:
                god_category = "jaesung"
            elif dominant_god in ["ì •ê´€", "í¸ê´€"]:
                god_category = "gwansung"
            elif dominant_god in ["ì •ì¸", "í¸ì¸"]:
                god_category = "insung"

            if god_category:
                rule_key = f"rule_ilgan_{god_category}"
                rule = daily_rules.get(rule_key)
                if rule:
                    results.append(f"ğŸ“… ì˜¤ëŠ˜ì˜ ê¸°ìš´ [{dominant_god}]: {get_text(rule)}\nğŸ’¡ {get_advice(rule)}")

    # ===============================================================
    # 2. MONTHLY RULES - Seasonal energy, monthly transits
    # ===============================================================
    if "monthly" in loaded_rules:
        monthly_rules = loaded_rules["monthly"]

        # Check monthly Ten God energy (wolgon)
        if dominant_god:
            god_category = ""
            if dominant_god in ["ë¹„ê²¬", "ê²ì¬"]:
                god_category = "bigyeop"
            elif dominant_god in ["ì‹ì‹ ", "ìƒê´€"]:
                god_category = "siksang"
            elif dominant_god in ["ì •ì¬", "í¸ì¬"]:
                god_category = "jaesung"
            elif dominant_god in ["ì •ê´€", "í¸ê´€"]:
                god_category = "gwansung"
            elif dominant_god in ["ì •ì¸", "í¸ì¸"]:
                god_category = "insung"

            if god_category:
                rule_key = f"rule_wolgon_{god_category}"
                rule = monthly_rules.get(rule_key)
                if rule:
                    results.append(f"ğŸ“† ì´ë²ˆ ë‹¬ ì—ë„ˆì§€ [{dominant_god}]: {get_text(rule)}\nğŸ’¡ {get_advice(rule)}")

        # Check for eclipse month (simple approximation - eclipse seasons)
        if now.month in [3, 4, 9, 10]:  # Approximate eclipse seasons
            rule = monthly_rules.get("rule_eclipse_month")
            if rule and rule.get("weight", 0) >= 8:
                results.append(f"ğŸŒ“ {get_text(rule)}\nğŸ’¡ {get_advice(rule)}")

    # ===============================================================
    # 3. NEW YEAR / 2025 RULES - Annual themes, daeun
    # ===============================================================
    if "new_year" in loaded_rules and theme in ["focus_2025", "focus_overall"]:
        new_year_rules = loaded_rules["new_year"]

        # Check daeun (10-year luck cycle) based on dominant god
        if dominant_god:
            god_category = ""
            if dominant_god in ["ë¹„ê²¬", "ê²ì¬"]:
                god_category = "bigyeop"
            elif dominant_god in ["ì‹ì‹ ", "ìƒê´€"]:
                god_category = "siksang"
            elif dominant_god in ["ì •ì¬", "í¸ì¬"]:
                god_category = "jaesung"
            elif dominant_god in ["ì •ê´€", "í¸ê´€"]:
                god_category = "gwansung"
            elif dominant_god in ["ì •ì¸", "í¸ì¸"]:
                god_category = "insung"

            if god_category:
                rule_key = f"rule_daeun_{god_category}"
                rule = new_year_rules.get(rule_key)
                if rule:
                    results.append(f"ğŸŠ 2025ë…„ ëŒ€ìš´ [{dominant_god}]: {get_text(rule)}\nğŸ’¡ {get_advice(rule)}")

        # Check year pillar harmony/clash (simplified)
        # 2025 is ì„ì‚¬ë…„ (ä¹™å·³å¹´) - Wood Snake
        year_snake_compatible = ["ì", "ì¶•", "ì‹ ", "ìœ "]  # Generally harmonious
        year_snake_clash = ["í•´"]  # ì‚¬í•´ì¶©

        day_branch = saju_data.get("dayPillar", {}).get("earthlyBranch", "")
        branch_ko = {"å­": "ì", "ä¸‘": "ì¶•", "å¯…": "ì¸", "å¯": "ë¬˜", "è¾°": "ì§„", "å·³": "ì‚¬",
                     "åˆ": "ì˜¤", "æœª": "ë¯¸", "ç”³": "ì‹ ", "é…‰": "ìœ ", "æˆŒ": "ìˆ ", "äº¥": "í•´"}.get(day_branch, "")

        if branch_ko in year_snake_compatible:
            rule = new_year_rules.get("rule_year_pillar_match")
            if rule:
                results.append(f"âœ¨ 2025ë…„ ìš´ì„¸ ì¡°í™”: {get_text(rule)}\nğŸ’¡ {get_advice(rule)}")
        elif branch_ko in year_snake_clash:
            rule = new_year_rules.get("rule_year_pillar_clash")
            if rule:
                results.append(f"âš¡ 2025ë…„ ë³€í™”ì˜ í•´: {get_text(rule)}\nğŸ’¡ {get_advice(rule)}")

    # ===============================================================
    # 4. NEXT YEAR RULES - Future planning
    # ===============================================================
    if "next_year" in loaded_rules and theme in ["focus_2025"]:
        next_year_rules = loaded_rules["next_year"]

        # Seun (yearly luck) based on dominant god
        if dominant_god:
            god_category = ""
            if dominant_god in ["ë¹„ê²¬", "ê²ì¬"]:
                god_category = "bigyeop"
            elif dominant_god in ["ì‹ì‹ ", "ìƒê´€"]:
                god_category = "siksang"
            elif dominant_god in ["ì •ì¬", "í¸ì¬"]:
                god_category = "jaesung"
            elif dominant_god in ["ì •ê´€", "í¸ê´€"]:
                god_category = "gwansung"
            elif dominant_god in ["ì •ì¸", "í¸ì¸"]:
                god_category = "insung"

            if god_category:
                rule_key = f"rule_seun_{god_category}"
                rule = next_year_rules.get(rule_key)
                if rule:
                    results.append(f"ğŸ”® 2026ë…„ ì„¸ìš´ ì „ë§ [{dominant_god}]: {get_text(rule)}\nğŸ’¡ {get_advice(rule)}")

    # ===============================================================
    # 5. FAMILY RULES - Relationship dynamics
    # ===============================================================
    if "family" in loaded_rules and theme in ["focus_love", "focus_family", "focus_compatibility"]:
        family_rules = loaded_rules["family"]

        # Check moon house position for family dynamics
        moon_house = astro_data.get("moon", {}).get("house")
        if moon_house:
            house_num = str(moon_house).replace("H", "")
            rule_key = f"rule_moon_{house_num}"
            rule = family_rules.get(rule_key)
            if rule:
                results.append(f"ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ ê°€ì¡± ê´€ê³„ [ë‹¬ {house_num}í•˜ìš°ìŠ¤]: {get_text(rule)}\nğŸ’¡ {get_advice(rule)}")

        # Check venus for relationships
        venus_house = astro_data.get("venus", {}).get("house")
        if venus_house:
            house_num = str(venus_house).replace("H", "")
            rule_key = f"rule_venus_{house_num}"
            rule = family_rules.get(rule_key)
            if rule:
                results.append(f"ğŸ’• ê´€ê³„ ì—ë„ˆì§€ [ê¸ˆì„± {house_num}í•˜ìš°ìŠ¤]: {get_text(rule)}\nğŸ’¡ {get_advice(rule)}")

    # ===============================================================
    # 5-1. HEALTH RULES - Element balance, 6th/12th house
    # ===============================================================
    if "health" in loaded_rules and theme == "focus_health":
        health_rules = loaded_rules["health"]

        # Check element deficiencies
        element_counts = saju_data.get("elementCounts", {})
        element_map = {"æœ¨": "wood", "ç«": "fire", "åœŸ": "earth", "é‡‘": "metal", "æ°´": "water"}

        for elem_ko, elem_en in element_map.items():
            count = element_counts.get(elem_ko, 0)
            if count == 0:
                rule_key = f"rule_{elem_en}_zero"
                rule = health_rules.get(rule_key)
                if rule:
                    results.append(f"âš•ï¸ ì˜¤í–‰ ë¶€ì¡± [{elem_ko}]: {get_text(rule)}\nğŸ’¡ {get_advice(rule)}")
            elif count >= 3:
                rule_key = f"rule_{elem_en}_high"
                rule = health_rules.get(rule_key)
                if rule:
                    results.append(f"âš•ï¸ ì˜¤í–‰ ê³¼ë‹¤ [{elem_ko}]: {get_text(rule)}\nğŸ’¡ {get_advice(rule)}")

        # Check health houses (6, 12)
        for planet in ["mars", "saturn", "moon", "neptune", "jupiter", "pluto"]:
            planet_data = astro_data.get(planet, {})
            house = planet_data.get("house")
            if house:
                house_num = str(house).replace("H", "")
                if house_num in ["6", "12", "1"]:
                    rule_key = f"rule_{planet}_{house_num}"
                    rule = health_rules.get(rule_key)
                    if rule:
                        results.append(f"ğŸ¥ ê±´ê°• ê´€ë¦¬ [{planet} {house_num}í•˜ìš°ìŠ¤]: {get_text(rule)}\nğŸ’¡ {get_advice(rule)}")

    # ===============================================================
    # 5-2. WEALTH RULES - Money houses, financial potential
    # ===============================================================
    if "wealth" in loaded_rules and theme == "focus_wealth":
        wealth_rules = loaded_rules["wealth"]

        # Check money houses (2, 8, 10, 11)
        for planet in ["jupiter", "venus", "saturn", "uranus", "pluto", "moon", "mars", "mercury", "sun"]:
            planet_data = astro_data.get(planet, {})
            house = planet_data.get("house")
            if house:
                house_num = str(house).replace("H", "")
                if house_num in ["2", "8", "10", "11"]:
                    rule_key = f"rule_{planet}_{house_num}"
                    rule = wealth_rules.get(rule_key)
                    if rule:
                        results.append(f"ğŸ’° ì¬ë¬¼ìš´ [{planet} {house_num}í•˜ìš°ìŠ¤]: {get_text(rule)}\nğŸ’¡ {get_advice(rule)}")

        # Check jaesung (ì¬ì„±) strength
        ten_gods_count = saju_data.get("tenGodsCount", {})
        jaesung_count = ten_gods_count.get("ì •ì¬", 0) + ten_gods_count.get("í¸ì¬", 0)
        if jaesung_count >= 2:
            rule = wealth_rules.get("rule_jaesung_strong")
            if rule:
                results.append(f"ğŸ’ ì¬ì„± ë¶„ì„: {get_text(rule)}\nğŸ’¡ {get_advice(rule)}")
        elif jaesung_count == 0:
            rule = wealth_rules.get("rule_jaesung_weak")
            if rule:
                results.append(f"ğŸ’ ì¬ì„± ë¶„ì„: {get_text(rule)}\nğŸ’¡ {get_advice(rule)}")

    # ===============================================================
    # 6. LIFE PATH RULES - Soul purpose, individuation
    # ===============================================================
    if "life_path" in loaded_rules and theme in ["focus_overall", "chat"]:
        life_path_rules = loaded_rules["life_path"]

        # Check sun house for life purpose
        sun_house = astro_data.get("sun", {}).get("house")
        if sun_house:
            house_num = str(sun_house).replace("H", "")
            rule_key = f"rule_sun_{house_num}"
            rule = life_path_rules.get(rule_key)
            if rule:
                results.append(f"ğŸŒŸ ì¸ìƒ ë°©í–¥ [íƒœì–‘ {house_num}í•˜ìš°ìŠ¤]: {get_text(rule)}\nğŸ’¡ {get_advice(rule)}")

        # Check north node for karmic direction
        north_node = astro_data.get("northNode", {}) or astro_data.get("north_node", {})
        nn_house = north_node.get("house")
        if nn_house:
            house_num = str(nn_house).replace("H", "")
            rule_key = f"rule_north_node_{house_num}"
            rule = life_path_rules.get(rule_key)
            if rule:
                results.append(f"ğŸ§­ ì˜í˜¼ì˜ ì„±ì¥ ë°©í–¥ [ë¶êµì  {house_num}í•˜ìš°ìŠ¤]: {get_text(rule)}\nğŸ’¡ {get_advice(rule)}")

    # Limit results and format
    if results:
        logger.info(f"[THEME-FUSION] Generated {len(results)} theme-specific insights for {theme}")
        return "\n\n".join(results[:5])  # Top 5 insights

    return ""


# ===============================================================
# ğŸš€ SESSION RAG CACHE - Pre-computed RAG data for fast chat
# ===============================================================
import threading
from datetime import datetime, timedelta

# In-memory session cache: session_id -> {data, created_at, last_accessed}
_SESSION_RAG_CACHE = {}
_SESSION_CACHE_LOCK = threading.Lock()
SESSION_CACHE_TTL_MINUTES = 60  # Session data expires after 60 minutes
SESSION_CACHE_MAX_SIZE = 50  # Max number of sessions to cache (LRU eviction)


def _cleanup_expired_sessions():
    """Remove expired session data."""
    now = datetime.now()
    expired = []
    with _SESSION_CACHE_LOCK:
        for sid, data in _SESSION_RAG_CACHE.items():
            if now - data.get("created_at", now) > timedelta(minutes=SESSION_CACHE_TTL_MINUTES):
                expired.append(sid)
        for sid in expired:
            del _SESSION_RAG_CACHE[sid]
    if expired:
        logger.info(f"[SESSION-CACHE] Cleaned up {len(expired)} expired sessions")


def _evict_lru_sessions(keep_count: int = SESSION_CACHE_MAX_SIZE):
    """Evict least recently used sessions to maintain cache size."""
    with _SESSION_CACHE_LOCK:
        if len(_SESSION_RAG_CACHE) <= keep_count:
            return
        # Sort by last_accessed time (oldest first)
        sorted_sessions = sorted(
            _SESSION_RAG_CACHE.items(),
            key=lambda x: x[1].get("last_accessed", x[1].get("created_at", datetime.min))
        )
        # Evict oldest sessions until we're under the limit
        evict_count = len(_SESSION_RAG_CACHE) - keep_count
        for sid, _ in sorted_sessions[:evict_count]:
            del _SESSION_RAG_CACHE[sid]
        logger.info(f"[SESSION-CACHE] LRU evicted {evict_count} sessions, {len(_SESSION_RAG_CACHE)} remaining")


def prefetch_all_rag_data(saju_data: dict, astro_data: dict, theme: str = "chat", locale: str = "ko") -> dict:
    """
    Pre-fetch relevant data from ALL RAG systems for a user's chart.
    Uses parallel execution for ~2-3x speedup.

    Returns:
        Dict with all pre-fetched RAG data
    """
    start_time = time.time()
    result = {
        "graph_nodes": [],
        "graph_context": "",
        "corpus_quotes": [],
        "persona_context": {},
        "cross_analysis": "",
    }

    # Build query from chart data (support both "heavenlyStem" and "name" for dayMaster)
    dm_data = saju_data.get("dayMaster", {})
    daymaster = dm_data.get("heavenlyStem") or dm_data.get("name", "")
    dm_element = dm_data.get("element", "")
    sun_sign = astro_data.get("sun", {}).get("sign", "")
    moon_sign = astro_data.get("moon", {}).get("sign", "")
    dominant = saju_data.get("dominantElement", "")

    # Build comprehensive query for embedding search
    query_parts = [theme, daymaster, dm_element, dominant]
    if sun_sign:
        query_parts.append(sun_sign)
    if moon_sign:
        query_parts.append(moon_sign)

    # Add planets and houses
    for planet in ["sun", "moon", "mercury", "venus", "mars", "jupiter", "saturn"]:
        p_data = astro_data.get(planet, {})
        if p_data.get("sign"):
            query_parts.append(p_data["sign"])
        if p_data.get("house"):
            query_parts.append(f"{planet} {p_data['house']}í•˜ìš°ìŠ¤")

    query = " ".join(filter(None, query_parts))
    logger.info(f"[PREFETCH] Query: {query[:100]}...")

    # Build facts dict for graph query (shared across tasks)
    facts = {
        "daymaster": daymaster,
        "element": dm_element,
        "sun_sign": sun_sign,
        "moon_sign": moon_sign,
        "theme": theme,
    }

    # Theme concepts for Jung quotes - ENHANCED with more keywords
    theme_concepts = {
        "career": "vocation calling work purpose self-realization individuation hero journey ì†Œëª… ì§ì—… ìì•„ì‹¤í˜„ ì˜ì›… ì—¬ì • ì‚¬ëª…",
        "love": "anima animus relationship shadow projection intimacy attachment ì•„ë‹ˆë§ˆ ì•„ë‹ˆë¬´ìŠ¤ ê·¸ë¦¼ì íˆ¬ì‚¬ ì¹œë°€ê° ê´€ê³„ ì‚¬ë‘",
        "health": "psyche wholeness integration healing body-mind ì¹˜ìœ  í†µí•© ì „ì²´ì„± ì‹¬ì‹  íšŒë³µ",
        "life_path": "individuation self persona shadow meaning transformation ê°œì„±í™” ìì•„ í˜ë¥´ì†Œë‚˜ ì˜ë¯¸ ë³€í™˜ ì„±ì¥",
        "wealth": "abundance value meaning purpose security prosperity ê°€ì¹˜ ì˜ë¯¸ ëª©ì  ì•ˆì • í’ìš”",
        "family": "complex archetype mother father inner child ì½¤í”Œë ‰ìŠ¤ ì›í˜• ë¶€ëª¨ ë‚´ë©´ì•„ì´ ê°€ì¡±",
        "chat": "self-discovery meaning crisis growth ìê¸°ë°œê²¬ ì˜ë¯¸ ìœ„ê¸° ì„±ì¥",
        "focus_career": "vocation calling work purpose self-realization ì†Œëª… ì§ì—… ìì•„ì‹¤í˜„ ì§„ë¡œ",
    }

    # --- Pre-load RAG instances (thread-safe) ---
    # SentenceTransformer encode() is NOT thread-safe, so we must load
    # instances in main thread and run queries SEQUENTIALLY
    _graph_rag_inst = get_graph_rag() if HAS_GRAPH_RAG else None
    _corpus_rag_inst = get_corpus_rag() if HAS_CORPUS_RAG else None
    _persona_rag_inst = get_persona_embed_rag() if HAS_PERSONA_EMBED else None

    # --- Execute RAG fetches SEQUENTIALLY (thread-safe) ---
    # GraphRAG
    try:
        if _graph_rag_inst:
            graph_result = _graph_rag_inst.query(
                facts, top_k=20,
                domain_priority=theme if theme in _graph_rag_inst.rules else "career"
            )
            result["graph_nodes"] = graph_result.get("matched_nodes", [])[:15]
            result["graph_context"] = graph_result.get("context_text", "")[:2000]
            if graph_result.get("rule_summary"):
                result["graph_rules"] = graph_result.get("rule_summary", [])[:5]
            logger.info(f"[PREFETCH] GraphRAG: {len(result['graph_nodes'])} nodes")
    except Exception as e:
        logger.warning(f"[PREFETCH] GraphRAG failed: {e}")

    # CorpusRAG (Jung quotes) - ENHANCED: fetch more quotes with diverse concepts
    try:
        if _corpus_rag_inst:
            jung_query_parts = [theme_concepts.get(theme, theme), query[:100]]
            jung_query = " ".join(jung_query_parts)
            # Primary theme-based quotes
            quotes = _corpus_rag_inst.search(jung_query, top_k=6, min_score=0.12)

            # Also fetch general wisdom quotes for variety
            general_queries = ["individuation growth ê°œì„±í™” ì„±ì¥", "shadow integration ê·¸ë¦¼ì í†µí•©"]
            for gq in general_queries:
                try:
                    extra_quotes = _corpus_rag_inst.search(gq, top_k=2, min_score=0.15)
                    quotes.extend(extra_quotes)
                except:
                    pass

            # Deduplicate and limit
            seen = set()
            unique_quotes = []
            for q in quotes:
                key = q.get("quote_kr", "") or q.get("quote_en", "")
                if key and key not in seen:
                    seen.add(key)
                    unique_quotes.append(q)
                if len(unique_quotes) >= 8:
                    break

            result["corpus_quotes"] = [
                {
                    "text_ko": q.get("quote_kr", ""),
                    "text_en": q.get("quote_en", ""),
                    "source": q.get("source", ""),
                    "concept": q.get("concept", ""),
                    "score": q.get("score", 0)
                }
                for q in unique_quotes
            ]
            logger.info(f"[PREFETCH] CorpusRAG: {len(result['corpus_quotes'])} quotes (enhanced)")
    except Exception as e:
        logger.warning(f"[PREFETCH] CorpusRAG failed: {e}")

    # PersonaEmbedRAG
    try:
        if _persona_rag_inst:
            persona_result = _persona_rag_inst.get_persona_context(query, top_k=5)
            result["persona_context"] = {
                "jung": persona_result.get("jung_insights", [])[:5],
                "stoic": persona_result.get("stoic_insights", [])[:5],
            }
            logger.info(f"[PREFETCH] PersonaEmbedRAG: {persona_result.get('total_matched', 0)} matches")
    except Exception as e:
        logger.warning(f"[PREFETCH] PersonaEmbedRAG failed: {e}")

    # Cross-analysis (no ML, thread-safe) - pass locale for proper language
    try:
        result["cross_analysis"] = get_cross_analysis_for_chart(saju_data, astro_data, theme, locale)
    except Exception as e:
        logger.warning(f"[PREFETCH] Cross-analysis failed: {e}")

    elapsed = time.time() - start_time
    logger.info(f"[PREFETCH] All RAG data prefetched in {elapsed:.2f}s (sequential)")
    result["prefetch_time_ms"] = int(elapsed * 1000)

    return result


def get_session_rag_cache(session_id: str) -> dict:
    """Get cached RAG data for a session. Updates last_accessed for LRU."""
    with _SESSION_CACHE_LOCK:
        cache_entry = _SESSION_RAG_CACHE.get(session_id)
        if cache_entry:
            # Check if expired
            if datetime.now() - cache_entry.get("created_at", datetime.now()) > timedelta(minutes=SESSION_CACHE_TTL_MINUTES):
                del _SESSION_RAG_CACHE[session_id]
                return None
            # Update last_accessed for LRU tracking
            cache_entry["last_accessed"] = datetime.now()
            return cache_entry.get("data")
    return None


def set_session_rag_cache(session_id: str, data: dict):
    """Store RAG data in session cache with LRU eviction."""
    now = datetime.now()
    with _SESSION_CACHE_LOCK:
        _SESSION_RAG_CACHE[session_id] = {
            "data": data,
            "created_at": now,
            "last_accessed": now,
        }
    # LRU eviction if cache is too large
    if len(_SESSION_RAG_CACHE) > SESSION_CACHE_MAX_SIZE:
        _cleanup_expired_sessions()  # First remove expired
        _evict_lru_sessions()  # Then evict LRU if still over limit


# ===============================================================
# ğŸš€ MODEL WARMUP - Preload models on startup for faster first request
# ===============================================================
def warmup_models():
    """Preload all singleton models and caches on startup."""
    logger.info("ğŸ”¥ Starting model warmup...")
    start = time.time()

    try:
        # 0. Cross-analysis cache (instant, no ML)
        _load_cross_analysis_cache()

        # 1. SentenceTransformer model + GraphRAG
        if HAS_GRAPH_RAG:
            model = get_model()
            logger.info(f"  âœ… SentenceTransformer loaded: {model.get_sentence_embedding_dimension()}d")

            # 2. GraphRAG with embeddings
            rag = get_graph_rag()
            logger.info(f"  âœ… GraphRAG loaded: {len(rag.graph.nodes())} nodes")

        # 3. Corpus RAG (Jung quotes)
        if HAS_CORPUS_RAG:
            corpus = get_corpus_rag()
            logger.info(f"  âœ… CorpusRAG loaded")

        # 4. Persona embeddings (if available)
        if HAS_PERSONA_EMBED:
            persona = get_persona_embed_rag()
            logger.info(f"  âœ… PersonaEmbedRAG loaded")

        # 5. Tarot RAG (if available)
        if HAS_TAROT:
            tarot = get_tarot_hybrid_rag()
            logger.info(f"  âœ… TarotHybridRAG loaded")

        # 6. Redis cache connection
        cache = get_cache()
        logger.info(f"  âœ… Redis cache: {'connected' if cache.enabled else 'memory fallback'}")

        elapsed = time.time() - start
        logger.info(f"ğŸ”¥ Model warmup completed in {elapsed:.2f}s")

    except Exception as e:
        logger.warning(f"âš ï¸ Warmup error (non-fatal): {e}")


# Auto-warmup on import if WARMUP_ON_START is set (for Gunicorn/production)
if os.getenv("WARMUP_ON_START", "").lower() in ("1", "true", "yes"):
    warmup_models()

# Simple token gate + rate limiting
ADMIN_TOKEN = os.getenv("ADMIN_API_TOKEN")
RATE_LIMIT = int(os.getenv("API_RATE_PER_MIN", "60"))
RATE_WINDOW_SECONDS = 60
_rate_state = defaultdict(list)  # ip -> timestamps
UNPROTECTED_PATHS = {"/", "/health", "/health/full", "/counselor/init"}


def _client_id() -> str:
    return (
        (request.headers.get("X-Forwarded-For") or "").split(",")[0].strip()
        or request.remote_addr
        or "unknown"
    )


def _check_rate() -> Tuple[bool, Optional[float]]:
    now = time.time()
    client = _client_id()
    window = [t for t in _rate_state[client] if now - t < RATE_WINDOW_SECONDS]
    _rate_state[client] = window
    if len(window) >= RATE_LIMIT:
        retry_after = max(0, RATE_WINDOW_SECONDS - (now - window[0]))
        return False, retry_after
    window.append(now)
    _rate_state[client] = window
    return True, None


def _require_auth() -> Optional[Tuple[dict, int]]:
    # Read token at request time to handle dotenv race conditions
    admin_token = os.getenv("ADMIN_API_TOKEN") or ADMIN_TOKEN
    if not admin_token:
        return None
    # Allow unauthenticated access to health endpoints for load balancers
    if request.path in UNPROTECTED_PATHS or request.method == "OPTIONS":
        return None
    auth_header = request.headers.get("Authorization", "")
    token = None
    if auth_header.lower().startswith("bearer "):
        token = auth_header[7:].strip()
    token = token or request.headers.get("X-API-KEY") or request.args.get("token")
    if token != admin_token:
        return {"status": "error", "message": "unauthorized"}, 401
    return None


@app.before_request
def before_request():
    g.request_id = str(uuid4())
    g._start_time = time.time()

    ok, retry_after = _check_rate()
    if not ok:
        logger.warning(
            f"[RATE_LIMIT] client={_client_id()} path={request.path} retry_after={retry_after}"
        )
        return (
            jsonify(
                {
                    "status": "error",
                    "message": "rate limit exceeded",
                    "retry_after": retry_after,
                }
            ),
            429,
        )

    auth_error = _require_auth()
    if auth_error:
        logger.warning(f"[AUTH] blocked client={_client_id()} path={request.path}")
        body, code = auth_error
        return jsonify(body), code


@app.after_request
def after_request(response):
    response.headers["X-Request-ID"] = getattr(g, "request_id", "")
    try:
        duration = time.time() - getattr(g, "_start_time", time.time())
        logger.info(
            f"[REQ] id={getattr(g, 'request_id', '')} path={request.path} "
            f"status={response.status_code} dur_ms={int(duration*1000)}"
        )
    except Exception:
        pass
    return response


# Helper functions for building chart context
def _build_saju_summary(saju_data: dict) -> str:
    """Build concise saju summary for chat context."""
    if not saju_data:
        return ""
    parts = []
    if saju_data.get("dayMaster"):
        dm = saju_data["dayMaster"]
        dm_stem = dm.get('heavenlyStem') or dm.get('name', '')
        parts.append(f"Day Master: {dm_stem} ({dm.get('element', '')})")
    if saju_data.get("yearPillar"):
        yp = saju_data["yearPillar"]
        parts.append(f"Year: {yp.get('heavenlyStem', '')}{yp.get('earthlyBranch', '')}")
    if saju_data.get("monthPillar"):
        mp = saju_data["monthPillar"]
        parts.append(f"Month: {mp.get('heavenlyStem', '')}{mp.get('earthlyBranch', '')}")
    if saju_data.get("dominantElement"):
        parts.append(f"Dominant: {saju_data['dominantElement']}")
    return "SAJU: " + " | ".join(parts) if parts else ""


def _build_astro_summary(astro_data: dict) -> str:
    """Build concise astro summary for chat context."""
    if not astro_data:
        return ""
    parts = []
    if astro_data.get("sun"):
        parts.append(f"Sun: {astro_data['sun'].get('sign', '')}")
    if astro_data.get("moon"):
        parts.append(f"Moon: {astro_data['moon'].get('sign', '')}")
    if astro_data.get("ascendant"):
        parts.append(f"Rising: {astro_data['ascendant'].get('sign', '')}")
    return "ASTRO: " + " | ".join(parts) if parts else ""


def _build_detailed_saju(saju_data: dict) -> str:
    """Build detailed saju context for personalized responses."""
    if not saju_data:
        return "ì‚¬ì£¼ ì •ë³´ ì—†ìŒ"

    lines = []

    # Four Pillars
    if saju_data.get("yearPillar"):
        yp = saju_data["yearPillar"]
        lines.append(f"ë…„ì£¼: {yp.get('heavenlyStem', '')}{yp.get('earthlyBranch', '')} ({yp.get('element', '')})")
    if saju_data.get("monthPillar"):
        mp = saju_data["monthPillar"]
        lines.append(f"ì›”ì£¼: {mp.get('heavenlyStem', '')}{mp.get('earthlyBranch', '')} ({mp.get('element', '')})")
    if saju_data.get("dayPillar"):
        dp = saju_data["dayPillar"]
        lines.append(f"ì¼ì£¼: {dp.get('heavenlyStem', '')}{dp.get('earthlyBranch', '')} ({dp.get('element', '')})")
    if saju_data.get("hourPillar"):
        hp = saju_data["hourPillar"]
        lines.append(f"ì‹œì£¼: {hp.get('heavenlyStem', '')}{hp.get('earthlyBranch', '')} ({hp.get('element', '')})")

    # Day Master (most important) - support both "heavenlyStem" and "name"
    if saju_data.get("dayMaster"):
        dm = saju_data["dayMaster"]
        dm_stem = dm.get('heavenlyStem') or dm.get('name', '')
        lines.append(f"ì¼ê°„(ë³¸ì¸): {dm_stem} - {dm.get('element', '')}ì˜ ê¸°ìš´")

    # Five Elements balance
    if saju_data.get("fiveElements"):
        fe = saju_data["fiveElements"]
        elements = [f"{k}({v})" for k, v in fe.items() if v]
        if elements:
            lines.append(f"ì˜¤í–‰ ë¶„í¬: {', '.join(elements)}")

    # Dominant element
    if saju_data.get("dominantElement"):
        lines.append(f"ì£¼ìš” ê¸°ìš´: {saju_data['dominantElement']}")

    # Ten Gods (if available)
    if saju_data.get("tenGods"):
        tg = saju_data["tenGods"]
        if isinstance(tg, dict):
            gods = [f"{k}: {v}" for k, v in list(tg.items())[:4]]
            if gods:
                lines.append(f"ì‹­ì‹ : {', '.join(gods)}")

    return "\n".join(lines) if lines else "ì‚¬ì£¼ ì •ë³´ ë¶€ì¡±"


def _build_detailed_astro(astro_data: dict) -> str:
    """Build detailed astrology context for personalized responses."""
    if not astro_data:
        return "ì ì„±ìˆ  ì •ë³´ ì—†ìŒ"

    lines = []
    from datetime import datetime
    now = datetime.now()

    # Big Three - ESSENTIAL
    sun_sign = ""
    moon_sign = ""
    if astro_data.get("sun"):
        sun = astro_data["sun"]
        sun_sign = sun.get('sign', '')
        house = sun.get('house', '')
        lines.append(f"â˜€ï¸ íƒœì–‘(ìì•„): {sun_sign} {sun.get('degree', '')}Â°" + (f" - {house}í•˜ìš°ìŠ¤" if house else ""))
    if astro_data.get("moon"):
        moon = astro_data["moon"]
        moon_sign = moon.get('sign', '')
        house = moon.get('house', '')
        lines.append(f"ğŸŒ™ ë‹¬(ê°ì •): {moon_sign} {moon.get('degree', '')}Â°" + (f" - {house}í•˜ìš°ìŠ¤" if house else ""))
    if astro_data.get("ascendant"):
        asc = astro_data["ascendant"]
        lines.append(f"â¬†ï¸ ìƒìŠ¹(ì™¸ì ): {asc.get('sign', '')} {asc.get('degree', '')}Â°")

    # Key planets with houses
    for planet, info in [("mercury", "ìˆ˜ì„±(ì†Œí†µ)"), ("venus", "ê¸ˆì„±(ì‚¬ë‘/ê´€ê³„)"),
                         ("mars", "í™”ì„±(ì—ë„ˆì§€)"), ("jupiter", "ëª©ì„±(í–‰ìš´/í™•ì¥)"),
                         ("saturn", "í† ì„±(ì‹œë ¨/ì±…ì„)")]:
        if astro_data.get(planet):
            p = astro_data[planet]
            house = p.get('house', '')
            lines.append(f"{info}: {p.get('sign', '')}" + (f" - {house}í•˜ìš°ìŠ¤" if house else ""))

    # Houses (if available)
    if astro_data.get("houses"):
        h = astro_data["houses"]
        lines.append("\nğŸ  ì£¼ìš” í•˜ìš°ìŠ¤:")
        if h.get("1"):
            lines.append(f"  1í•˜ìš°ìŠ¤(ìì•„): {h['1'].get('sign', '')}")
        if h.get("7"):
            lines.append(f"  7í•˜ìš°ìŠ¤(íŒŒíŠ¸ë„ˆ): {h['7'].get('sign', '')}")
        if h.get("10"):
            lines.append(f"  10í•˜ìš°ìŠ¤(ì»¤ë¦¬ì–´): {h['10'].get('sign', '')}")

    # Current transits - ADD TIMING CONTEXT for 2025
    lines.append(f"\nğŸ”® í˜„ì¬ íŠ¸ëœì§“ ({now.year}ë…„ {now.month}ì›”):")
    if now.year == 2025:
        if now.month <= 3:
            lines.append("â€¢ í† ì„± ë¬¼ê³ ê¸°ìë¦¬: ê°ì •ì  ê²½ê³„ í•™ìŠµ, ì˜ì  ì„±ìˆ™")
            lines.append("â€¢ ëª©ì„± ìŒë‘¥ì´ìë¦¬: ì†Œí†µê³¼ í•™ìŠµì˜ í™•ì¥ê¸°")
        elif now.month <= 6:
            lines.append("â€¢ í† ì„± ì–‘ìë¦¬ ì…ì„± (5ì›”): ìƒˆë¡œìš´ ì±…ì„ê³¼ ë„ì „ì˜ ì‹œì‘")
            lines.append("â€¢ ëª©ì„± ìŒë‘¥ì´ìë¦¬ ë§ˆë¬´ë¦¬: ì§€ì‹ í™•ì¥ ì™„ë£Œ")
        else:
            lines.append("â€¢ í† ì„± ì–‘ìë¦¬: ìê¸°ì£¼ë„ì  ì„±ì¥ì˜ ì‹œê¸°")
            lines.append("â€¢ ëª©ì„± ê²Œìë¦¬ (7ì›”~): ê°€ì •/ì •ì„œì  í’ìš”")
        lines.append("â€¢ ëª…ì™•ì„± ë¬¼ë³‘ìë¦¬: ì‚¬íšŒì  ë³€í˜, ê°œì¸ì˜ ë…ë¦½ì„± ê°•ì¡°")
    else:
        lines.append("â€¢ ì£¼ìš” í–‰ì„± íŠ¸ëœì§“ ì°¸ê³ í•˜ì—¬ í•´ì„")

    # Interpretation hints
    if sun_sign or moon_sign:
        lines.append("\nğŸ’¡ í•´ì„ í¬ì¸íŠ¸:")
        if sun_sign:
            lines.append(f"  íƒœì–‘ {sun_sign}: í•µì‹¬ ì •ì²´ì„±, ì‚¶ì˜ ëª©ì ")
        if moon_sign:
            lines.append(f"  ë‹¬ {moon_sign}: ê°ì • íŒ¨í„´, ë‚´ë©´ì˜ ìš•êµ¬")

    return "\n".join(lines) if lines else "ì ì„±ìˆ  ì •ë³´ ë¶€ì¡±"


# Health check
@app.route("/", methods=["GET"])
def index():
    return jsonify({"status": "ok", "message": "DestinyPal Fusion AI backend is running!"})


# Fusion endpoint with caching and performance optimization
@app.route("/ask", methods=["POST"])
def ask():
    """
    Accepts saju/astro/tarot facts + theme/locale/prompt and runs fusion logic.
    Enhanced with Redis caching and performance monitoring.
    """
    try:
        data = request.get_json(force=True)
        saju_data = data.get("saju") or {}
        astro_data = data.get("astro") or {}
        tarot_data = data.get("tarot") or {}
        theme = data.get("theme", "daily")
        locale = data.get("locale", "en")
        raw_prompt = data.get("prompt") or ""

        # Normalize dayMaster structure (nested -> flat)
        saju_data = normalize_day_master(saju_data)

        # Detect structured JSON prompts from frontend (these contain format instructions)
        is_structured_prompt = (
            "You MUST return a valid JSON object" in raw_prompt or
            '"lifeTimeline"' in raw_prompt or
            '"categoryAnalysis"' in raw_prompt
        )
        # Allow full prompt for structured requests, otherwise clamp to 500 chars
        prompt = raw_prompt if is_structured_prompt else raw_prompt[:500]
        if is_structured_prompt:
            logger.info(f"[ASK] Detected STRUCTURED JSON prompt (len={len(raw_prompt)})")

        # render_mode: "template" (AI ì—†ì´ ì¦‰ì‹œ) or "gpt" (AI ì‚¬ìš©)
        render_mode = data.get("render_mode", "gpt")
        logger.info(f"[ASK] id={g.request_id} theme={theme} locale={locale} render_mode={render_mode}")

        # DEBUG: Log saju.unse data received from frontend
        unse_data = saju_data.get("unse", {})
        logger.info(f"[ASK] saju.unse received: daeun={len(unse_data.get('daeun', []))}, annual={len(unse_data.get('annual', []))}")

        facts = {
            "theme": theme,
            "saju": saju_data,
            "astro": astro_data,
            "tarot": tarot_data,
            "prompt": prompt,
            "locale": locale,
            "render_mode": render_mode,  # ğŸ”¥ í…œí”Œë¦¿/AI ëª¨ë“œ êµ¬ë¶„
        }

        # Performance monitoring
        start_time = time.time()
        result = interpret_with_ai(facts)
        duration_ms = int((time.time() - start_time) * 1000)

        logger.info(f"[ASK] id={g.request_id} completed in {duration_ms}ms cache_hit={result.get('cached', False)}")

        # Add performance metadata
        if isinstance(result, dict):
            result["performance"] = {
                "duration_ms": duration_ms,
                "cached": result.get("cached", False)
            }

        return jsonify({"status": "success", "data": result})

    except Exception as e:
        logger.exception(f"[ERROR] id={getattr(g, 'request_id', '')} /ask failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/ask-stream", methods=["POST"])
def ask_stream():
    """
    Streaming version of /ask for real-time chat responses.
    Uses Server-Sent Events (SSE) for instant first-token response.

    If session_id is provided (from /counselor/init), uses pre-fetched RAG data
    for richer responses with all embedded knowledge.
    """
    try:
        # Ensure UTF-8 encoding for request data (Windows encoding fix)
        import json as json_mod
        raw_data = request.get_data(as_text=False)
        data = json_mod.loads(raw_data.decode('utf-8'))

        saju_data = data.get("saju") or {}
        astro_data = data.get("astro") or {}
        birth_data = data.get("birth") or {}
        theme = data.get("theme", "chat")
        locale = data.get("locale", "en")
        prompt = (data.get("prompt") or "")[:1500]  # Chat prompt limit
        session_id = data.get("session_id")  # Optional: use pre-fetched RAG data
        conversation_history = data.get("history") or []  # Previous messages for context
        user_context = data.get("user_context") or {}  # Premium: persona + session summaries
        cv_text = (data.get("cv_text") or "")[:4000]  # CV/Resume text for career consultations

        # Normalize dayMaster structure (nested -> flat)
        saju_data = normalize_day_master(saju_data)

        logger.info(f"[ASK-STREAM] id={g.request_id} theme={theme} locale={locale} session={session_id or 'none'} history_len={len(conversation_history)} has_user_ctx={bool(user_context)} cv_len={len(cv_text)}")
        logger.info(f"[ASK-STREAM] saju dayMaster: {saju_data.get('dayMaster', {})}")

        # Check for pre-fetched RAG data from session
        session_cache = None
        rag_context = ""
        if session_id:
            session_cache = get_session_rag_cache(session_id)
            if session_cache:
                logger.info(f"[ASK-STREAM] Using pre-fetched session data for {session_id}")
                # Use cached saju/astro if not provided in request
                if not saju_data:
                    saju_data = session_cache.get("saju_data", {})
                if not astro_data:
                    astro_data = session_cache.get("astro_data", {})

                # Build rich RAG context from pre-fetched data
                rag_data = session_cache.get("rag_data", {})

                # GraphRAG context
                if rag_data.get("graph_nodes"):
                    rag_context += "\n[ğŸ“Š ê´€ë ¨ ì§€ì‹ ê·¸ë˜í”„]\n"
                    rag_context += "\n".join(rag_data["graph_nodes"][:8])

                # Jung quotes
                if rag_data.get("corpus_quotes"):
                    rag_context += "\n\n[ğŸ“š ê´€ë ¨ ìœµ ì‹¬ë¦¬í•™ ì¸ìš©]\n"
                    for q in rag_data["corpus_quotes"][:3]:
                        rag_context += f"â€¢ {q.get('text_ko', q.get('text_en', ''))} ({q.get('source', '')})\n"

                # Persona insights
                persona = rag_data.get("persona_context", {})
                if persona.get("jung"):
                    rag_context += "\n[ğŸ§  ë¶„ì„ê°€ ê´€ì ]\n"
                    rag_context += "\n".join(f"â€¢ {i}" for i in persona["jung"][:3])
                if persona.get("stoic"):
                    rag_context += "\n\n[âš”ï¸ ìŠ¤í† ì•„ ì² í•™ ê´€ì ]\n"
                    rag_context += "\n".join(f"â€¢ {i}" for i in persona["stoic"][:3])

                logger.info(f"[ASK-STREAM] RAG context from session: {len(rag_context)} chars")
            else:
                logger.warning(f"[ASK-STREAM] Session {session_id} not found or expired")

        # If saju/astro not provided but birth info is, compute minimal data
        if not saju_data and birth_data.get("date") and birth_data.get("time"):
            try:
                saju_data = calculate_saju_data(
                    birth_data["date"],
                    birth_data["time"],
                    birth_data.get("gender", "male")
                )
            except Exception as e:
                logger.warning(f"[ASK-STREAM] Failed to compute saju: {e}")

        if not astro_data and birth_data.get("date") and birth_data.get("time"):
            try:
                lat = birth_data.get("lat") or birth_data.get("latitude") or 37.5665
                lon = birth_data.get("lon") or birth_data.get("longitude") or 126.9780
                # calculate_astrology_data expects a dict with year/month/day/hour/minute
                date_parts = birth_data["date"].split("-")  # "YYYY-MM-DD"
                time_parts = birth_data["time"].split(":")  # "HH:MM"
                astro_data = calculate_astrology_data({
                    "year": int(date_parts[0]),
                    "month": int(date_parts[1]),
                    "day": int(date_parts[2]),
                    "hour": int(time_parts[0]),
                    "minute": int(time_parts[1]) if len(time_parts) > 1 else 0,
                    "latitude": lat,
                    "longitude": lon,
                })
            except Exception as e:
                logger.warning(f"[ASK-STREAM] Failed to compute astro: {e}")

        # Build DETAILED chart context (not just summary)
        saju_detail = _build_detailed_saju(saju_data)
        astro_detail = _build_detailed_astro(astro_data)
        logger.info(f"[ASK-STREAM] saju_detail length: {len(saju_detail)}")
        logger.info(f"[ASK-STREAM] astro_detail length: {len(astro_detail)}")

        # Get cross-analysis (from session or instant lookup)
        cross_rules = ""
        if session_cache and session_cache.get("rag_data", {}).get("cross_analysis"):
            cross_rules = session_cache["rag_data"]["cross_analysis"]
        else:
            try:
                cross_rules = get_cross_analysis_for_chart(saju_data, astro_data, theme, locale)
                if cross_rules:
                    logger.info(f"[ASK-STREAM] Instant cross-analysis: {len(cross_rules)} chars, theme={theme}")
            except Exception as e:
                logger.warning(f"[ASK-STREAM] Cross-analysis lookup failed: {e}")

        # Build cross-analysis section
        cross_section = ""
        if cross_rules:
            cross_section = f"\n[ì‚¬ì£¼+ì ì„± êµì°¨ í•´ì„ ê·œì¹™]\n{cross_rules}\n"

        # Current date for time-relevant advice
        from datetime import datetime
        now = datetime.now()
        weekdays_ko = ["ì›”ìš”ì¼", "í™”ìš”ì¼", "ìˆ˜ìš”ì¼", "ëª©ìš”ì¼", "ê¸ˆìš”ì¼", "í† ìš”ì¼", "ì¼ìš”ì¼"]
        current_date_str = f"ì˜¤ëŠ˜: {now.year}ë…„ {now.month}ì›” {now.day}ì¼ ({weekdays_ko[now.weekday()]})"

        # Build user context section for returning users (premium feature)
        user_context_section = ""
        if user_context:
            persona = user_context.get("persona", {})
            recent_sessions = user_context.get("recentSessions", [])

            if persona.get("sessionCount", 0) > 0 or recent_sessions:
                user_context_section = "\n[ğŸ”„ ì´ì „ ìƒë‹´ ë§¥ë½]\n"

                # Persona memory
                if persona.get("sessionCount"):
                    user_context_section += f"â€¢ ì´ {persona['sessionCount']}íšŒ ìƒë‹´í•œ ì¬ë°©ë¬¸ ê³ ê°\n"
                if persona.get("lastTopics"):
                    topics = persona["lastTopics"][:3] if isinstance(persona["lastTopics"], list) else []
                    if topics:
                        user_context_section += f"â€¢ ì£¼ìš” ê´€ì‹¬ì‚¬: {', '.join(topics)}\n"
                if persona.get("emotionalTone"):
                    user_context_section += f"â€¢ ê°ì • ìƒíƒœ: {persona['emotionalTone']}\n"
                if persona.get("recurringIssues"):
                    issues = persona["recurringIssues"][:2] if isinstance(persona["recurringIssues"], list) else []
                    if issues:
                        user_context_section += f"â€¢ ë°˜ë³µ ì´ìŠˆ: {', '.join(issues)}\n"

                # Recent session summaries
                if recent_sessions:
                    user_context_section += "\n[ìµœê·¼ ëŒ€í™”]\n"
                    for sess in recent_sessions[:2]:  # Last 2 sessions
                        if sess.get("summary"):
                            user_context_section += f"â€¢ {sess['summary']}\n"
                        elif sess.get("keyTopics"):
                            topics_str = ", ".join(sess["keyTopics"][:3]) if isinstance(sess["keyTopics"], list) else ""
                            if topics_str:
                                user_context_section += f"â€¢ ì£¼ì œ: {topics_str}\n"

                user_context_section += "\nâ†’ ì¬ë°©ë¬¸ ê³ ê°ì´ë‹ˆ 'ë˜ ì˜¤ì…¨ë„¤ìš”' ê°™ì€ ì¹œê·¼í•œ ì¸ì‚¬ë¡œ ì‹œì‘í•˜ê³ , ì´ì „ ìƒë‹´ ë‚´ìš©ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì°¸ì¡°í•˜ì„¸ìš”.\n"
                logger.info(f"[ASK-STREAM] User context section: {len(user_context_section)} chars")

        # Build CV/Resume section - use CV whenever available (for career, life_path, chat themes)
        cv_section = ""
        if cv_text:
            cv_section = f"""
[ğŸ“„ ì‚¬ìš©ì ì´ë ¥ì„œ/CV]
{cv_text}

â†’ ìœ„ ì´ë ¥ì„œ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ê²½ë ¥, ê¸°ìˆ , ê²½í—˜ì— ë§ëŠ” êµ¬ì²´ì ì¸ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.
â†’ ì‚¬ì£¼/ì ì„± í•´ì„ê³¼ ì´ë ¥ì„œ ë‚´ìš©ì„ ì—°ê²°í•˜ì—¬ ê°œì¸í™”ëœ ì¡°ì–¸ì„ í•´ì£¼ì„¸ìš”.
â†’ ì»¤ë¦¬ì–´, ì§ì—…, ì ì„± ê´€ë ¨ ì§ˆë¬¸ì—ëŠ” ì´ë ¥ì„œ ì •ë³´ë¥¼ ì ê·¹ í™œìš©í•˜ì„¸ìš”.
"""
            logger.info(f"[ASK-STREAM] CV section added: {len(cv_text)} chars, theme={theme}")

        # ======================================================
        # ğŸŒ± LIFESPAN GUIDANCE - Age-appropriate psychological tasks
        # ======================================================
        lifespan_section = ""
        birth_year = None
        try:
            # Extract birth year from birth_data or saju_data
            if birth_data.get("date"):
                birth_year = int(birth_data["date"].split("-")[0])
            elif saju_data.get("birthYear"):
                birth_year = int(saju_data["birthYear"])
        except:
            pass

        if birth_year:
            lifespan_guidance = get_lifespan_guidance(birth_year)
            if lifespan_guidance and lifespan_guidance.get("stage_name"):
                stage = lifespan_guidance
                lifespan_section = f"""
[ğŸŒ± ìƒì• ì£¼ê¸°ë³„ ì‹¬ë¦¬ ê³¼ì œ: {stage['stage_name']} ({stage['age']}ì„¸)]
â€¢ ë°œë‹¬ ê³¼ì œ: {', '.join(stage.get('psychological_tasks', [])[:3])}
â€¢ í•µì‹¬ ì›í˜•: {stage.get('archetypal_themes', {}).get('primary', [''])[0] if isinstance(stage.get('archetypal_themes', {}).get('primary'), list) else ''}
â€¢ í”í•œ ìœ„ê¸°: {', '.join(stage.get('developmental_crises', stage.get('shadow_challenges', []))[:2])}
â€¢ ì‚¬ì£¼ ì—°ê²°: {stage.get('saju_parallel', {}).get('theme', '')}
â€¢ ì ì„± ì—°ê²°: {stage.get('astro_parallel', {}).get('theme', '')}

â†’ ì´ ìƒì•  ë‹¨ê³„ì— ë§ëŠ” ì¡°ì–¸ì„ í•´ì£¼ì„¸ìš”. ë‚˜ì´ì— ë§ì§€ ì•ŠëŠ” ì¡°ì–¸(ì˜ˆ: 20ëŒ€ì—ê²Œ 'ì€í‡´ ì¤€ë¹„')ì€ í”¼í•˜ì„¸ìš”.
"""
                logger.info(f"[ASK-STREAM] Lifespan guidance: {stage['stage_name']} (age {stage['age']})")

        # ======================================================
        # ğŸ¯ THEME FUSION RULES - Daily/Monthly/Yearly guidance
        # ======================================================
        theme_fusion_section = ""
        try:
            theme_fusion = get_theme_fusion_rules(saju_data, astro_data, theme, locale, birth_year)
            if theme_fusion:
                theme_fusion_section = f"""
[ğŸ¯ í…Œë§ˆë³„ ìœµí•© í•´ì„]
{theme_fusion}

â†’ ìœ„ í…Œë§ˆë³„ í•´ì„ì„ ìƒë‹´ ë‚´ìš©ì— ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ì„œ ì „ë‹¬í•˜ì„¸ìš”.
"""
                logger.info(f"[ASK-STREAM] Theme fusion rules added: {len(theme_fusion)} chars, theme={theme}")
        except Exception as e:
            logger.warning(f"[ASK-STREAM] Theme fusion rules failed: {e}")

        # ======================================================
        # ğŸ¨ ACTIVE IMAGINATION - Deep therapeutic prompts (optional)
        # ======================================================
        imagination_section = ""
        if prompt and any(k in prompt.lower() for k in ["ê¹Šì´", "ë‚´ë©´", "ë¬´ì˜ì‹", "ê·¸ë¦¼ì", "ëª…ìƒ", "ìƒìƒ"]):
            ai_prompts = get_active_imagination_prompts(prompt)
            if ai_prompts:
                imagination_section = f"""
[ğŸ¨ ì ê·¹ì  ìƒìƒ ê¸°ë²• - ì‹¬ì¸µ ì‘ì—…ìš©]
â€¢ ì‹œì‘ ì§ˆë¬¸: {ai_prompts.get('opening', [''])[0] if ai_prompts.get('opening') else ''}
â€¢ ì‹¬í™” ì§ˆë¬¸: {ai_prompts.get('deepening', [''])[0] if ai_prompts.get('deepening') else ''}
â€¢ í†µí•© ì§ˆë¬¸: {ai_prompts.get('integration', [''])[0] if ai_prompts.get('integration') else ''}

â†’ ì‚¬ìš©ìê°€ ê¹Šì€ ë‚´ë©´ ì‘ì—…ì„ ì›í•  ë•Œë§Œ ì´ ì§ˆë¬¸ë“¤ì„ í™œìš©í•˜ì„¸ìš”. ê°•ìš”í•˜ì§€ ë§ˆì„¸ìš”.
"""
                logger.info(f"[ASK-STREAM] Active imagination prompts added")

        # ======================================================
        # ğŸš¨ CRISIS DETECTION - Check for dangerous keywords
        # ======================================================
        crisis_response = None
        if HAS_COUNSELING and prompt:
            crisis_check = CrisisDetector.detect_crisis(prompt)
            if crisis_check["is_crisis"]:
                logger.warning(f"[ASK-STREAM] Crisis detected! severity={crisis_check['max_severity']}")
                crisis_response = CrisisDetector.get_crisis_response(
                    crisis_check["max_severity"],
                    locale=locale
                )
                if crisis_check["requires_immediate_action"]:
                    # Return safety response immediately via SSE
                    def crisis_generator():
                        msg = crisis_response.get("immediate_message", "")
                        if crisis_response.get("follow_up"):
                            msg += "\n\n" + crisis_response["follow_up"]
                        if crisis_response.get("closing"):
                            msg += "\n\n" + crisis_response["closing"]
                        yield f"data: {msg}\n\n"
                        yield "data: [DONE]\n\n"

                    return Response(
                        stream_with_context(crisis_generator()),
                        mimetype="text/event-stream",
                        headers={
                            "Cache-Control": "no-cache",
                            "Connection": "keep-alive",
                            "X-Accel-Buffering": "no",
                        }
                    )

        # Build crisis context for medium/medium_high severity (not immediate, but needs empathetic response)
        crisis_context_section = ""
        if crisis_response and not crisis_check.get("requires_immediate_action"):
            severity = crisis_check.get("max_severity", "")
            if severity == "medium_high":
                crisis_context_section = """
[âš ï¸ ì‚¬ìš©ì ê°ì • ìƒíƒœ: ë†’ì€ ìŠ¤íŠ¸ë ˆìŠ¤]
- ê³µê°ê³¼ ì•ˆì •ê°ì„ ì£¼ëŠ” í†¤ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”
- ë¨¼ì € ê°ì •ì„ ì¸ì •í•˜ê³  í˜¸í¡/ê·¸ë¼ìš´ë”© ê¸°ë²•ì„ ì•ˆë‚´í•˜ì„¸ìš”
- ì ìˆ  í•´ì„ì€ í¬ë§ì ì¸ ê´€ì ìœ¼ë¡œ ë¶€ë“œëŸ½ê²Œ ì „ë‹¬í•˜ì„¸ìš”
- í•„ìš”ì‹œ ì „ë¬¸ ìƒë‹´ ê¶Œìœ : ì •ì‹ ê±´ê°•ìœ„ê¸°ìƒë‹´ì „í™” 1577-0199
"""
            elif severity == "medium":
                crisis_context_section = """
[âš ï¸ ì‚¬ìš©ì ê°ì • ìƒíƒœ: í¬ë§ ì €í•˜]
- ê³µê°ê³¼ ë”°ëœ»í•¨ì„ ë‹´ì•„ ì‘ë‹µí•˜ì„¸ìš”
- ì‘ì€ í¬ë§ì´ë¼ë„ ì°¾ì„ ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ì„¸ìš”
- ì ìˆ  í•´ì„ì—ì„œ ê¸ì •ì  ê°€ëŠ¥ì„±ì„ ê°•ì¡°í•˜ì„¸ìš”
- "í˜¼ìê°€ ì•„ë‹ˆì—ìš”"ë¼ëŠ” ë©”ì‹œì§€ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì „ë‹¬í•˜ì„¸ìš”
"""
            logger.info(f"[ASK-STREAM] Added crisis context for severity={severity}")

        # Build therapeutic context based on question type - ENHANCED with Jung psychology
        therapeutic_section = ""
        if HAS_COUNSELING and prompt:
            prompt_lower = prompt.lower()
            # Detect question themes and add therapeutic guidance
            if any(k in prompt_lower for k in ["í˜ë“¤", "ìš°ìš¸", "ì§€ì³", "í¬ê¸°", "ì˜ë¯¸ì—†", "í—ˆë¬´"]):
                therapeutic_section = """
[ğŸ§  ì‹¬ë¦¬ìƒë‹´ ê°€ì´ë“œ: ì˜ë¯¸/ì •ì„œ ì§€ì§€]
- ë¨¼ì € ê°ì •ì„ ì¶©ë¶„íˆ ì¸ì •: "ì •ë§ í˜ë“œì…¨ê² ì–´ìš”... ê·¸ ë¬´ê²Œë¥¼ í˜¼ì ì§€ê³  ê³„ì…¨êµ°ìš”"
- ìœµ ê´€ì : "ì˜í˜¼ì˜ ì–´ë‘ìš´ ë°¤(dark night of soul)"ì€ ë³€í™”ì˜ ì „ì¡°
- ì‚¬ì£¼/ì ì„±ì—ì„œ 'ì „í™˜ì 'ì´ë‚˜ 'ì„±ì¥ê¸°'ë¥¼ ì°¾ì•„ í¬ë§ ì—°ê²°
- ê·¸ë¦¼ì ì‘ì—…: "ì´ í˜ë“¦ì´ ë‹¹ì‹ ì—ê²Œ ê°€ë¥´ì¹˜ë ¤ëŠ” ê²Œ ìˆë‹¤ë©´?"
- ì‘ì€ ì•¡ì…˜ ì œì•ˆ: "ì˜¤ëŠ˜ í•˜ë‚˜ë§Œ ìì‹ ì„ ìœ„í•´ í•œë‹¤ë©´ ë­˜ í•˜ê³  ì‹¶ìœ¼ì„¸ìš”?"
"""
            elif any(k in prompt_lower for k in ["ì—°ì• ", "ì‚¬ë‘", "ê²°í˜¼", "ì´ë³„", "ì§ì‚¬ë‘", "ì¸"]):
                therapeutic_section = """
[ğŸ§  ì‹¬ë¦¬ìƒë‹´ ê°€ì´ë“œ: ê´€ê³„/ì‚¬ë‘]
- ê°ì •ì˜ ê¹Šì´ë¥¼ ì¸ì •: "ë§ˆìŒì´ ë§ì´ ì“°ì´ì‹œë„¤ìš”"
- ìœµ ê´€ì  - ì•„ë‹ˆë§ˆ/ì•„ë‹ˆë¬´ìŠ¤ íˆ¬ì‚¬: "ëŒë¦¬ëŠ” ê·¸ íŠ¹ì„±ì´ í˜¹ì‹œ ë‚´ ì•ˆì—ë„ ìˆë‹¤ë©´?"
- ê·¸ë¦¼ì íˆ¬ì‚¬: "ì‹«ì€ ê·¸ ì ... ë‚´ ê·¸ë¦¼ìëŠ” ì•„ë‹ê¹Œìš”?"
- ì‚¬ì£¼ ê´€ì„±(å®˜æ˜Ÿ)/ì ì„± ê¸ˆì„±-7í•˜ìš°ìŠ¤ í•´ì„ì„ ì‹¬ë¦¬ì  íŒ¨í„´ê³¼ ì—°ê²°
- ì§ˆë¬¸ìœ¼ë¡œ ë§ˆë¬´ë¦¬: "ìƒëŒ€ì—ê²Œ ì§„ì§œ ì›í•˜ëŠ” ê±´ ë­˜ê¹Œìš”?" / "ì™„ë²½í•œ ê´€ê³„ë€ ì–´ë–¤ ëª¨ìŠµì´ì—ìš”?"
"""
            elif any(k in prompt_lower for k in ["ì·¨ì—…", "ì´ì§", "ì§„ë¡œ", "ì‚¬ì—…", "í‡´ì‚¬", "ì»¤ë¦¬ì–´"]):
                therapeutic_section = """
[ğŸ§  ì‹¬ë¦¬ìƒë‹´ ê°€ì´ë“œ: ì»¤ë¦¬ì–´/ì •ì²´ì„±]
- ë¶ˆì•ˆê° ì¸ì •: "ì¤‘ìš”í•œ ê²°ì • ì•ì—ì„œ ê³ ë¯¼ì´ ê¹Šìœ¼ì‹œë„¤ìš”"
- ìœµ ê´€ì  - ì†Œëª…(calling): "ëˆì„ ë– ë‚˜ì„œ, ì§„ì§œ í•˜ê³  ì‹¶ì€ ì¼ì€ ë­ì˜ˆìš”?"
- í˜ë¥´ì†Œë‚˜ vs ìê¸°(Self): "ì¼í•˜ëŠ” ë‚˜ vs ì§„ì§œ ë‚˜, ì–¼ë§ˆë‚˜ ë‹¤ë¥¸ê°€ìš”?"
- ì‚¬ì£¼ ì‹ìƒ/ì¬ì„±ê³¼ ì ì„± 10í•˜ìš°ìŠ¤/MC ì—°ê²°í•˜ì—¬ ì ì„± ë¶„ì„
- êµ¬ì²´ì  ì‹œê¸° ì œì‹œ: "2025ë…„ ìƒë°˜ê¸°ê°€ ì „í™˜ì " ì‹ìœ¼ë¡œ
- ì§ˆë¬¸: "ëˆ vs ë³´ëŒ, ì§€ê¸ˆ ë” ì¤‘ìš”í•œ ê±´?" / "5ë…„ ë’¤ ì–´ë–¤ ëª¨ìŠµì´ê³  ì‹¶ìœ¼ì„¸ìš”?"
"""
            elif any(k in prompt_lower for k in ["ë¶€ëª¨", "ì—„ë§ˆ", "ì•„ë¹ ", "ê°€ì¡±", "í˜•ì œ", "ìë§¤"]):
                therapeutic_section = """
[ğŸ§  ì‹¬ë¦¬ìƒë‹´ ê°€ì´ë“œ: ê°€ì¡±/ì½¤í”Œë ‰ìŠ¤]
- ê°€ì¡± ê´€ê³„ì˜ ë³µì¡í•¨ ì¸ì •: "ê°€ì¡±ì´ë¼ ë” ì–´ë µì£ "
- ìœµ ê´€ì  - ë¶€ëª¨ ì½¤í”Œë ‰ìŠ¤: ì–´ë¨¸ë‹ˆ/ì•„ë²„ì§€ ì›í˜•ì´ í˜„ì¬ ê´€ê³„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥
- ë‚´ë©´ì•„ì´ ì‘ì—…: "ì–´ë¦° ì‹œì ˆì˜ ë‚˜ì—ê²Œ ë­ë¼ê³  ë§í•´ì£¼ê³  ì‹¶ìœ¼ì„¸ìš”?"
- ì‚¬ì£¼ ì¸ì„±(å°æ˜Ÿ)/ê´€ì„±(å®˜æ˜Ÿ)ê³¼ 4í•˜ìš°ìŠ¤/10í•˜ìš°ìŠ¤ ë¶„ì„
- ì§ˆë¬¸: "ë¶€ëª¨ë‹˜ê»˜ ì§„ì§œ í•˜ê³  ì‹¶ì€ ë§ì€?" / "ìš©ì„œê°€ í•„ìš”í•œ ê±´ ëˆ„êµ¬ì¸ê°€ìš”?"
"""
            elif any(k in prompt_lower for k in ["ë¶ˆì•ˆ", "ê±±ì •", "ë‘ë ¤", "ë¬´ì„œ"]):
                therapeutic_section = """
[ğŸ§  ì‹¬ë¦¬ìƒë‹´ ê°€ì´ë“œ: ë¶ˆì•ˆ/ë‘ë ¤ì›€]
- ë¶ˆì•ˆ ì¸ì •: "ë¶ˆì•ˆí•œ ë§ˆìŒ, ì¶©ë¶„íˆ ì´í•´í•´ìš”"
- ìœµ ê´€ì : ë‘ë ¤ì›€ì€ ê·¸ë¦¼ìê°€ ë³´ë‚´ëŠ” ë©”ì‹œì§€ì¼ ìˆ˜ ìˆìŒ
- ê·¸ë¼ìš´ë”©: "ì§€ê¸ˆ ë°œì´ ë°”ë‹¥ì— ë‹¿ì•„ìˆëŠ” ê±¸ ëŠê»´ë³´ì„¸ìš”"
- ì§ˆë¬¸: "ê·¸ ë‘ë ¤ì›€ì´ ì‚¬ëŒì´ë¼ë©´, ë­ë¼ê³  ë§í•  ê²ƒ ê°™ì•„ìš”?"
- ì‚¬ì£¼/ì ì„±ì—ì„œ ì•ˆì •ê°ì„ ì¤„ ìˆ˜ ìˆëŠ” ì‹œê¸°ë‚˜ ìš”ì†Œ ì°¾ê¸°
"""
            elif any(k in prompt_lower for k in ["ì„±ê²©", "ë‚˜ëŠ”", "ì–´ë–¤ ì‚¬ëŒ", "ì¥ì ", "ë‹¨ì "]):
                therapeutic_section = """
[ğŸ§  ì‹¬ë¦¬ìƒë‹´ ê°€ì´ë“œ: ìê¸°íƒìƒ‰]
- í˜¸ê¸°ì‹¬ í‘œí˜„: "ìì‹ ì„ ì•Œê³  ì‹¶ì€ ë§ˆìŒì´ ë©‹ì§€ë„¤ìš”"
- ìœµ ê´€ì  - í˜ë¥´ì†Œë‚˜/ê·¸ë¦¼ì: ë³´ì—¬ì£¼ëŠ” ë‚˜ vs ìˆ¨ê¸°ëŠ” ë‚˜
- ì‚¬ì£¼ ì¼ê°„ íŠ¹ì„±ê³¼ ì ì„± íƒœì–‘/ìƒìŠ¹/ë‹¬ ì—°ê²°í•˜ì—¬ ë‹¤ì¸µì  ì„±ê²© ë¶„ì„
- ê·¸ë¦¼ì(ì•½ì )ë„ ì„±ì¥ ê°€ëŠ¥ì„±ìœ¼ë¡œ ì¬í•´ì„: "ê·¸ ì ì´ ê±´ê°•í•˜ê²Œ ë°œíœ˜ë˜ë©´?"
- ì§ˆë¬¸: "ê°€ì¥ 'ë‚˜ë‹µë‹¤'ê³  ëŠë‚„ ë•ŒëŠ”?" / "ë‚¨ë“¤ì€ ëª¨ë¥´ëŠ” ë‚˜ë§Œì˜ ëª¨ìŠµì´ ìˆë‹¤ë©´?"
"""
            elif any(k in prompt_lower for k in ["ê¿ˆ", "ì•…ëª½", "ê¿ˆì—ì„œ", "ê¿ˆì„ ê¿¨"]):
                therapeutic_section = """
[ğŸ§  ì‹¬ë¦¬ìƒë‹´ ê°€ì´ë“œ: ê¿ˆ í•´ì„]
- í˜¸ê¸°ì‹¬ í‘œí˜„: "í¥ë¯¸ë¡œìš´ ê¿ˆì´ë„¤ìš”. ë¬´ì˜ì‹ì´ ë©”ì‹œì§€ë¥¼ ë³´ë‚´ê³  ìˆì–´ìš”"
- ìœµ ê´€ì  - ê¿ˆì€ ë¬´ì˜ì‹ì˜ ì–¸ì–´: ìƒì§•ì  ì˜ë¯¸ íƒìƒ‰
- ê¿ˆì˜ ê°ì •ì— ì£¼ëª©: "ê·¸ ê¿ˆì—ì„œ ì–´ë–¤ ê°ì •ì´ ë“¤ì—ˆì–´ìš”?"
- í˜„ì¬ ìƒí™©ê³¼ ì—°ê²°: "ìš”ì¦˜ ì‚¶ì—ì„œ ë¹„ìŠ·í•œ ëŠë‚Œì´ ë“œëŠ” ê²Œ ìˆë‚˜ìš”?"
- ì ê·¹ì  ìƒìƒ ì œì•ˆ: "ê¿ˆ ì† ì¸ë¬¼ì—ê²Œ ë¬¼ì–´ë³¸ë‹¤ë©´, ë­˜ ë¬»ê³  ì‹¶ìœ¼ì„¸ìš”?"
"""
            elif any(k in prompt_lower for k in ["ì‹«ì–´", "ì§œì¦", "ë¯¸ì›Œ", "í˜ì˜¤"]):
                therapeutic_section = """
[ğŸ§  ì‹¬ë¦¬ìƒë‹´ ê°€ì´ë“œ: ê·¸ë¦¼ì íˆ¬ì‚¬]
- ê°ì • ì¸ì •: "ì •ë§ ë¶ˆí¸í•˜ì…¨ê² ì–´ìš”"
- ìœµ ê´€ì  - ê·¸ë¦¼ì íˆ¬ì‚¬: ê°•í•˜ê²Œ ì‹«ì€ ê²ƒì€ ë‚´ ê·¸ë¦¼ìì¼ ìˆ˜ ìˆìŒ
- ì§ˆë¬¸: "ê·¸ ì‚¬ëŒì˜ ì–´ë–¤ ì ì´ ê°€ì¥ ì‹«ìœ¼ì„¸ìš”?"
- ë„ì „: "ê·¸ íŠ¹ì„±ì´ í˜¹ì‹œ ë‚˜í•œí…Œë„ ì¡°ê¸ˆ ìˆë‹¤ë©´?"
- í†µí•©: "ê·¸ ì—ë„ˆì§€ë¥¼ ê±´ê°•í•˜ê²Œ ì“´ë‹¤ë©´ ì–´ë–¤ ëª¨ìŠµì¼ê¹Œìš”?"
"""
            elif any(k in prompt_lower for k in ["ì–¸ì œ", "ì‹œê¸°", "íƒ€ì´ë°", "ëª‡ ì›”", "ì˜¬í•´", "ë‚´ë…„"]):
                therapeutic_section = """
[ğŸ§  ì‹¬ë¦¬ìƒë‹´ ê°€ì´ë“œ: ì‹œê¸°/íƒ€ì´ë°]
- êµ¬ì²´ì  ì‹œê¸° ì œì‹œ í•„ìˆ˜: ì‚¬ì£¼ ëŒ€ìš´/ì„¸ìš´ + ì ì„± íŠ¸ëœì§“ ë¶„ì„
- ì›”/ë¶„ê¸° ë‹¨ìœ„ë¡œ ëª…í™•í•˜ê²Œ: "2025ë…„ 3-4ì›”ì´ ì¢‹ì•„ìš”"
- ì™œ ê·¸ ì‹œê¸°ì¸ì§€ ì„¤ëª…: "ëª©ì„±ì´ ~ì— ë“¤ì–´ì˜¤ë©´ì„œ..."
- ê·¸ ì‹œê¸°ì— í•  ì¼ ì œì•ˆ: "ì´ ì‹œê¸°ì— [êµ¬ì²´ì  í–‰ë™]ì„ ì‹œì‘í•˜ë©´ ì¢‹ê² ì–´ìš”"
- ì£¼ì˜í•  ì‹œê¸°ë„ í•¨ê»˜: "ë‹¤ë§Œ ~ì›”ì€ ì‹ ì¤‘í•˜ê²Œ"
"""

        # Build system prompt - Enhanced counselor persona with Jung-inspired therapeutic approach
        counselor_persona = """ë‹¹ì‹ ì€ ì‚¬ì£¼+ì ì„±ìˆ  í†µí•© ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.

âš ï¸ ì ˆëŒ€ ê·œì¹™:
1. ì¸ì‚¬ ê¸ˆì§€ - "ì•ˆë…•í•˜ì„¸ìš”", "ë°˜ê°€ì›Œìš”" ë“± ì¸ì‚¬ ì ˆëŒ€ ê¸ˆì§€
2. ì‹ ìƒ ì†Œê°œ ê¸ˆì§€ - "ì¼ê°„ì´ Xì…ë‹ˆë‹¤", "ë‹¹ì‹ ì€ Y ì„±í–¥" ê°™ì€ ê¸°ë³¸ ì„¤ëª… ê¸ˆì§€. ì‚¬ìš©ìëŠ” ì´ë¯¸ ìê¸° ì‚¬ì£¼ë¥¼ ì•ˆë‹¤. ë°”ë¡œ ì§ˆë¬¸ì— ë‹µí•´.
3. ì œê³µëœ ë°ì´í„°ë§Œ ì‚¬ìš© - ëŒ€ìš´/ì„¸ìš´ì„ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”. ì•„ë˜ [ì‚¬ì£¼ ë¶„ì„]ì— ìˆëŠ” ê·¸ëŒ€ë¡œë§Œ ì¸ìš©
4. ì²« ë¬¸ì¥ë¶€í„° ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ìœ¼ë¡œ ì‹œì‘

ğŸ’¬ ìƒë‹´ ìŠ¤íƒ€ì¼:
â€¢ ìƒì„¸í•˜ê³  ê¹Šì´ ìˆëŠ” ë¶„ì„ (400-600ë‹¨ì–´)
â€¢ ì‚¬ì£¼ì™€ ì ì„±ìˆ  ê· í˜•ìˆê²Œ í™œìš©í•˜ë˜ ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ë‚´
â€¢ êµ¬ì²´ì  ë‚ ì§œ/ì‹œê¸° ì œì‹œ
â€¢ 'ì™œ ê·¸ëŸ°ì§€' ì´ìœ ë¥¼ ì¶©ë¶„íˆ ì„¤ëª…"""

        if rag_context:
            # RICH prompt with all RAG data
            system_prompt = f"""{counselor_persona}

âš ï¸ {current_date_str} - ê³¼ê±° ë‚ ì§œë¥¼ ë¯¸ë˜ì²˜ëŸ¼ ë§í•˜ì§€ ë§ˆì„¸ìš”

[ğŸ“Š ì‚¬ì£¼ ë¶„ì„]
{saju_detail}

[ğŸŒŸ ì ì„± ë¶„ì„]
{astro_detail}
{cross_section}
{rag_context}
{user_context_section}{cv_section}{lifespan_section}{theme_fusion_section}{imagination_section}{crisis_context_section}{therapeutic_section}

[ğŸ¯ ì‘ë‹µ ìŠ¤íƒ€ì¼]
â€¢ ì²« ë¬¸ì¥ë¶€í„° ì‚¬ìš©ì ì§ˆë¬¸ì— ì§ì ‘ ë‹µë³€ - ì‹ ìƒ ì†Œê°œ NO
â€¢ ì‚¬ì£¼ì™€ ì ì„±ìˆ  í†µì°°ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ì„œ ì„¤ëª…
â€¢ 'ì™œ ê·¸ëŸ°ì§€' ì´ìœ ë¥¼ ìƒì„¸íˆ í’€ì–´ì„œ ì„¤ëª…
â€¢ êµ¬ì²´ì ì¸ ë‚ ì§œ/ì‹œê¸° ë°˜ë“œì‹œ í¬í•¨
â€¢ ì‹¤ì²œ ê°€ëŠ¥í•œ êµ¬ì²´ì  ì¡°ì–¸ ì œê³µ

âŒ ì ˆëŒ€ ê¸ˆì§€:
â€¢ ì¸ì‚¬/í™˜ì˜ ë©˜íŠ¸ ("ì•ˆë…•í•˜ì„¸ìš”", "ë‹¤ì‹œ ì°¾ì•„ì£¼ì…¨ë„¤ìš”")
â€¢ ì‹ ìƒ ì†Œê°œ ("ì¼ê°„ì´ Xì…ë‹ˆë‹¤", "ë‹¹ì‹ ì€ Y ì„±í–¥" ë“±)
â€¢ ëŒ€ìš´/ì„¸ìš´ ì§€ì–´ë‚´ê¸° (ìœ„ ë°ì´í„°ì— ì—†ëŠ” ê²ƒ ì–¸ê¸‰)
â€¢ ì¶”ìƒì  ë§ë§Œ ë‚˜ì—´ (êµ¬ì²´ì  ì‹œê¸° ì—†ì´)
â€¢ í”¼ìƒì ì´ê³  ì§§ì€ ë‹µë³€

ğŸ“Œ ì‘ë‹µ ê¸¸ì´: 400-600ë‹¨ì–´ë¡œ ì¶©ë¶„íˆ ìƒì„¸í•˜ê²Œ ({locale})"""
        else:
            # Standard prompt (no session data)
            system_prompt = f"""{counselor_persona}

âš ï¸ {current_date_str} - ê³¼ê±° ë‚ ì§œë¥¼ ë¯¸ë˜ì²˜ëŸ¼ ë§í•˜ì§€ ë§ˆì„¸ìš”

[ğŸ“Š ì‚¬ì£¼ ë¶„ì„]
{saju_detail}

[ğŸŒŸ ì ì„± ë¶„ì„]
{astro_detail}
{cross_section}
{user_context_section}{cv_section}{lifespan_section}{theme_fusion_section}{imagination_section}{crisis_context_section}{therapeutic_section}

[ğŸ¯ ì‘ë‹µ ìŠ¤íƒ€ì¼]
â€¢ ì²« ë¬¸ì¥ë¶€í„° ì‚¬ìš©ì ì§ˆë¬¸ì— ì§ì ‘ ë‹µë³€ - ì‹ ìƒ ì†Œê°œ NO
â€¢ ì‚¬ì£¼ì™€ ì ì„±ìˆ  í†µì°°ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ì„œ ì„¤ëª…
â€¢ 'ì™œ ê·¸ëŸ°ì§€' ì´ìœ ë¥¼ ìƒì„¸íˆ í’€ì–´ì„œ ì„¤ëª…
â€¢ êµ¬ì²´ì ì¸ ë‚ ì§œ/ì‹œê¸° ë°˜ë“œì‹œ í¬í•¨
â€¢ ì‹¤ì²œ ê°€ëŠ¥í•œ êµ¬ì²´ì  ì¡°ì–¸ ì œê³µ

âŒ ì ˆëŒ€ ê¸ˆì§€:
â€¢ ì¸ì‚¬/í™˜ì˜ ë©˜íŠ¸ ("ì•ˆë…•í•˜ì„¸ìš”", "ë‹¤ì‹œ ì°¾ì•„ì£¼ì…¨ë„¤ìš”")
â€¢ ì‹ ìƒ ì†Œê°œ ("ì¼ê°„ì´ Xì…ë‹ˆë‹¤", "ë‹¹ì‹ ì€ Y ì„±í–¥" ë“±)
â€¢ ëŒ€ìš´/ì„¸ìš´ ì§€ì–´ë‚´ê¸° (ìœ„ ë°ì´í„°ì— ì—†ëŠ” ê²ƒ ì–¸ê¸‰)
â€¢ ì¶”ìƒì  ë§ë§Œ ë‚˜ì—´ (êµ¬ì²´ì  ì‹œê¸° ì—†ì´)
â€¢ í”¼ìƒì ì´ê³  ì§§ì€ ë‹µë³€

ğŸ“Œ ì‘ë‹µ ê¸¸ì´: 400-600ë‹¨ì–´ë¡œ ì¶©ë¶„íˆ ìƒì„¸í•˜ê²Œ ({locale})"""
        # ======================================================
        # EMOTION TRACKING - Detect user's emotional state
        # ======================================================
        emotion_context = ""
        if prompt:
            prompt_lower = prompt.lower()
            # Detect emotional indicators
            emotions_detected = []
            if any(k in prompt_lower for k in ["í˜ë“¤", "ì§€ì³", "í”¼ê³¤", "ì§€ì¹¨"]):
                emotions_detected.append("exhausted")
            if any(k in prompt_lower for k in ["ìš°ìš¸", "ìŠ¬í¼", "ëˆˆë¬¼", "ìš¸ê³ "]):
                emotions_detected.append("sad")
            if any(k in prompt_lower for k in ["ë¶ˆì•ˆ", "ê±±ì •", "ë‘ë ¤", "ë¬´ì„œ"]):
                emotions_detected.append("anxious")
            if any(k in prompt_lower for k in ["í™”ë‚˜", "ì§œì¦", "ì–µìš¸", "ë¶„ë…¸"]):
                emotions_detected.append("angry")
            if any(k in prompt_lower for k in ["ì™¸ë¡œ", "í˜¼ì", "ê³ ë…"]):
                emotions_detected.append("lonely")
            if any(k in prompt_lower for k in ["ì„¤ë ˆ", "ê¸°ëŒ€", "í–‰ë³µ", "ì¢‹ì•„"]):
                emotions_detected.append("hopeful")
            if any(k in prompt_lower for k in ["í˜¼ë€", "ëª¨ë¥´ê² ", "ì–´ë–»ê²Œ", "ë­˜ í•´ì•¼"]):
                emotions_detected.append("confused")

            if emotions_detected:
                emotion_map = {
                    "exhausted": "ì§€ì¹¨/í”¼ë¡œ",
                    "sad": "ìŠ¬í””/ìš°ìš¸",
                    "anxious": "ë¶ˆì•ˆ/ê±±ì •",
                    "angry": "ë¶„ë…¸/ë‹µë‹µ",
                    "lonely": "ì™¸ë¡œì›€",
                    "hopeful": "í¬ë§/ì„¤ë ˜",
                    "confused": "í˜¼ë€/ë°©í–¥ìƒì‹¤"
                }
                detected_ko = [emotion_map.get(e, e) for e in emotions_detected]
                emotion_context = f"\n[ğŸ’­ ê°ì§€ëœ ê°ì • ìƒíƒœ: {', '.join(detected_ko)}]\nâ†’ ì´ ê°ì •ì„ ë¨¼ì € ì¸ì •í•˜ê³  ê³µê°í•˜ì„¸ìš”. ì„±ê¸‰íˆ í•´ê²°ì±…ìœ¼ë¡œ ë„˜ì–´ê°€ì§€ ë§ˆì„¸ìš”.\n"
                logger.info(f"[ASK-STREAM] Emotion detected: {emotions_detected}")

        # Add emotion context to system prompt if detected
        if emotion_context:
            system_prompt = system_prompt.replace("[ğŸ“ ì‘ë‹µ êµ¬ì¡°]", f"{emotion_context}\n[ğŸ“ ì‘ë‹µ êµ¬ì¡°]")

        def generate():
            """SSE generator for streaming response."""
            try:
                from openai import OpenAI
                client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

                # Build messages with conversation history (EXPANDED: last 12 exchanges)
                messages = [{"role": "system", "content": system_prompt}]

                # Add conversation history - increased limit for better context
                history_limit = 12  # 6 user + 6 assistant messages (was 6)
                recent_history = conversation_history[-history_limit:] if conversation_history else []

                # Generate conversation summary for long sessions (>6 messages)
                conversation_summary = ""
                if len(conversation_history) > 6:
                    # Extract key topics from older messages
                    older_msgs = conversation_history[:-6]
                    topics = []
                    for m in older_msgs:
                        if m.get("role") == "user" and m.get("content"):
                            content = m["content"][:100]
                            if any(k in content for k in ["ì—°ì• ", "ì‚¬ë‘", "ê²°í˜¼"]):
                                topics.append("ì—°ì• /ê´€ê³„")
                            elif any(k in content for k in ["ì·¨ì—…", "ì´ì§", "ì»¤ë¦¬ì–´", "ì§„ë¡œ"]):
                                topics.append("ì»¤ë¦¬ì–´/ì§„ë¡œ")
                            elif any(k in content for k in ["í˜ë“¤", "ìš°ìš¸", "ì§€ì³"]):
                                topics.append("ê°ì •ì  ì–´ë ¤ì›€")
                            elif any(k in content for k in ["ë‚˜ëŠ”", "ì„±ê²©", "ì–´ë–¤ ì‚¬ëŒ"]):
                                topics.append("ìê¸°íƒìƒ‰")
                    if topics:
                        unique_topics = list(dict.fromkeys(topics))[:3]
                        conversation_summary = f"[ğŸ“‹ ì´ì „ ëŒ€í™” ìš”ì•½: {', '.join(unique_topics)} ì£¼ì œë¡œ ëŒ€í™”í•¨]\n"

                # Add summary if available
                if conversation_summary:
                    messages.append({
                        "role": "system",
                        "content": conversation_summary
                    })

                # Smart truncation: recent messages get more space
                for idx, msg in enumerate(recent_history):
                    if msg.get("role") in ("user", "assistant") and msg.get("content"):
                        # Older messages: shorter, Recent messages: longer
                        is_recent = idx >= len(recent_history) - 4
                        max_len = 800 if is_recent else 300
                        messages.append({
                            "role": msg["role"],
                            "content": msg["content"][:max_len]
                        })

                # Add current user message
                messages.append({"role": "user", "content": prompt})

                stream = client.chat.completions.create(
                    model="gpt-4o-mini",  # Fast model for chat
                    messages=messages,
                    max_tokens=1000,  # Increased for richer responses (was 900)
                    temperature=0.75,  # Slightly more creative (was 0.7)
                    stream=True
                )

                for chunk in stream:
                    if chunk.choices[0].delta.content:
                        text = chunk.choices[0].delta.content
                        # SSE format: data: <content>\n\n
                        yield f"data: {text}\n\n"

                # Signal end of stream
                yield "data: [DONE]\n\n"

            except Exception as e:
                logger.error(f"[ASK-STREAM] Streaming error: {e}")
                yield f"data: [ERROR] {str(e)}\n\n"

        return Response(
            stream_with_context(generate()),
            mimetype="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",  # Disable nginx buffering
            }
        )

    except Exception as e:
        logger.exception(f"[ERROR] id={getattr(g, 'request_id', '')} /ask-stream failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/counselor/init", methods=["POST"])
def counselor_init():
    """
    Initialize counselor session with pre-fetched RAG data.
    Call this ONCE when user enters counselor chat (before first message).

    This pre-computes all relevant RAG data (~10-20s) so subsequent
    chat messages are instant.

    Request body:
        {
            "saju": {...},      # User's saju data
            "astro": {...},     # User's astrology data
            "theme": "career",  # Optional theme (default: "chat")
        }

    Response:
        {
            "status": "success",
            "session_id": "abc123",
            "prefetch_time_ms": 15234,
            "data_summary": {
                "graph_nodes": 15,
                "corpus_quotes": 5,
                "persona_insights": 10
            }
        }
    """
    try:
        import json as json_mod
        raw_data = request.get_data(as_text=False)
        data = json_mod.loads(raw_data.decode('utf-8'))

        saju_data = data.get("saju") or {}
        astro_data = data.get("astro") or {}
        theme = data.get("theme", "chat")
        locale = data.get("locale", "ko")

        # Normalize dayMaster structure (nested -> flat)
        saju_data = normalize_day_master(saju_data)

        logger.info(f"[COUNSELOR-INIT] id={g.request_id} theme={theme}")
        logger.info(f"[COUNSELOR-INIT] saju dayMaster: {saju_data.get('dayMaster', {})}")

        # Generate session ID
        session_id = str(uuid4())[:12]

        # Pre-fetch ALL RAG data (this is slow but only happens once)
        rag_data = prefetch_all_rag_data(saju_data, astro_data, theme, locale)

        # Store in session cache
        set_session_rag_cache(session_id, {
            "rag_data": rag_data,
            "saju_data": saju_data,
            "astro_data": astro_data,
            "theme": theme,
        })

        return jsonify({
            "status": "success",
            "session_id": session_id,
            "prefetch_time_ms": rag_data.get("prefetch_time_ms", 0),
            "data_summary": {
                "graph_nodes": len(rag_data.get("graph_nodes", [])),
                "corpus_quotes": len(rag_data.get("corpus_quotes", [])),
                "persona_insights": len(rag_data.get("persona_context", {}).get("jung", [])) +
                                   len(rag_data.get("persona_context", {}).get("stoic", [])),
                "has_cross_analysis": bool(rag_data.get("cross_analysis")),
            }
        })

    except Exception as e:
        logger.exception(f"[ERROR] id={getattr(g, 'request_id', '')} /counselor/init failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


# Saju calc
@app.route("/calc_saju", methods=["POST"])
def calc_saju():
    try:
        body = request.get_json(force=True)
        birth_date = body.get("birth_date")
        birth_time = body.get("birth_time")
        gender = body.get("gender", "male")

        result = calculate_saju_data(birth_date, birth_time, gender)
        return jsonify({"status": "success", "saju": result})
    except Exception as e:
        logger.exception(f"[ERROR] /calc_saju failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


# Astrology calc
@app.route("/calc_astro", methods=["POST"])
def calc_astro():
    try:
        body = request.get_json(force=True)
        result = calculate_astrology_data(
            {
                "year": body.get("year"),
                "month": body.get("month"),
                "day": body.get("day"),
                "hour": body.get("hour"),
                "minute": body.get("minute"),
                "latitude": body.get("latitude"),
                "longitude": body.get("longitude"),
            }
        )
        return jsonify({"status": "success", "astro": result})
    except Exception as e:
        logger.exception(f"[ERROR] /calc_astro failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


# Dream interpretation endpoint
@app.route("/api/dream/interpret-stream", methods=["POST"])
def dream_interpret_stream():
    """
    Streaming dream interpretation - returns SSE for real-time display.
    Uses GPT-4o-mini for fast streaming.
    Streams: summary â†’ symbols â†’ recommendations â†’ done
    """
    try:
        data = request.get_json(force=True)
        logger.info(f"[DREAM_STREAM] id={g.request_id} Starting streaming interpretation")

        dream_text = data.get("dream", "")
        symbols = data.get("symbols", [])
        emotions = data.get("emotions", [])
        themes = data.get("themes", [])
        context = data.get("context", [])
        locale = data.get("locale", "ko")

        # Cultural symbols
        cultural_parts = []
        if data.get("koreanTypes"):
            cultural_parts.append(f"Korean Types: {', '.join(data['koreanTypes'])}")
        if data.get("koreanLucky"):
            cultural_parts.append(f"Korean Lucky: {', '.join(data['koreanLucky'])}")
        if data.get("chinese"):
            cultural_parts.append(f"Chinese: {', '.join(data['chinese'])}")
        if data.get("islamicTypes"):
            cultural_parts.append(f"Islamic Types: {', '.join(data['islamicTypes'])}")
        if data.get("western"):
            cultural_parts.append(f"Western/Jungian: {', '.join(data['western'])}")
        if data.get("hindu"):
            cultural_parts.append(f"Hindu: {', '.join(data['hindu'])}")
        if data.get("japanese"):
            cultural_parts.append(f"Japanese: {', '.join(data['japanese'])}")

        cultural_context = '\n'.join(cultural_parts) if cultural_parts else 'None'

        is_korean = locale == "ko"
        lang_instruction = "Please respond entirely in Korean (í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”)." if is_korean else "Please respond in English."

        def generate_stream():
            """Generator for SSE streaming dream interpretation"""
            try:
                if not OPENAI_AVAILABLE or not openai_client:
                    yield f"data: {json.dumps({'error': 'OpenAI not available'})}\n\n"
                    return

                # === SECTION 1: Summary (streaming) ===
                yield f"data: {json.dumps({'section': 'summary', 'status': 'start'})}\n\n"

                summary_prompt = f"""ë‹¹ì‹ ì€ ë”°ëœ»í•˜ê³  ê³µê° ëŠ¥ë ¥ì´ ë›°ì–´ë‚œ ê¿ˆ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.
ë§ˆì¹˜ ì˜¤ëœ ì¹œêµ¬ì—ê²Œ ì´ì•¼ê¸°í•˜ë“¯ í¸ì•ˆí•˜ê²Œ ê¿ˆì˜ ë©”ì‹œì§€ë¥¼ ì „ë‹¬í•´ì£¼ì„¸ìš”.

{lang_instruction}

ê¿ˆ ë‚´ìš©:
{dream_text[:1500]}

ì‹¬ë³¼: {', '.join(symbols) if symbols else 'ì—†ìŒ'}
ê°ì •: {', '.join(emotions) if emotions else 'ì—†ìŒ'}
ìœ í˜•: {', '.join(themes) if themes else 'ì—†ìŒ'}
ìƒí™©: {', '.join(context) if context else 'ì—†ìŒ'}
ë¬¸í™”ì  ë§¥ë½: {cultural_context}

ìƒë‹´ ìŠ¤íƒ€ì¼:
- ë”°ëœ»í•˜ê³  ê³µê°í•˜ëŠ” ë§íˆ¬ ("~í•˜ì…¨êµ°ìš”", "~ëŠë¼ì…¨ì„ ê±°ì˜ˆìš”")
- ê¿ˆì´ ì „í•˜ëŠ” ë©”ì‹œì§€ë¥¼ ë¶€ë“œëŸ½ê²Œ í•´ì„
- ë¶ˆì•ˆí•œ ê¿ˆì´ë¼ë„ ê¸ì •ì  ê´€ì ìœ¼ë¡œ ì¬í•´ì„
- 3-4ë¬¸ì¥ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ìš”ì•½"""

                stream = openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[{"role": "user", "content": summary_prompt}],
                    temperature=0.7,
                    max_tokens=400,
                    stream=True
                )

                summary_text = ""
                for chunk in stream:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        summary_text += content
                        yield f"data: {json.dumps({'section': 'summary', 'content': content})}\n\n"

                yield f"data: {json.dumps({'section': 'summary', 'status': 'done', 'full_text': summary_text})}\n\n"

                # === SECTION 2: Symbol Analysis (streaming) ===
                yield f"data: {json.dumps({'section': 'symbols', 'status': 'start'})}\n\n"

                symbols_prompt = f"""ë‹¹ì‹ ì€ ë”°ëœ»í•œ ê¿ˆ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ê¿ˆì— ë‚˜íƒ€ë‚œ ì‹¬ë³¼ë“¤ì˜ ì˜ë¯¸ë¥¼ ì¹œê·¼í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.

{lang_instruction}

ê¿ˆ ë‚´ìš©: {dream_text[:1000]}
ì‹¬ë³¼: {', '.join(symbols) if symbols else 'ê¿ˆì—ì„œ ì¶”ì¶œ'}
ë¬¸í™”ì  ë§¥ë½: {cultural_context}

ìƒë‹´ ìŠ¤íƒ€ì¼:
- ê° ì‹¬ë³¼ì„ ê°œì¸ì˜ ìƒí™©ê³¼ ì—°ê²°í•˜ì—¬ í•´ì„
- ë¬¸í™”ì Â·ì‹¬ë¦¬í•™ì  ì˜ë¯¸ë¥¼ ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…
- ë¶€ì •ì  ì‹¬ë³¼ë„ ì„±ì¥ì˜ ë©”ì‹œì§€ë¡œ ì¬í•´ì„
- ë²ˆí˜¸ ì—†ì´ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´ë¡œ 2-3ê°œ ì‹¬ë³¼ ë¶„ì„"""

                symbol_stream = openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[{"role": "user", "content": symbols_prompt}],
                    temperature=0.7,
                    max_tokens=500,
                    stream=True
                )

                symbols_text = ""
                for chunk in symbol_stream:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        symbols_text += content
                        yield f"data: {json.dumps({'section': 'symbols', 'content': content})}\n\n"

                yield f"data: {json.dumps({'section': 'symbols', 'status': 'done', 'full_text': symbols_text})}\n\n"

                # === SECTION 3: Recommendations (streaming) ===
                yield f"data: {json.dumps({'section': 'recommendations', 'status': 'start'})}\n\n"

                rec_prompt = f"""ë‹¹ì‹ ì€ ë”°ëœ»í•œ ê¿ˆ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ê¿ˆì˜ ë©”ì‹œì§€ë¥¼ ì‹¤ìƒí™œì— ì ìš©í•  ìˆ˜ ìˆëŠ” ì¡°ì–¸ì„ í•´ì£¼ì„¸ìš”.

{lang_instruction}

ê¿ˆ ìš”ì•½: {summary_text[:500]}
ê°ì •: {', '.join(emotions) if emotions else 'ì—†ìŒ'}

ìƒë‹´ ìŠ¤íƒ€ì¼:
- ì¹œêµ¬ì—ê²Œ ì¡°ì–¸í•˜ë“¯ í¸ì•ˆí•˜ê³  ì‹¤ìš©ì ìœ¼ë¡œ
- ì‘ì€ ì‹¤ì²œ ê°€ëŠ¥í•œ í–‰ë™ ì œì•ˆ (ì˜ˆ: "ì˜¤ëŠ˜ ì ê¹ ì‚°ì±…í•´ë³´ì‹œëŠ” ê±´ ì–´ë–¨ê¹Œìš”?")
- ê¿ˆì´ ì „í•˜ëŠ” ê¸ì •ì  ë©”ì‹œì§€ ê°•ì¡°
- 2-3ê°€ì§€ ë”°ëœ»í•œ ì¡°ì–¸"""

                rec_stream = openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[{"role": "user", "content": rec_prompt}],
                    temperature=0.7,
                    max_tokens=300,
                    stream=True
                )

                rec_text = ""
                for chunk in rec_stream:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        rec_text += content
                        yield f"data: {json.dumps({'section': 'recommendations', 'content': content})}\n\n"

                yield f"data: {json.dumps({'section': 'recommendations', 'status': 'done', 'full_text': rec_text})}\n\n"

                # === DONE ===
                yield f"data: {json.dumps({'done': True})}\n\n"

            except Exception as stream_error:
                logger.exception(f"[DREAM_STREAM] Error: {stream_error}")
                yield f"data: {json.dumps({'error': str(stream_error)})}\n\n"

        return Response(
            generate_stream(),
            mimetype='text/event-stream',
            headers={
                'Cache-Control': 'no-cache',
                'Connection': 'keep-alive',
                'X-Accel-Buffering': 'no'
            }
        )

    except Exception as e:
        logger.exception(f"[ERROR] /api/dream/interpret-stream failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/dream", methods=["POST"])
def dream_interpret():
    """
    Dream interpretation endpoint.
    Accepts dream text, symbols, emotions, themes, and cultural context.
    """
    try:
        data = request.get_json(force=True)
        logger.info(f"[DREAM] id={g.request_id} Processing dream interpretation")

        # Extract dream data
        birth_data = data.get("birth") or {}
        locale = data.get("locale", "en")
        facts = {
            "dream": data.get("dream", ""),
            "symbols": data.get("symbols", []),
            "emotions": data.get("emotions", []),
            "themes": data.get("themes", []),
            "context": data.get("context", []),
            "locale": locale,
            # Cultural symbols
            "koreanTypes": data.get("koreanTypes", []),
            "koreanLucky": data.get("koreanLucky", []),
            "chinese": data.get("chinese", []),
            "islamicTypes": data.get("islamicTypes", []),
            "islamicBlessed": data.get("islamicBlessed", []),
            "western": data.get("western", []),
            "hindu": data.get("hindu", []),
            "nativeAmerican": data.get("nativeAmerican", []),
            "japanese": data.get("japanese", []),
            # Optional birth data
            "birth": birth_data,
        }

        start_time = time.time()
        result = interpret_dream(facts)
        duration_ms = int((time.time() - start_time) * 1000)

        logger.info(f"[DREAM] id={g.request_id} completed in {duration_ms}ms")

        if isinstance(result, dict):
            result["performance"] = {"duration_ms": duration_ms}

        # ğŸ’¾ Save to user memory (MOAT)
        if HAS_USER_MEMORY and birth_data:
            try:
                user_id = generate_user_id(birth_data)
                memory = get_user_memory(user_id)
                interpretation = result.get("interpretation", "") if isinstance(result, dict) else str(result)
                record_id = memory.save_consultation(
                    theme="dream",
                    locale=locale,
                    birth_data=birth_data,
                    fusion_result=interpretation,
                    service_type="dream",
                )
                result["user_id"] = user_id
                result["record_id"] = record_id
                logger.info(f"[DREAM] Saved to memory: {record_id}")
            except Exception as mem_e:
                logger.warning(f"[DREAM] Memory save failed: {mem_e}")

        return jsonify({"status": "success", "data": result})

    except Exception as e:
        logger.exception(f"[ERROR] id={getattr(g, 'request_id', '')} /dream failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


# Cache stats and management
@app.route("/cache/stats", methods=["GET"])
def cache_stats():
    """Get cache statistics."""
    try:
        cache = get_cache()
        stats = cache.stats()
        return jsonify({"status": "success", "cache": stats})
    except Exception as e:
        logger.exception(f"[ERROR] /cache/stats failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/cache/clear", methods=["POST"])
def cache_clear():
    """Clear cache (admin only)."""
    try:
        cache = get_cache()
        pattern = request.json.get("pattern", "fusion:*") if request.json else "fusion:*"
        cleared = cache.clear(pattern)
        return jsonify({"status": "success", "cleared": cleared})
    except Exception as e:
        logger.exception(f"[ERROR] /cache/clear failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


# Performance monitoring endpoints
@app.route("/performance/stats", methods=["GET"])
def performance_stats():
    """Get performance statistics with optimization suggestions."""
    try:
        stats = get_performance_stats()
        suggestions = suggest_optimizations(stats)
        cache_health = get_cache_health()

        return jsonify({
            "status": "success",
            "performance": stats,
            "cache_health": cache_health,
            "suggestions": suggestions
        })
    except Exception as e:
        logger.exception(f"[ERROR] /performance/stats failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/health", methods=["GET"])
def health_check():
    """Simple health check for Railway/load balancer."""
    return jsonify({"status": "ok"})


@app.route("/health/full", methods=["GET"])
def full_health_check():
    """Comprehensive health check including performance metrics."""
    try:
        perf_stats = get_performance_stats()
        cache_health = get_cache_health()

        # Calculate overall health score
        health_score = 100

        # Penalize for low cache hit rate
        if perf_stats["cache_hit_rate"] < 30:
            health_score -= 20

        # Penalize for slow responses
        if perf_stats["avg_response_time_ms"] > 2000:
            health_score -= 15

        # Penalize for cache issues
        if cache_health["health_score"] < 80:
            health_score -= 15

        status_text = "excellent" if health_score >= 90 else "good" if health_score >= 70 else "degraded"

        return jsonify({
            "status": "success",
            "health_score": health_score,
            "status_text": status_text,
            "performance": perf_stats,
            "cache": cache_health,
            "timestamp": time.time()
        })
    except Exception as e:
        logger.exception(f"[ERROR] /health/full failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


# ===============================================================
# GEMINI-LEVEL ENDPOINTS
# ===============================================================

# Real-time transit data
@app.route("/transits", methods=["GET"])
def get_transits():
    """Get current planetary transits (real-time)."""
    if not HAS_REALTIME:
        return jsonify({"status": "error", "message": "Realtime astro not available"}), 501

    try:
        locale = request.args.get("locale", "en")
        transits = get_current_transits()
        interpretation = get_transit_interpretation(transits, locale)

        return jsonify({
            "status": "success",
            "transits": transits,
            "interpretation": interpretation,
        })
    except Exception as e:
        logger.exception(f"[ERROR] /transits failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


# Chart generation
@app.route("/charts/saju", methods=["POST"])
def generate_saju_chart():
    """Generate Saju Paljja table SVG."""
    if not HAS_CHARTS:
        return jsonify({"status": "error", "message": "Chart generator not available"}), 501

    try:
        data = request.get_json(force=True)
        pillars = data.get("pillars", {})
        day_master = data.get("dayMaster", {})
        five_elements = data.get("fiveElements", {})

        svg = generate_saju_table_svg(pillars, day_master, five_elements)

        return jsonify({
            "status": "success",
            "svg": svg,
            "base64": svg_to_base64(svg),
        })
    except Exception as e:
        logger.exception(f"[ERROR] /charts/saju failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/charts/natal", methods=["POST"])
def generate_natal_chart():
    """Generate natal chart wheel SVG."""
    if not HAS_CHARTS:
        return jsonify({"status": "error", "message": "Chart generator not available"}), 501

    try:
        data = request.get_json(force=True)
        planets = data.get("planets", [])
        ascendant = data.get("ascendant", 0)
        size = data.get("size", 400)

        svg = generate_natal_chart_svg(planets, ascendant=ascendant, size=size)

        return jsonify({
            "status": "success",
            "svg": svg,
            "base64": svg_to_base64(svg),
        })
    except Exception as e:
        logger.exception(f"[ERROR] /charts/natal failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/charts/full", methods=["POST"])
def generate_full_charts():
    """Generate complete HTML with all charts."""
    if not HAS_CHARTS:
        return jsonify({"status": "error", "message": "Chart generator not available"}), 501

    try:
        data = request.get_json(force=True)
        saju_data = data.get("saju", {})
        astro_data = data.get("astro", {})
        locale = data.get("locale", "en")

        html = generate_full_chart_html(saju_data, astro_data, locale)

        return jsonify({
            "status": "success",
            "html": html,
        })
    except Exception as e:
        logger.exception(f"[ERROR] /charts/full failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


# User memory endpoints
@app.route("/memory/save", methods=["POST"])
def save_consultation():
    """Save consultation to user memory."""
    if not HAS_USER_MEMORY:
        return jsonify({"status": "error", "message": "User memory not available"}), 501

    try:
        data = request.get_json(force=True)
        birth_data = data.get("birth", {})
        theme = data.get("theme", "")
        locale = data.get("locale", "en")
        result = data.get("result", "")

        user_id = generate_user_id(birth_data)
        memory = get_user_memory(user_id)

        record_id = memory.save_consultation(
            theme=theme,
            locale=locale,
            birth_data=birth_data,
            fusion_result=result,
        )

        return jsonify({
            "status": "success",
            "user_id": user_id,
            "record_id": record_id,
        })
    except Exception as e:
        logger.exception(f"[ERROR] /memory/save failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/memory/context", methods=["POST"])
def get_memory_context():
    """Get user context for personalized readings."""
    if not HAS_USER_MEMORY:
        return jsonify({"status": "error", "message": "User memory not available"}), 501

    try:
        data = request.get_json(force=True)
        birth_data = data.get("birth", {})
        theme = data.get("theme", "life_path")
        locale = data.get("locale", "en")

        user_id = generate_user_id(birth_data)
        memory = get_user_memory(user_id)

        context = memory.build_context_for_llm(theme, locale)
        profile = memory.get_profile()
        history = memory.get_history(limit=5)

        return jsonify({
            "status": "success",
            "user_id": user_id,
            "context": context,
            "profile": profile.__dict__ if profile else None,
            "history": history,
        })
    except Exception as e:
        logger.exception(f"[ERROR] /memory/context failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/memory/feedback", methods=["POST"])
def save_feedback():
    """Save user feedback for a consultation (MOAT - improves recommendations)."""
    if not HAS_USER_MEMORY:
        return jsonify({"status": "error", "message": "User memory not available"}), 501

    try:
        data = request.get_json(force=True)
        birth_data = data.get("birth", {})
        record_id = data.get("record_id", "")
        feedback = data.get("feedback", "")  # Text feedback
        rating = data.get("rating")  # 1-5 stars or thumbs up/down (1 or 5)

        if not record_id:
            return jsonify({"status": "error", "message": "record_id required"}), 400

        user_id = generate_user_id(birth_data)
        memory = get_user_memory(user_id)
        memory.save_feedback(record_id, feedback, rating)

        return jsonify({
            "status": "success",
            "user_id": user_id,
            "record_id": record_id,
            "message": "Feedback saved successfully",
        })
    except Exception as e:
        logger.exception(f"[ERROR] /memory/feedback failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/memory/history", methods=["POST"])
def get_history():
    """Get user consultation history."""
    if not HAS_USER_MEMORY:
        return jsonify({"status": "error", "message": "User memory not available"}), 501

    try:
        data = request.get_json(force=True)
        birth_data = data.get("birth", {})
        limit = data.get("limit", 10)

        user_id = generate_user_id(birth_data)
        memory = get_user_memory(user_id)
        history = memory.get_history(limit=limit)
        profile = memory.get_profile()

        return jsonify({
            "status": "success",
            "user_id": user_id,
            "history": history,
            "consultation_count": profile.consultation_count if profile else 0,
            "dominant_themes": profile.dominant_themes if profile else [],
        })
    except Exception as e:
        logger.exception(f"[ERROR] /memory/history failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


# ===============================================================
# I CHING (PREMIUM) ENDPOINTS
# ===============================================================

@app.route("/iching/cast", methods=["POST"])
def iching_cast():
    """Cast I Ching hexagram (premium)."""
    if not HAS_ICHING:
        return jsonify({"status": "error", "message": "I Ching module not available"}), 501

    try:
        result = cast_hexagram()
        return jsonify({
            "status": "success",
            "cast": result,
        })
    except Exception as e:
        logger.exception(f"[ERROR] /iching/cast failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/iching/interpret", methods=["POST"])
def iching_interpret():
    """Get hexagram interpretation (premium)."""
    if not HAS_ICHING:
        return jsonify({"status": "error", "message": "I Ching module not available"}), 501

    try:
        data = request.get_json(force=True)
        hexagram_num = data.get("hexagram", 1)
        theme = data.get("theme", "general")
        locale = data.get("locale", "ko")
        changing_lines = data.get("changingLines", [])
        saju_element = data.get("sajuElement")

        interp = get_hexagram_interpretation(
            hexagram_num=hexagram_num,
            theme=theme,
            locale=locale,
            changing_lines=changing_lines,
            saju_element=saju_element,
        )

        return jsonify({
            "status": "success",
            "interpretation": interp,
        })
    except Exception as e:
        logger.exception(f"[ERROR] /iching/interpret failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/iching/reading", methods=["POST"])
def iching_reading():
    """Perform complete I Ching reading (premium)."""
    if not HAS_ICHING:
        return jsonify({"status": "error", "message": "I Ching module not available"}), 501

    try:
        data = request.get_json(force=True)
        question = data.get("question", "")
        theme = data.get("theme", "general")
        locale = data.get("locale", "ko")
        saju_element = data.get("sajuElement")
        birth_data = data.get("birth") or {}

        reading = perform_iching_reading(
            question=question,
            theme=theme,
            locale=locale,
            saju_element=saju_element,
        )

        # ğŸ’¾ Save to user memory (MOAT)
        if HAS_USER_MEMORY and birth_data:
            try:
                user_id = generate_user_id(birth_data)
                memory = get_user_memory(user_id)
                # Extract interpretation text
                interpretation = reading.get("combined_interpretation", "") if isinstance(reading, dict) else str(reading)
                hexagram_name = reading.get("hexagram", {}).get("korean_name", "") if isinstance(reading, dict) else ""
                record_id = memory.save_consultation(
                    theme=f"iching:{theme}",
                    locale=locale,
                    birth_data=birth_data,
                    fusion_result=f"[{hexagram_name}] {interpretation}",
                    key_insights=[question] if question else [],
                    service_type="iching",
                )
                reading["user_id"] = user_id
                reading["record_id"] = record_id
                logger.info(f"[ICHING] Saved to memory: {record_id}")
            except Exception as mem_e:
                logger.warning(f"[ICHING] Memory save failed: {mem_e}")

        return jsonify({
            "status": "success",
            "reading": reading,
        })
    except Exception as e:
        logger.exception(f"[ERROR] /iching/reading failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/iching/reading-stream", methods=["POST"])
def iching_reading_stream():
    """
    Enhanced Streaming I Ching interpretation with:
    - Five Element (äº”è¡Œ) analysis
    - Seasonal harmony
    - Trigram imagery
    - Nuclear/Opposite/Reverse hexagram insights
    - Saju cross-analysis
    - Advanced changing line rules
    """
    if not HAS_ICHING:
        return jsonify({"status": "error", "message": "I Ching module not available"}), 501

    try:
        data = request.get_json(force=True)
        logger.info(f"[ICHING_STREAM] id={g.request_id} Starting enhanced streaming interpretation")

        # Get hexagram data from request
        hexagram_number = data.get("hexagramNumber")
        hexagram_name = data.get("hexagramName", "")
        hexagram_symbol = data.get("hexagramSymbol", "")
        hexagram_binary = data.get("hexagramBinary", "")
        judgment = data.get("judgment", "")
        image = data.get("image", "")
        core_meaning = data.get("coreMeaning", "")
        changing_lines = data.get("changingLines", [])
        resulting_hexagram = data.get("resultingHexagram")
        question = data.get("question", "")
        locale = data.get("locale", "ko")
        themes = data.get("themes", {})

        # Enhanced data from new analysis functions
        trigram_upper = data.get("trigramUpper", "")
        trigram_lower = data.get("trigramLower", "")
        hexagram_element = data.get("element", "")
        saju_element = data.get("sajuElement", "")  # User's day master element

        # Related hexagrams (if provided)
        nuclear_hexagram = data.get("nuclearHexagram", {})
        opposite_hexagram = data.get("oppositeHexagram", {})
        reverse_hexagram = data.get("reverseHexagram", {})

        is_korean = locale == "ko"
        lang_instruction = "Please respond entirely in Korean (í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”)." if is_korean else "Please respond in English."

        # Current date and seasonal analysis
        now = datetime.now()
        weekdays_ko = ["ì›”ìš”ì¼", "í™”ìš”ì¼", "ìˆ˜ìš”ì¼", "ëª©ìš”ì¼", "ê¸ˆìš”ì¼", "í† ìš”ì¼", "ì¼ìš”ì¼"]
        weekdays_en = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]

        # Determine current season and ì ˆê¸°
        month = now.month
        if month in [3, 4, 5]:
            season_ko, season_element = "ë´„", "ëª©(æœ¨)"
        elif month in [6, 7, 8]:
            season_ko, season_element = "ì—¬ë¦„", "í™”(ç«)"
        elif month in [9, 10, 11]:
            season_ko, season_element = "ê°€ì„", "ê¸ˆ(é‡‘)"
        else:
            season_ko, season_element = "ê²¨ìš¸", "ìˆ˜(æ°´)"

        if is_korean:
            current_date_str = f"ì˜¤ëŠ˜: {now.year}ë…„ {now.month}ì›” {now.day}ì¼ ({weekdays_ko[now.weekday()]}) - {season_ko}"
        else:
            current_date_str = f"Today: {now.strftime('%B %d, %Y')} ({weekdays_en[now.weekday()]})"

        # Five Element (ì˜¤í–‰) analysis for hexagram
        wuxing_korean = {"wood": "ëª©(æœ¨)", "fire": "í™”(ç«)", "earth": "í† (åœŸ)", "metal": "ê¸ˆ(é‡‘)", "water": "ìˆ˜(æ°´)"}
        hex_element_ko = wuxing_korean.get(hexagram_element, hexagram_element) if hexagram_element else ""

        # Trigram imagery
        trigram_names = {
            "heaven": "ê±´(ä¹¾/í•˜ëŠ˜)", "earth": "ê³¤(å¤/ë•…)", "thunder": "ì§„(éœ‡/ìš°ë ˆ)",
            "water": "ê°(å/ë¬¼)", "mountain": "ê°„(è‰®/ì‚°)", "wind": "ì†(å·½/ë°”ëŒ)",
            "fire": "ë¦¬(é›¢/ë¶ˆ)", "lake": "íƒœ(å…Œ/ì—°ëª»)"
        }
        upper_name = trigram_names.get(trigram_upper, trigram_upper)
        lower_name = trigram_names.get(trigram_lower, trigram_lower)

        def generate_stream():
            """Generator for SSE streaming I Ching interpretation with enhanced analysis"""
            try:
                if not OPENAI_AVAILABLE or not openai_client:
                    yield f"data: {json.dumps({'error': 'OpenAI not available'})}\n\n"
                    return

                # === SECTION 1: Overview with ê´˜ìƒ/ì˜¤í–‰/ê³„ì ˆ ë¶„ì„ (streaming) ===
                yield f"data: {json.dumps({'section': 'overview', 'status': 'start'})}\n\n"

                # Build enhanced context
                trigram_context = ""
                if upper_name and lower_name:
                    trigram_context = f"""
ê´˜ìƒ(å¦è±¡) ë¶„ì„:
- ìƒê´˜: {upper_name}
- í•˜ê´˜: {lower_name}
- ê´˜ìƒ ì´ë¯¸ì§€: ìœ„ì— {upper_name.split('/')[1] if '/' in upper_name else upper_name}, ì•„ë˜ì— {lower_name.split('/')[1] if '/' in lower_name else lower_name}"""

                element_context = ""
                if hex_element_ko:
                    element_context = f"""
ì˜¤í–‰(äº”è¡Œ) ë¶„ì„:
- ê´˜ì˜ ì˜¤í–‰: {hex_element_ko}
- í˜„ì¬ ê³„ì ˆ: {season_ko} ({season_element})"""
                    # Add saju analysis if available
                    if saju_element:
                        saju_element_ko = wuxing_korean.get(saju_element, saju_element)
                        element_context += f"""
- ë‹¹ì‹ ì˜ ì¼ê°„(æ—¥å¹²): {saju_element_ko}"""

                related_context = ""
                if nuclear_hexagram.get("name") or opposite_hexagram.get("name") or reverse_hexagram.get("name"):
                    related_context = """
ê´€ë ¨ ê´˜(å¦) ì°¸ê³ :"""
                    if nuclear_hexagram.get("name"):
                        related_context += f"""
- í˜¸ê´˜(äº’å¦): {nuclear_hexagram.get('name', '')} - ìƒí™©ì˜ ë‚´ë©´ì— ìˆ¨ê²¨ì§„ ì˜ë¯¸"""
                    if opposite_hexagram.get("name"):
                        related_context += f"""
- ì°©ê´˜(éŒ¯å¦): {opposite_hexagram.get('name', '')} - ì •ë°˜ëŒ€ ê´€ì ì—ì„œì˜ í†µì°°"""
                    if reverse_hexagram.get("name"):
                        related_context += f"""
- ì¢…ê´˜(ç¶œå¦): {reverse_hexagram.get('name', '')} - ìƒëŒ€ë°© ì…ì¥ì—ì„œì˜ ì‹œê°"""

                overview_prompt = f"""ë‹¹ì‹ ì€ ê¹Šì€ í†µì°°ë ¥ì„ ê°€ì§„ ì£¼ì—­(å‘¨æ˜“) ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.
ë™ì–‘ ì² í•™ê³¼ ì˜¤í–‰(äº”è¡Œ) ì‚¬ìƒì— ì •í†µí•˜ë©°, ë”°ëœ»í•˜ê³  ì§€í˜œë¡œìš´ ìŠ¤ìŠ¹ì²˜ëŸ¼ ê´˜ì˜ ë©”ì‹œì§€ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.

{lang_instruction}

{current_date_str}

ã€ê´˜ ì •ë³´ã€‘
- ê´˜ëª…: {hexagram_name} {hexagram_symbol} (ì œ{hexagram_number}ê´˜)
- ê´˜ì‚¬(å½–è¾­): {judgment}
- ìƒì‚¬(è±¡è¾­): {image}
- í•µì‹¬ ì˜ë¯¸: {core_meaning}
{trigram_context}
{element_context}
{related_context}

{f'ã€ì§ˆë¬¸ã€‘ {question}' if question else 'ã€ì¼ë°˜ ì ê´˜ã€‘'}

ã€í…Œë§ˆë³„ í•´ì„ ì°¸ê³ ã€‘
- ì§ì—…/ì‚¬ì—…: {themes.get('career', '')}
- ì—°ì• /ê´€ê³„: {themes.get('love', '')}
- ê±´ê°•: {themes.get('health', '')}
- ì¬ë¬¼: {themes.get('wealth', '')}
- ì‹œê¸°: {themes.get('timing', '')}

ã€ìƒë‹´ ì§€ì¹¨ã€‘
1. ê´˜ìƒ(å¦è±¡) ì´ë¯¸ì§€ë¥¼ í™œìš©í•˜ì—¬ ì‹œê°ì ì´ê³  ì§ê´€ì ìœ¼ë¡œ ì„¤ëª…
2. ì˜¤í–‰ì˜ ìƒìƒìƒê·¹ ê´€ê³„ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ì„œ í•´ì„
3. í˜„ì¬ ê³„ì ˆ({season_ko})ê³¼ ê´˜ì˜ ê¸°ìš´ ì¡°í™”ë¥¼ ì–¸ê¸‰
4. ë”°ëœ»í•˜ê³  ê³µê°í•˜ëŠ” ë§íˆ¬ ("~í•˜ì‹œëŠ”êµ°ìš”", "~ì˜ ì‹œê¸°ì…ë‹ˆë‹¤")
5. ì§ˆë¬¸ì´ ìˆë‹¤ë©´ ê·¸ì— ë§ì¶° êµ¬ì²´ì ìœ¼ë¡œ ë‹µë³€
6. 4-5ë¬¸ì¥ìœ¼ë¡œ ê¹Šì´ ìˆìœ¼ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰½ê²Œ í•´ì„"""

                stream = openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[{"role": "user", "content": overview_prompt}],
                    temperature=0.7,
                    max_tokens=500,
                    stream=True
                )

                overview_text = ""
                for chunk in stream:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        overview_text += content
                        yield f"data: {json.dumps({'section': 'overview', 'content': content})}\n\n"

                yield f"data: {json.dumps({'section': 'overview', 'status': 'done', 'full_text': overview_text})}\n\n"

                # === SECTION 2: Changing Lines Analysis (if any) ===
                if changing_lines:
                    yield f"data: {json.dumps({'section': 'changing', 'status': 'start'})}\n\n"

                    changing_info = "\n".join([f"- {line.get('index', i+1)}íš¨: {line.get('text', '')}" for i, line in enumerate(changing_lines)])
                    resulting_info = ""
                    if resulting_hexagram:
                        resulting_info = f"ë³€í™” í›„ ê´˜(ì§€ê´˜): {resulting_hexagram.get('name', '')} {resulting_hexagram.get('symbol', '')} - {resulting_hexagram.get('judgment', '')}"

                    # ë³€íš¨ ê°œìˆ˜ì— ë”°ë¥¸ ì „í†µ ì£¼ì—­ í•´ì„ ê·œì¹™
                    line_count = len(changing_lines)
                    line_nums = [line.get('index', i+1) for i, line in enumerate(changing_lines)]

                    if line_count == 1:
                        interpretation_rule = f"ã€ë‹¨ë³€(å–®è®Š)ã€‘ {line_nums[0]}íš¨ í•˜ë‚˜ë§Œ ë³€í•˜ë‹ˆ, ë³¸ê´˜ì˜ {line_nums[0]}íš¨ íš¨ì‚¬ê°€ í•µì‹¬ì…ë‹ˆë‹¤."
                    elif line_count == 2:
                        sorted_lines = sorted(line_nums)
                        upper_line = sorted_lines[-1]
                        interpretation_rule = f"ã€ì´ë³€(äºŒè®Š)ã€‘ {sorted_lines[0]}, {sorted_lines[1]}íš¨ê°€ ë³€í•©ë‹ˆë‹¤. ìœ„ íš¨ì¸ {upper_line}íš¨ì˜ íš¨ì‚¬ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•´ì„í•˜ì„¸ìš”."
                    elif line_count == 3:
                        interpretation_rule = "ã€ì‚¼ë³€(ä¸‰è®Š)ã€‘ ë³¸ê´˜ì™€ ì§€ê´˜ì˜ ê´˜ì‚¬ë¥¼ í•¨ê»˜ ë³´ë˜, ë³¸ê´˜ ê´˜ì‚¬ê°€ ì¤‘ì‹¬ì…ë‹ˆë‹¤."
                    elif line_count == 4:
                        all_lines = {1, 2, 3, 4, 5, 6}
                        unchanged = sorted(all_lines - set(line_nums))
                        interpretation_rule = f"ã€ì‚¬ë³€(å››è®Š)ã€‘ ë³€í•˜ì§€ ì•ŠëŠ” {unchanged[0]}, {unchanged[1]}íš¨ ì¤‘ ì•„ë˜ íš¨ì¸ {unchanged[0]}íš¨ì˜ ì§€ê´˜ íš¨ì‚¬ë¥¼ ë³´ì„¸ìš”."
                    elif line_count == 5:
                        all_lines = {1, 2, 3, 4, 5, 6}
                        unchanged = list(all_lines - set(line_nums))[0]
                        interpretation_rule = f"ã€ì˜¤ë³€(äº”è®Š)ã€‘ {unchanged}íš¨ë§Œ ë³€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ ë¶ˆë³€íš¨ì˜ ì§€ê´˜ íš¨ì‚¬ê°€ í•µì‹¬ì…ë‹ˆë‹¤."
                    elif line_count == 6:
                        # íŠ¹ìˆ˜ ì¼€ì´ìŠ¤: ê±´â†’ê³¤ (ìš©êµ¬), ê³¤â†’ê±´ (ìš©ìœ¡)
                        if hexagram_number == 1 and resulting_hexagram and resulting_hexagram.get('number') == 2:
                            interpretation_rule = "ã€ì „íš¨ë³€ - ìš©êµ¬(ç”¨ä¹)ã€‘ 'è¦‹ç¾¤é¾ç„¡é¦– å‰' - ì—¬ëŸ¬ ìš©ì´ ë‚˜íƒ€ë‚˜ë˜ ìš°ë‘ë¨¸ë¦¬ê°€ ì—†ìœ¼ë‹ˆ ê¸¸í•˜ë‹¤. ë¦¬ë”ì‹­ì„ ë‚´ë ¤ë†“ê³  ê²¸ì†íˆ ë¬¼ëŸ¬ë‚˜ë©´ ê¸¸í•©ë‹ˆë‹¤."
                        elif hexagram_number == 2 and resulting_hexagram and resulting_hexagram.get('number') == 1:
                            interpretation_rule = "ã€ì „íš¨ë³€ - ìš©ìœ¡(ç”¨å…­)ã€‘ 'åˆ©æ°¸è²' - ì˜ì›íˆ ë°”ë¥´ê²Œ í•¨ì´ ì´ë¡­ë‹¤. ëê¹Œì§€ ë°”ë¥¸ ë„ë¥¼ ì§€í‚¤ë©´ ê°•ê±´í•¨ì„ ì–»ìŠµë‹ˆë‹¤."
                        else:
                            interpretation_rule = "ã€ì „íš¨ë³€(å…¨çˆ»è®Š)ã€‘ 6íš¨ê°€ ëª¨ë‘ ë³€í•˜ë‹ˆ, ì§€ê´˜ì˜ ê´˜ì‚¬ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•´ì„í•˜ì„¸ìš”."
                    else:
                        interpretation_rule = ""

                    # Enhanced changing line context
                    line_position_meanings = {
                        1: "ì´ˆíš¨ - ì‹œì‘, ì ì¬ë ¥ì˜ ë‹¨ê³„",
                        2: "ì´íš¨ - ë‚´ë©´ì˜ ì„±ì¥, ë°œì „ê¸°",
                        3: "ì‚¼íš¨ - ë‚´ì™¸ ê²½ê³„, ì „í™˜ì ",
                        4: "ì‚¬íš¨ - ì™¸ë¶€ ì§„ì…, ë„ì•½ê¸°",
                        5: "ì˜¤íš¨ - ì •ì , ì „ì„±ê¸°",
                        6: "ìƒíš¨ - ê·¹ì , ë§ˆë¬´ë¦¬"
                    }
                    line_positions = "\n".join([f"- {line_position_meanings.get(line.get('index', i+1), '')}" for i, line in enumerate(changing_lines)])

                    changing_prompt = f"""ë‹¹ì‹ ì€ ì£¼ì—­ì˜ ë³€íš¨(è®Šçˆ») í•´ì„ì— ì •í†µí•œ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.
ì „í†µì ì¸ íš¨ë³€ í•´ì„ë²•(æœ±ç†¹ å‘¨æ˜“æœ¬ç¾©)ì— ë”°ë¼ ì •í™•í•˜ê³  ê¹Šì´ ìˆê²Œ í•´ì„í•©ë‹ˆë‹¤.

{lang_instruction}

ã€ë³¸ê´˜(æœ¬å¦)ã€‘ {hexagram_name} {hexagram_symbol}

ã€ë³€íš¨(è®Šçˆ») ì •ë³´ã€‘
{changing_info}

ã€íš¨ìœ„(çˆ»ä½) ì˜ë¯¸ã€‘
{line_positions}

ã€ì§€ê´˜(ä¹‹å¦) ì •ë³´ã€‘
{resulting_info}

ã€ì „í†µ ì£¼ì—­ í•´ì„ ê·œì¹™ (æœ±ç†¹ å‘¨æ˜“æœ¬ç¾©)ã€‘
{interpretation_rule}

ã€í•´ì„ ì§€ì¹¨ã€‘
1. ìœ„ í•´ì„ ê·œì¹™ì„ ì •í™•íˆ ë”°ë¼ í•´ì„ì˜ ì¤‘ì‹¬ì„ ì¡ìœ¼ì„¸ìš”
2. íš¨ìœ„(çˆ»ä½)ê°€ ìƒì§•í•˜ëŠ” ì¸ìƒ ë‹¨ê³„ì™€ ì—°ê²°í•˜ì—¬ ì„¤ëª…
3. ë³¸ê´˜ì—ì„œ ì§€ê´˜ë¡œì˜ ë³€í™”ê°€ ì˜ë¯¸í•˜ëŠ” íë¦„ì„ í•´ì„
4. ì¤‘ì •(ä¸­æ­£) - 2,5íš¨ê°€ ì¤‘ì•™ì´ê³  ì–‘íš¨ê°€ í™€ìˆ˜ìë¦¬, ìŒíš¨ê°€ ì§ìˆ˜ìë¦¬ë©´ ì •ìœ„
5. ì‘íš¨(æ‡‰çˆ») ê´€ê³„ - 1â†”4, 2â†”5, 3â†”6íš¨ì˜ í˜¸ì‘
6. ë³€í™”ë¥¼ ë‘ë ¤ì›Œí•˜ì§€ ì•Šë„ë¡ ê¸ì •ì ì´ë©´ì„œë„ í˜„ì‹¤ì ìœ¼ë¡œ
7. 4-5ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ì„ ì „ë‹¬"""

                    changing_stream = openai_client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=[{"role": "user", "content": changing_prompt}],
                        temperature=0.7,
                        max_tokens=400,
                        stream=True
                    )

                    changing_text = ""
                    for chunk in changing_stream:
                        if chunk.choices[0].delta.content:
                            content = chunk.choices[0].delta.content
                            changing_text += content
                            yield f"data: {json.dumps({'section': 'changing', 'content': content})}\n\n"

                    yield f"data: {json.dumps({'section': 'changing', 'status': 'done', 'full_text': changing_text})}\n\n"

                # === SECTION 3: Practical Advice (streaming) ===
                yield f"data: {json.dumps({'section': 'advice', 'status': 'start'})}\n\n"

                # Build saju advice context if available
                saju_advice_context = ""
                if saju_element:
                    saju_element_ko = wuxing_korean.get(saju_element, saju_element)
                    saju_advice_context = f"""
ã€ì‚¬ì£¼ ì—°ë™ ì¡°ì–¸ã€‘
- ë‹¹ì‹ ì˜ ì¼ê°„(æ—¥å¹²): {saju_element_ko}
- ê´˜ì˜ ì˜¤í–‰({hex_element_ko})ê³¼ì˜ ê´€ê³„ë¥¼ ê³ ë ¤í•œ ë§ì¶¤ ì¡°ì–¸ í•„ìš”"""

                advice_prompt = f"""ë‹¹ì‹ ì€ ì£¼ì—­ì˜ ì§€í˜œë¥¼ í˜„ëŒ€ ìƒí™œì— ì ìš©í•˜ëŠ” ì‹¤ìš©ì ì¸ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.
ë™ì–‘ ì² í•™ì˜ ê¹Šì€ í†µì°°ì„ ì¼ìƒì—ì„œ ì‹¤ì²œ ê°€ëŠ¥í•œ ì¡°ì–¸ìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.

{lang_instruction}

{current_date_str}

ã€ê´˜ ì •ë³´ã€‘
ê´˜: {hexagram_name} {hexagram_symbol}
í•µì‹¬ ì˜ë¯¸: {core_meaning}
ê´˜ì˜ ì˜¤í–‰: {hex_element_ko}
í˜„ì¬ ê³„ì ˆ: {season_ko} ({season_element})
{saju_advice_context}

{f'ã€ì§ˆë¬¸ã€‘ {question}' if question else ''}

ã€ì•ì„  í•´ì„ ìš”ì•½ã€‘
{overview_text[:400]}

ã€ì¡°ì–¸ ì§€ì¹¨ã€‘
1. ì˜¤í–‰ì˜ ìƒìƒìƒê·¹ì„ í™œìš©í•œ êµ¬ì²´ì  í–‰ë™ ì œì•ˆ
   - ìƒìƒ: ìì—°ìŠ¤ëŸ½ê²Œ íë¥´ëŠ” ë°©í–¥ ì œì‹œ
   - ìƒê·¹: ê·¹ë³µí•´ì•¼ í•  ì ê³¼ ì¡°í™” ë°©ë²•
2. í˜„ì¬ ê³„ì ˆ({season_ko})ì— ë§ëŠ” ì‹œì˜ì ì ˆí•œ ì¡°ì–¸
3. ì˜¤ëŠ˜/ì´ë²ˆ ì£¼ ì‹¤ì²œí•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì  í–‰ë™ 2-3ê°€ì§€
4. ê´˜ìƒ(å¦è±¡) ì´ë¯¸ì§€ë¥¼ ë¹„ìœ ë¡œ í™œìš©
5. ì¹œêµ¬ì—ê²Œ ì¡°ì–¸í•˜ë“¯ ë”°ëœ»í•˜ë©´ì„œë„ í˜„ì‹¤ì ìœ¼ë¡œ
6. ë²ˆí˜¸ ì—†ì´ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ì—°ê²°"""

                advice_stream = openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[{"role": "user", "content": advice_prompt}],
                    temperature=0.7,
                    max_tokens=400,
                    stream=True
                )

                advice_text = ""
                for chunk in advice_stream:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        advice_text += content
                        yield f"data: {json.dumps({'section': 'advice', 'content': content})}\n\n"

                yield f"data: {json.dumps({'section': 'advice', 'status': 'done', 'full_text': advice_text})}\n\n"

                # === DONE ===
                yield f"data: {json.dumps({'done': True})}\n\n"

            except Exception as stream_error:
                logger.exception(f"[ICHING_STREAM] Error: {stream_error}")
                yield f"data: {json.dumps({'error': str(stream_error)})}\n\n"

        return Response(
            generate_stream(),
            mimetype='text/event-stream',
            headers={
                'Cache-Control': 'no-cache',
                'Connection': 'keep-alive',
                'X-Accel-Buffering': 'no'
            }
        )

    except Exception as e:
        logger.exception(f"[ERROR] /iching/reading-stream failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/iching/search", methods=["GET"])
def iching_search():
    """Search I Ching wisdom."""
    if not HAS_ICHING:
        return jsonify({"status": "error", "message": "I Ching module not available"}), 501

    try:
        query = request.args.get("q", "")
        top_k = int(request.args.get("top_k", 5))

        results = search_iching_wisdom(query, top_k=top_k)

        return jsonify({
            "status": "success",
            "results": results,
        })
    except Exception as e:
        logger.exception(f"[ERROR] /iching/search failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/iching/hexagrams", methods=["GET"])
def iching_hexagrams():
    """Get all 64 hexagrams summary."""
    if not HAS_ICHING:
        return jsonify({"status": "error", "message": "I Ching module not available"}), 501

    try:
        locale = request.args.get("locale", "ko")
        summaries = get_all_hexagrams_summary(locale=locale)

        return jsonify({
            "status": "success",
            "hexagrams": summaries,
        })
    except Exception as e:
        logger.exception(f"[ERROR] /iching/hexagrams failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/iching/changing-line", methods=["POST"])
def iching_changing_line():
    """Get detailed changing line interpretation."""
    if not HAS_ICHING:
        return jsonify({"status": "error", "message": "I Ching module not available"}), 501

    try:
        from backend_ai.app.iching_rag import get_changing_line_interpretation

        data = request.get_json() or {}
        hexagram_number = data.get("hexagramNumber")
        line_index = data.get("lineIndex")  # 1-6
        locale = data.get("locale", "ko")

        if not hexagram_number or not line_index:
            return jsonify({
                "status": "error",
                "message": "hexagramNumber and lineIndex are required"
            }), 400

        result = get_changing_line_interpretation(
            hexagram_num=int(hexagram_number),
            line_index=int(line_index),
            locale=locale
        )

        if "error" in result:
            return jsonify({"status": "error", "message": result["error"]}), 400

        return jsonify({
            "status": "success",
            **result
        })
    except Exception as e:
        logger.exception(f"[ERROR] /iching/changing-line failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/iching/hexagram-lines/<int:hexagram_num>", methods=["GET"])
def iching_hexagram_lines(hexagram_num: int):
    """Get all changing line interpretations for a specific hexagram."""
    if not HAS_ICHING:
        return jsonify({"status": "error", "message": "I Ching module not available"}), 501

    try:
        from backend_ai.app.iching_rag import get_all_changing_lines_for_hexagram

        locale = request.args.get("locale", "ko")

        result = get_all_changing_lines_for_hexagram(
            hexagram_num=hexagram_num,
            locale=locale
        )

        if "error" in result:
            return jsonify({"status": "error", "message": result["error"]}), 400

        return jsonify({
            "status": "success",
            **result
        })
    except Exception as e:
        logger.exception(f"[ERROR] /iching/hexagram-lines/{hexagram_num} failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


# ===============================================================
# TAROT (PREMIUM) ENDPOINTS
# ===============================================================

# Theme mapping: Frontend IDs â†’ Backend theme names
TAROT_THEME_MAPPING = {
    # Direct matches
    "love": "love",
    "career": "career",
    "health": "health",
    "spiritual": "spiritual",
    "daily": "daily",
    "monthly": "monthly",
    "life_path": "life_path",
    "family": "family",

    # Frontend uses hyphens, backend uses underscores/different names
    "love-relationships": "love",
    "career-work": "career",
    "money-finance": "wealth",  # Key mapping: frontend uses money-finance, backend uses wealth
    "well-being-health": "health",
    "spiritual-growth": "spiritual",
    "daily-reading": "daily",
    "general-insight": "life_path",  # General maps to life_path
    "decisions-crossroads": "life_path",  # Maps to life_path (contains crossroads sub_topic)
    "self-discovery": "life_path",  # Maps to life_path (contains true_self sub_topic)
}

# Sub-topic mapping for themes that use different sub_topic names
TAROT_SUBTOPIC_MAPPING = {
    # decisions-crossroads spreads â†’ life_path sub_topics
    ("decisions-crossroads", "simple-choice"): ("life_path", "crossroads"),
    ("decisions-crossroads", "decision-cross"): ("life_path", "major_decision"),
    ("decisions-crossroads", "path-ahead"): ("life_path", "life_direction"),

    # self-discovery spreads â†’ life_path sub_topics
    ("self-discovery", "inner-self"): ("life_path", "true_self"),
    ("self-discovery", "personal-growth"): ("life_path", "life_lessons"),

    # general-insight spreads â†’ various themes
    ("general-insight", "quick-reading"): ("daily", "one_card"),
    ("general-insight", "past-present-future"): ("daily", "three_card"),
    ("general-insight", "celtic-cross"): ("life_path", "life_direction"),
}


def _map_tarot_theme(category: str, spread_id: str) -> tuple:
    """Map frontend theme/spread to backend theme/sub_topic"""
    # Check specific mapping first
    key = (category, spread_id)
    if key in TAROT_SUBTOPIC_MAPPING:
        return TAROT_SUBTOPIC_MAPPING[key]

    # Fall back to theme-only mapping
    mapped_theme = TAROT_THEME_MAPPING.get(category, category)
    return (mapped_theme, spread_id)


# ===============================================================
# ğŸ´ AI íŠ¹ìœ  í‘œí˜„ í›„ì²˜ë¦¬ í•„í„°
# ===============================================================
def _clean_ai_phrases(text: str) -> str:
    """
    Remove AI-sounding phrases from tarot interpretations.
    Makes output more natural and less robotic.
    """
    import re

    # AI íŠ¹ìœ ì˜ í•œêµ­ì–´ í‘œí˜„ íŒ¨í„´
    ai_patterns_ko = [
        (r'~í•˜ì‹œëŠ”êµ°ìš”\.?', ''),
        (r'~ëŠë¼ì‹¤ ìˆ˜ ìˆì–´ìš”\.?', ''),
        (r'~í•˜ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤\.?', ''),
        (r'~í•´ë³´ì‹œëŠ” ê±´ ì–´ë–¨ê¹Œìš”\?', ''),
        (r'ê¸ì •ì ì¸ ì—ë„ˆì§€ê°€ ëŠê»´ì§€ë„¤ìš”\.?', ''),
        (r'ì¢‹ì€ ê²°ê³¼ê°€ ìˆì„ ê±°ì˜ˆìš”\.?', ''),
        (r'ì˜ ë  ê±°ì˜ˆìš”\.?', ''),
        (r'ê±±ì •í•˜ì§€ ë§ˆì„¸ìš”\.?', ''),
        (r'ìì‹ ê°ì„ ê°€ì§€ì‹œë©´ ì¢‹ê² ìŠµë‹ˆë‹¤\.?', ''),
        (r'~ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤\.', 'ë‹¤.'),
        (r'~ì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤\.', 'ë‹¤.'),
        (r'~ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\.', 'ë‹¤.'),
        (r'í¬ë§ì ì¸ ë©”ì‹œì§€ë¥¼ ì „í•˜ê³  ìˆë„¤ìš”\.?', ''),
        (r'ì‘ì›í•©ë‹ˆë‹¤\.?', ''),
        (r'íŒŒì´íŒ…ì´ì—ìš”\.?', ''),
        (r'í™”ì´íŒ…!?', ''),
    ]

    # AI íŠ¹ìœ ì˜ ì˜ì–´ í‘œí˜„ íŒ¨í„´
    ai_patterns_en = [
        (r'I hope this helps\.?', ''),
        (r'Feel free to ask.*', ''),
        (r'I\'m here to help\.?', ''),
        (r'This suggests that you should\.?', 'This suggests'),
        (r'It\'s important to remember that\.?', ''),
        (r'positive energy', 'energy'),
    ]

    result = text
    for pattern, replacement in ai_patterns_ko + ai_patterns_en:
        result = re.sub(pattern, replacement, result)

    # ì—°ì†ëœ ê³µë°±/ë§ˆì¹¨í‘œ ì •ë¦¬
    result = re.sub(r'\s+', ' ', result)
    result = re.sub(r'\.+', '.', result)
    result = result.strip()

    return result


# ===============================================================
# ğŸ´ DYNAMIC FOLLOW-UP QUESTIONS GENERATOR
# ===============================================================
def generate_dynamic_followup_questions(
    interpretation: str,
    cards: list,
    category: str,
    user_question: str = "",
    language: str = "ko",
    static_questions: list = None
) -> list:
    """
    Generate dynamic, contextual follow-up questions based on the interpretation.
    Uses GPT to create specific, engaging questions that change with each reading.

    Args:
        interpretation: The full interpretation text
        cards: List of card dicts with 'name' and 'isReversed'
        category: Theme category (love, career, etc.)
        user_question: Original user question if any
        language: 'ko' or 'en'
        static_questions: Fallback static questions

    Returns:
        List of 5 dynamic follow-up questions
    """
    try:
        # Extract key elements from interpretation for context
        interpretation_preview = interpretation[:800] if len(interpretation) > 800 else interpretation
        card_names = [f"{c.get('name', '')}{'(ì—­ë°©í–¥)' if c.get('isReversed') else ''}" for c in cards]
        cards_str = ", ".join(card_names)

        # Detect reading tone from interpretation
        positive_keywords = ["ê¸°íšŒ", "ì„±ê³µ", "í–‰ìš´", "ê¸ì •", "ë°œì „", "í¬ë§", "ì‚¬ë‘", "ì¶•ë³µ", "ì„±ì·¨", "ê¸°ì¨",
                           "opportunity", "success", "luck", "positive", "growth", "hope", "love", "blessing", "joy"]
        challenging_keywords = ["ì£¼ì˜", "ê²½ê³ ", "ìœ„í—˜", "ë„ì „", "ê°ˆë“±", "ì–´ë ¤ì›€", "ì¥ì• ", "ì‹œë ¨", "ì¡°ì‹¬",
                               "caution", "warning", "danger", "challenge", "conflict", "difficulty", "obstacle"]

        tone = "neutral"
        positive_count = sum(1 for k in positive_keywords if k in interpretation.lower())
        challenging_count = sum(1 for k in challenging_keywords if k in interpretation.lower())

        if positive_count > challenging_count + 2:
            tone = "positive"
        elif challenging_count > positive_count + 2:
            tone = "challenging"

        # Build GPT prompt for generating dynamic questions
        is_korean = language == "ko"

        if is_korean:
            prompt = f"""ë‹¹ì‹ ì€ ì „ë¬¸ íƒ€ë¡œ ë¦¬ë”ì…ë‹ˆë‹¤. ë°©ê¸ˆ ì œê³µëœ íƒ€ë¡œ í•´ì„ì„ ë°”íƒ•ìœ¼ë¡œ, ì‚¬ìš©ìê°€ ë” ê¹Šì´ íƒêµ¬í•˜ê³  ì‹¶ì–´í•  ë§Œí•œ í›„ì† ì§ˆë¬¸ 5ê°œë¥¼ ìƒì„±í•˜ì„¸ìš”.

## í•´ì„ ìš”ì•½
ì¹´ë“œ: {cards_str}
ì¹´í…Œê³ ë¦¬: {category}
ë¦¬ë”© í†¤: {tone}
{'ì›ë˜ ì§ˆë¬¸: ' + user_question if user_question else ''}

## í•´ì„ ë‚´ìš©
{interpretation_preview}

## ì§ˆë¬¸ ìƒì„± ì§€ì¹¨
1. í•´ì„ì—ì„œ ì–¸ê¸‰ëœ êµ¬ì²´ì ì¸ ë‚´ìš©/ìƒì§•/ì¡°ì–¸ì— ê¸°ë°˜í•œ ì§ˆë¬¸
2. ì‚¬ìš©ìê°€ "ì™€, ì´ê±¸ ë” ì•Œê³  ì‹¶ë‹¤!" ë¼ê³  ëŠë‚„ ë§Œí¼ í¥ë¯¸ë¡œìš´ ì§ˆë¬¸
3. ë‹¨ìˆœ ì˜ˆ/ì•„ë‹ˆì˜¤ê°€ ì•„ë‹Œ, ê¹Šì´ ìˆëŠ” ëŒ€í™”ë¥¼ ìœ ë„í•˜ëŠ” ì§ˆë¬¸
4. ì¹´ë“œ ì´ë¦„ì´ë‚˜ ìƒì§•ì„ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰
5. ê° ì§ˆë¬¸ì€ ì„œë¡œ ë‹¤ë¥¸ ê´€ì  ì œì‹œ (ì‹œê¸°, ì¡°ì–¸, ìˆ¨ê²¨ì§„ ì˜ë¯¸, ê´€ê³„, í–‰ë™)

## ì‘ë‹µ í˜•ì‹
ì§ˆë¬¸ 5ê°œë¥¼ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„í•´ì„œ ì‘ì„±í•˜ì„¸ìš”. ë²ˆí˜¸ë‚˜ ë¶ˆë¦¿ ì—†ì´ ì§ˆë¬¸ë§Œ ì‘ì„±.

ì˜ˆì‹œ:
{card_names[0] if card_names else 'ê´‘ëŒ€'} ì¹´ë“œê°€ ì•”ì‹œí•˜ëŠ” ìƒˆë¡œìš´ ì‹œì‘ì˜ êµ¬ì²´ì ì¸ íƒ€ì´ë°ì€?
ì´ ë¦¬ë”©ì—ì„œ ê²½ê³ í•˜ëŠ” ìˆ¨ê²¨ì§„ ì¥ì• ë¬¼ì„ ê·¹ë³µí•˜ëŠ” ë°©ë²•ì€?"""
        else:
            prompt = f"""You are an expert tarot reader. Based on the tarot interpretation just provided, generate 5 follow-up questions the user would want to explore deeper.

## Reading Summary
Cards: {cards_str}
Category: {category}
Reading Tone: {tone}
{'Original Question: ' + user_question if user_question else ''}

## Interpretation
{interpretation_preview}

## Question Guidelines
1. Based on specific content/symbols/advice mentioned in the interpretation
2. Intriguing enough that user thinks "I want to know more about this!"
3. Open-ended questions that lead to deeper conversation
4. Specifically mention card names or symbols
5. Each question offers a different perspective (timing, advice, hidden meaning, relationships, actions)

## Response Format
Write 5 questions separated by newlines. No numbers or bullets, just questions.

Example:
What specific timing does {card_names[0] if card_names else 'The Fool'} suggest for this new beginning?
How can I overcome the hidden obstacles this reading warns about?"""

        # Generate with GPT-4o-mini for speed
        response = _generate_with_gpt4(prompt, max_tokens=500, temperature=0.8, use_mini=True)

        # Parse response into list
        questions = [q.strip() for q in response.strip().split('\n') if q.strip() and len(q.strip()) > 10]

        # Ensure we have exactly 5 questions
        if len(questions) >= 5:
            return questions[:5]
        elif len(questions) > 0:
            # Pad with static questions if needed
            if static_questions:
                remaining = 5 - len(questions)
                questions.extend(static_questions[:remaining])
            return questions[:5]
        else:
            # Fallback to static
            return static_questions[:5] if static_questions else []

    except Exception as e:
        logger.warning(f"[TAROT] Dynamic question generation failed: {e}")
        return static_questions[:5] if static_questions else []


@app.route("/api/tarot/interpret", methods=["POST"])
def tarot_interpret():
    """
    Premium tarot interpretation using Hybrid RAG + Gemini.
    Supports optional saju/astrology context for enhanced readings.
    With caching for same card combinations.
    """
    if not HAS_TAROT:
        return jsonify({"status": "error", "message": "Tarot module not available"}), 501

    try:
        data = request.get_json(force=True)
        logger.info(f"[TAROT] id={g.request_id} Interpreting tarot reading")

        category = data.get("category", "general")
        spread_id = data.get("spread_id", "three_card")
        spread_title = data.get("spread_title", "Three Card Spread")
        cards = data.get("cards", [])
        user_question = data.get("user_question", "")
        language = data.get("language", "ko")

        # Optional context for enhanced readings (from destiny-map)
        saju_context = data.get("saju_context")  # e.g., day_master, five_elements
        astro_context = data.get("astro_context")  # e.g., sun_sign, moon_sign

        # Premium personalization (Tier 4-6)
        birthdate = data.get("birthdate")  # User's birthdate 'YYYY-MM-DD' for birth card
        moon_phase = data.get("moon_phase")  # Current moon phase for realtime context

        if not cards:
            return jsonify({"status": "error", "message": "No cards provided"}), 400

        start_time = time.time()

        # === CACHING: Check cache for same card combination ===
        # Build cache key from cards + category + spread + language
        card_key = "_".join(sorted([
            f"{c.get('name', '')}{'_R' if c.get('is_reversed') else ''}"
            for c in cards
        ]))
        cache_key = f"tarot:interpret:{category}:{spread_id}:{language}:{card_key}"

        # Don't cache if user has specific question or personalization
        use_cache = not user_question and not birthdate and not saju_context and not astro_context
        cache = get_cache()

        if use_cache and cache:
            cached_result = cache.get(cache_key)
            if cached_result:
                duration_ms = int((time.time() - start_time) * 1000)
                logger.info(f"[TAROT] id={g.request_id} CACHE HIT in {duration_ms}ms")
                cached_result["cached"] = True
                cached_result["performance"] = {"duration_ms": duration_ms, "cache_hit": True}
                return jsonify(cached_result)
        hybrid_rag = get_tarot_hybrid_rag()

        # Convert cards to expected format
        drawn_cards = [
            {"name": c.get("name", ""), "isReversed": c.get("is_reversed", False)}
            for c in cards
        ]

        # Build enhanced context if saju/astro data is available
        enhanced_question = user_question
        if saju_context or astro_context:
            context_parts = []
            if saju_context:
                day_master = saju_context.get("day_master", {})
                if day_master:
                    context_parts.append(f"ì¼ê°„: {day_master.get('element', '')} {day_master.get('stem', '')}")
                five_elements = saju_context.get("five_elements", {})
                if five_elements:
                    dominant = max(five_elements.items(), key=lambda x: x[1])[0] if five_elements else None
                    if dominant:
                        context_parts.append(f"ì£¼ìš” ì˜¤í–‰: {dominant}")

            if astro_context:
                sun_sign = astro_context.get("sun_sign", "")
                moon_sign = astro_context.get("moon_sign", "")
                if sun_sign:
                    context_parts.append(f"íƒœì–‘ ë³„ìë¦¬: {sun_sign}")
                if moon_sign:
                    context_parts.append(f"ë‹¬ ë³„ìë¦¬: {moon_sign}")

            if context_parts:
                enhanced_question = f"[ë°°ê²½: {', '.join(context_parts)}] {user_question}"

        # Generate reading using GPT-4 (same as destiny-map)
        # Apply theme/spread mapping (frontend IDs â†’ backend names)
        mapped_theme, mapped_spread = _map_tarot_theme(category, spread_id)
        logger.info(f"[TAROT] Mapped {category}/{spread_id} â†’ {mapped_theme}/{mapped_spread}")

        # === PARALLEL PROCESSING: Build RAG context and advanced analysis concurrently ===
        def build_rag_context():
            if birthdate:
                return hybrid_rag.build_premium_reading_context(
                    theme=mapped_theme,
                    sub_topic=mapped_spread,
                    drawn_cards=drawn_cards,
                    question=enhanced_question,
                    birthdate=birthdate,
                    moon_phase=moon_phase
                )
            else:
                return hybrid_rag.build_reading_context(
                    theme=mapped_theme,
                    sub_topic=mapped_spread,
                    drawn_cards=drawn_cards,
                    question=enhanced_question
                )

        def build_advanced_analysis():
            return hybrid_rag.get_advanced_analysis(drawn_cards)

        # Run both in parallel using ThreadPoolExecutor
        with ThreadPoolExecutor(max_workers=2) as executor:
            rag_future = executor.submit(build_rag_context)
            advanced_future = executor.submit(build_advanced_analysis)

            rag_context = rag_future.result()
            advanced = advanced_future.result()

        if birthdate:
            logger.info(f"[TAROT] Using premium context with birthdate={birthdate} (parallel)")
        logger.info(f"[TAROT] RAG context and advanced analysis built in parallel")

        # Step 2: Build premium tarot prompt with current date context
        is_korean = language == "ko"
        cards_str = ", ".join([
            f"{c.get('name', '')}{'(ì—­ë°©í–¥)' if c.get('isReversed') else ''}"
            for c in drawn_cards
        ])

        # Current date info for time-relevant advice
        now = datetime.now()
        weekday_names_ko = ["ì›”ìš”ì¼", "í™”ìš”ì¼", "ìˆ˜ìš”ì¼", "ëª©ìš”ì¼", "ê¸ˆìš”ì¼", "í† ìš”ì¼", "ì¼ìš”ì¼"]
        weekday_names_en = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]
        month_names_ko = ["1ì›”", "2ì›”", "3ì›”", "4ì›”", "5ì›”", "6ì›”", "7ì›”", "8ì›”", "9ì›”", "10ì›”", "11ì›”", "12ì›”"]

        if is_korean:
            date_str = f"{now.year}ë…„ {now.month}ì›” {now.day}ì¼ ({weekday_names_ko[now.weekday()]})"
            season = "ë´„" if now.month in [3, 4, 5] else "ì—¬ë¦„" if now.month in [6, 7, 8] else "ê°€ì„" if now.month in [9, 10, 11] else "ê²¨ìš¸"
        else:
            date_str = now.strftime("%B %d, %Y (%A)")
            season = "Spring" if now.month in [3, 4, 5] else "Summer" if now.month in [6, 7, 8] else "Fall" if now.month in [9, 10, 11] else "Winter"

        # Try to get moon phase from advanced rules
        moon_phase_hint = ""
        try:
            moon_guidance = hybrid_rag.advanced_rules.get_current_moon_advice("waxing_crescent")  # placeholder
            if moon_guidance:
                moon_phase_hint = f"\n- ë‹¬ ìœ„ìƒ ì—ë„ˆì§€: {moon_guidance.get('energy', '')}"
        except Exception:
            pass

        tarot_prompt = f"""ë‹¹ì‹ ì€ 10ë…„ ê²½ë ¥ì˜ íƒ€ë¡œ ë¦¬ë”ì…ë‹ˆë‹¤. ì¹´ë“œ ìƒì§•ê³¼ ì´ë¯¸ì§€ë¥¼ ì§ê´€ì ìœ¼ë¡œ ì½ì–´ë‚´ë©°, ì§ˆë¬¸ìì˜ ìƒí™©ì— ë§ëŠ” ì‹¤ì§ˆì ì¸ í†µì°°ì„ ì „ë‹¬í•©ë‹ˆë‹¤.

## ì˜¤ëŠ˜: {date_str} ({season}){moon_phase_hint}

## ë¦¬ë”© ì •ë³´
ì¹´í…Œê³ ë¦¬: {category}
ìŠ¤í”„ë ˆë“œ: {spread_title}
ì¹´ë“œ: {cards_str}
ì§ˆë¬¸: {enhanced_question or "ì¼ë°˜ ìš´ì„¸"}

## ì¹´ë“œ ì»¨í…ìŠ¤íŠ¸
{rag_context}

## ì¢‹ì€ í•´ì„ ì˜ˆì‹œ
"íƒ‘ ì¹´ë“œê°€ ì²« ìœ„ì¹˜ì— ë‚˜ì™”ë‹¤. ë²ˆê°œê°€ ì™•ê´€ì„ ì¹˜ê³  ë‘ ì‚¬ëŒì´ ì¶”ë½í•˜ëŠ” ê·¸ë¦¼â€”ì§€ê¸ˆ ë­”ê°€ê°€ ë¬´ë„ˆì§€ê³  ìˆê±°ë‚˜, ê³§ ë¬´ë„ˆì§ˆ ê²ƒì´ë‹¤. í•˜ì§€ë§Œ ë‘ ë²ˆì§¸ ìœ„ì¹˜ì˜ ë³„ ì¹´ë“œë¥¼ ë³´ë¼. í­í’ í›„ ë²Œê±°ë²—ì€ ì—¬ì¸ì´ ë¬¼ì„ ë¶“ê³  ìˆë‹¤. ë¬´ë„ˆì§„ í›„ì— ì¹˜ìœ ê°€ ì˜¨ë‹¤. ì„¸ ë²ˆì§¸ í™©ì œ ì¹´ë“œëŠ” ê·¸ ì”í•´ ìœ„ì— ìƒˆë¡œìš´ ì§ˆì„œë¥¼ ì„¸ìš°ë¼ê³  í•œë‹¤. ì§€ê¸ˆ ë¬´ë„ˆì§€ëŠ” ê²Œ ë­ë“ , ê·¸ê±´ ì´ë¯¸ ê¸ˆì´ ê°€ ìˆì—ˆë‹¤."

## í”¼í•´ì•¼ í•  AIìŠ¤ëŸ¬ìš´ í•´ì„
"ì´ ì¹´ë“œëŠ” ë³€í™”ë¥¼ ë‚˜íƒ€ë‚´ë©°, ìƒˆë¡œìš´ ì‹œì‘ì˜ ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤. ê¸ì •ì ì¸ ì—ë„ˆì§€ê°€ ëŠê»´ì§€ë„¤ìš”. ìì‹ ê°ì„ ê°€ì§€ê³  ì•ìœ¼ë¡œ ë‚˜ì•„ê°€ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤."

## í•´ì„ ë°©í–¥
- ì¹´ë“œ ì´ë¯¸ì§€ì˜ ìƒì§•ì„ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰
- ìœ„ì¹˜ë³„ ì¹´ë“œê°€ ì„œë¡œ ì–´ë–¤ ì´ì•¼ê¸°ë¥¼ ë§Œë“¤ì–´ë‚´ëŠ”ì§€ ì—°ê²°
- ë§‰ì—°í•œ ê²©ë ¤ ëŒ€ì‹  êµ¬ì²´ì ì¸ ìƒí™© í•´ì„
- ì§ˆë¬¸ê³¼ ì§ì ‘ ì—°ê²°ëœ í†µì°° ì œì‹œ
- {('ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´' if is_korean else 'Natural English')}
- 500-700ì"""

        # Generate with GPT-4o-mini (fast, skip refine step)
        try:
            reading_text = _generate_with_gpt4(tarot_prompt, max_tokens=1200, temperature=0.8, use_mini=True)
            # Apply post-processing to remove AI-sounding phrases
            reading_text = _clean_ai_phrases(reading_text)
        except Exception as llm_e:
            logger.warning(f"[TAROT] GPT-4o-mini failed: {llm_e}, using fallback")
            reading_text = f"ì¹´ë“œ í•´ì„: {cards_str}. {rag_context[:500]}"

        # Get card insights
        card_insights = []
        for i, card in enumerate(drawn_cards):
            card_name = card.get("name", "")
            is_reversed = card.get("isReversed", False)
            position = cards[i].get("position", f"Card {i+1}") if i < len(cards) else f"Card {i+1}"

            insights = hybrid_rag.get_card_insights(card_name)

            card_insight = {
                "position": position,
                "card_name": card_name,
                "is_reversed": is_reversed,
                "interpretation": reading_text[:300] if i == 0 else "",  # Just first part for first card
                "spirit_animal": insights.get("spirit_animal"),
                "chakra": None,
                "element": None,
                "shadow": insights.get("shadow_work")
            }

            # Extract chakra
            chakras = insights.get("chakras", [])
            if chakras:
                first_chakra = chakras[0]
                card_insight["chakra"] = {
                    "name": first_chakra.get("korean", first_chakra.get("name", "")),
                    "color": first_chakra.get("color", "#8a2be2"),
                    "guidance": first_chakra.get("healing_affirmation", "")
                }

            # Extract element from astrology
            astro = insights.get("astrology", {})
            if astro:
                card_insight["element"] = astro.get("element")

            card_insights.append(card_insight)

        # Note: advanced analysis already done in parallel above

        # Build response
        # Get static questions as fallback
        static_followup = hybrid_rag.advanced_rules.get_followup_questions(category, "neutral") if hasattr(hybrid_rag, 'advanced_rules') else []

        # Generate dynamic, contextual follow-up questions based on the interpretation
        dynamic_followup = generate_dynamic_followup_questions(
            interpretation=reading_text,
            cards=drawn_cards,
            category=category,
            user_question=enhanced_question or user_question or "",
            language=language,
            static_questions=static_followup
        )

        result = {
            "overall_message": reading_text,
            "card_insights": card_insights,
            "guidance": advanced.get("elemental_analysis", {}).get("dominant_advice", "ì¹´ë“œì˜ ì§€í˜œì— ê·€ ê¸°ìš¸ì´ì„¸ìš”."),
            "affirmation": "ë‚˜ëŠ” ìš°ì£¼ì˜ ì§€í˜œë¥¼ ì‹ ë¢°í•©ë‹ˆë‹¤.",
            "combinations": [],
            "followup_questions": dynamic_followup
        }

        # Add combination if found
        combo = advanced.get("special_combination")
        if combo:
            result["combinations"].append({
                "cards": combo.get("cards", []),
                "meaning": combo.get("korean", combo.get("meaning", ""))
            })

        # Add premium personalization if birthdate provided
        logger.info(f"[TAROT] Checking birthdate for personalization: birthdate={birthdate}")
        if birthdate:
            logger.info(f"[TAROT] Starting personalization with birthdate={birthdate}")
            try:
                birth_card = hybrid_rag.get_birth_card(birthdate)
                logger.info(f"[TAROT] Got birth_card: {birth_card.get('primary_card', 'NONE')}")
                year_card = hybrid_rag.get_year_card(birthdate)
                logger.info(f"[TAROT] Got year_card: {year_card.get('year_card', 'NONE')}")
                personalization = hybrid_rag.get_personalized_reading(drawn_cards, birthdate)
                narrative = hybrid_rag.get_reading_narrative(drawn_cards, mapped_theme)

                result["personalization"] = {
                    "birth_card": {
                        "name": birth_card.get("primary_card"),
                        "korean": birth_card.get("korean"),
                        "traits": birth_card.get("traits", [])
                    },
                    "year_card": {
                        "name": year_card.get("year_card"),
                        "korean": year_card.get("year_card_korean"),
                        "theme": year_card.get("korean"),
                        "advice": year_card.get("advice")
                    },
                    "personal_connections": personalization.get("personal_connections", [])
                }

                result["narrative"] = {
                    "opening_hook": narrative.get("opening_hook"),
                    "tone": narrative.get("tone", {}).get("mood"),
                    "resolution": narrative.get("resolution"),
                    "card_connections": hybrid_rag.get_card_connections(drawn_cards)[:5]
                }
            except Exception as pers_e:
                logger.warning(f"[TAROT] Personalization failed: {pers_e}")

        duration_ms = int((time.time() - start_time) * 1000)
        logger.info(f"[TAROT] id={g.request_id} completed in {duration_ms}ms")
        result["performance"] = {"duration_ms": duration_ms, "cache_hit": False}

        # === CACHING: Store result in cache for same card combination ===
        if use_cache and cache:
            try:
                # Cache for 1 hour (3600 seconds) - same cards can have slightly varied interpretations
                cache.set(cache_key, result, ttl=3600)
                logger.info(f"[TAROT] Cached result for key: {cache_key[:50]}...")
            except Exception as cache_err:
                logger.warning(f"[TAROT] Failed to cache: {cache_err}")

        return jsonify(result)

    except Exception as e:
        logger.exception(f"[ERROR] /api/tarot/interpret failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/api/tarot/prefetch", methods=["POST"])
def tarot_prefetch():
    """
    Prefetch RAG context while user is selecting cards.
    Call this when user starts card selection to warm up the RAG system.
    """
    if not HAS_TAROT:
        return jsonify({"status": "error", "message": "Tarot module not available"}), 501

    try:
        data = request.get_json(force=True)
        category = data.get("category", "general")
        spread_id = data.get("spread_id", "three_card")

        logger.info(f"[TAROT_PREFETCH] id={g.request_id} Prefetching for {category}/{spread_id}")

        start_time = time.time()
        hybrid_rag = get_tarot_hybrid_rag()

        # Map theme/spread
        mapped_theme, mapped_spread = _map_tarot_theme(category, spread_id)

        # Pre-warm the RAG by loading theme-specific data
        # This loads embeddings and indexes into memory
        try:
            # Load theme data
            hybrid_rag._ensure_loaded()

            # Pre-compute some common lookups
            if hasattr(hybrid_rag, 'advanced_rules'):
                hybrid_rag.advanced_rules.get_followup_questions(category, "neutral")

            duration_ms = int((time.time() - start_time) * 1000)
            logger.info(f"[TAROT_PREFETCH] Completed in {duration_ms}ms")

            return jsonify({
                "status": "ready",
                "category": category,
                "spread_id": spread_id,
                "mapped_theme": mapped_theme,
                "mapped_spread": mapped_spread,
                "duration_ms": duration_ms
            })

        except Exception as warm_e:
            logger.warning(f"[TAROT_PREFETCH] Warm-up failed: {warm_e}")
            return jsonify({
                "status": "partial",
                "message": str(warm_e)
            })

    except Exception as e:
        logger.exception(f"[ERROR] /api/tarot/prefetch failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/api/tarot/interpret-stream", methods=["POST"])
def tarot_interpret_stream():
    """
    Streaming tarot interpretation - returns SSE for real-time display.
    Streams: overall_message â†’ card_insights (one by one) â†’ guidance â†’ done
    """
    if not HAS_TAROT:
        return jsonify({"status": "error", "message": "Tarot module not available"}), 501

    try:
        data = request.get_json(force=True)
        logger.info(f"[TAROT_STREAM] id={g.request_id} Starting streaming interpretation")

        category = data.get("category", "general")
        spread_id = data.get("spread_id", "three_card")
        spread_title = data.get("spread_title", "Three Card Spread")
        cards = data.get("cards", [])
        user_question = data.get("user_question", "")
        language = data.get("language", "ko")

        if not cards:
            return jsonify({"status": "error", "message": "No cards provided"}), 400

        hybrid_rag = get_tarot_hybrid_rag()

        # Convert cards to expected format
        drawn_cards = [
            {"name": c.get("name", ""), "isReversed": c.get("is_reversed", False)}
            for c in cards
        ]

        # Map theme/spread
        mapped_theme, mapped_spread = _map_tarot_theme(category, spread_id)

        # Build context in parallel
        def build_rag():
            return hybrid_rag.build_reading_context(
                theme=mapped_theme,
                sub_topic=mapped_spread,
                drawn_cards=drawn_cards,
                question=user_question
            )

        def build_advanced():
            return hybrid_rag.get_advanced_analysis(drawn_cards)

        with ThreadPoolExecutor(max_workers=2) as executor:
            rag_future = executor.submit(build_rag)
            adv_future = executor.submit(build_advanced)
            rag_context = rag_future.result()
            advanced = adv_future.result()

        is_korean = language == "ko"
        cards_str = ", ".join([
            f"{c.get('name', '')}{'(ì—­ë°©í–¥)' if c.get('isReversed') else ''}"
            for c in drawn_cards
        ])

        now = datetime.now()
        weekday_names_ko = ["ì›”ìš”ì¼", "í™”ìš”ì¼", "ìˆ˜ìš”ì¼", "ëª©ìš”ì¼", "ê¸ˆìš”ì¼", "í† ìš”ì¼", "ì¼ìš”ì¼"]
        if is_korean:
            date_str = f"{now.year}ë…„ {now.month}ì›” {now.day}ì¼ ({weekday_names_ko[now.weekday()]})"
        else:
            date_str = now.strftime("%B %d, %Y (%A)")

        def generate_stream():
            """Generator for SSE streaming interpretation"""
            try:
                if not OPENAI_AVAILABLE or not openai_client:
                    yield f"data: {json.dumps({'error': 'OpenAI not available'})}\n\n"
                    return

                # === SECTION 1: Overall Message (streaming) ===
                yield f"data: {json.dumps({'section': 'overall_message', 'status': 'start'})}\n\n"

                overall_prompt = f"""ë‹¹ì‹ ì€ ê²½í—˜ ë§ì€ íƒ€ë¡œ ë¦¬ë”ì…ë‹ˆë‹¤. ì¹´ë“œì˜ ìƒì§•ê³¼ ì´ë¯¸ì§€ë¥¼ ì§ê´€ì ìœ¼ë¡œ ì½ê³ , ì§ˆë¬¸ìì—ê²Œ ì‹¤ì§ˆì ì¸ í†µì°°ì„ ì „ë‹¬í•©ë‹ˆë‹¤.

ì¹´ë“œ: {cards_str}
ì¹´í…Œê³ ë¦¬: {category}
ìŠ¤í”„ë ˆë“œ: {spread_title}
ì§ˆë¬¸: {user_question or "ì¼ë°˜ ìš´ì„¸"}

ì°¸ê³  ì»¨í…ìŠ¤íŠ¸:
{rag_context[:1500]}

ì¢‹ì€ ì˜ˆì‹œ: "ì ˆë²½ ëì— ì„  ê´‘ëŒ€ê°€ ì²« ì¹´ë“œë‹¤. ë°œë°‘ì„ ì•ˆ ë³´ê³  í•˜ëŠ˜ì„ ë³¸ë‹¤â€”ë­”ê°€ ì‹œì‘í•˜ë ¤ í•˜ì§€ë§Œ ì¤€ë¹„ê°€ ëœ ëë‹¤. ë‘ ë²ˆì§¸ í˜ ì¹´ë“œëŠ” ì‚¬ìì˜ í„±ì„ ë¶€ë“œëŸ½ê²Œ ì¡ì€ ì—¬ì¸, ì–µì§€ë¡œ ë°€ì–´ë¶™ì´ì§€ ë§ë¼ëŠ” ëœ»ì´ë‹¤."
í”¼í•  ê²ƒ: "ê¸ì •ì ì¸ ì—ë„ˆì§€ê°€ ëŠê»´ì§€ë„¤ìš”. ì¢‹ì€ ë³€í™”ê°€ ì˜¬ ê²ƒ ê°™ìŠµë‹ˆë‹¤."

í•´ì„ ë°©í–¥:
- ì¹´ë“œ ì´ë¯¸ì§€ì˜ êµ¬ì²´ì  ìƒì§• ì–¸ê¸‰ (ì¸ë¬¼, ë°°ê²½, ë¬¼ê±´)
- ì¹´ë“œë“¤ì´ ì—°ê²°ë˜ì–´ ë³´ì—¬ì£¼ëŠ” ì´ì•¼ê¸°
- 3-4ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ë§Œ"""

                stream = openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[{"role": "user", "content": overall_prompt}],
                    temperature=0.8,
                    max_tokens=300,
                    stream=True
                )

                overall_text = ""
                for chunk in stream:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        overall_text += content
                        yield f"data: {json.dumps({'section': 'overall_message', 'content': content})}\n\n"

                yield f"data: {json.dumps({'section': 'overall_message', 'status': 'done', 'full_text': overall_text})}\n\n"

                # === SECTION 2: Card Insights (one by one, streaming each) ===
                for i, card in enumerate(drawn_cards):
                    card_name = card.get("name", "")
                    is_reversed = card.get("isReversed", False)
                    position = cards[i].get("position", f"Card {i+1}") if i < len(cards) else f"Card {i+1}"

                    yield f"data: {json.dumps({'section': 'card_insight', 'index': i, 'status': 'start', 'card_name': card_name, 'position': position})}\n\n"

                    # Get card-specific context
                    card_info = hybrid_rag.get_card_info(card_name, is_reversed)
                    insights = hybrid_rag.get_card_insights(card_name, is_reversed)

                    card_prompt = f"""ë‹¹ì‹ ì€ íƒ€ë¡œ ë¦¬ë”ì…ë‹ˆë‹¤. ì´ ì¹´ë“œì˜ ìƒì§•ê³¼ ì´ë¯¸ì§€ê°€ í˜„ì¬ ìœ„ì¹˜ì—ì„œ ë¬´ì—‡ì„ ì˜ë¯¸í•˜ëŠ”ì§€ í•´ì„í•˜ì„¸ìš”.

ì¹´ë“œ: {card_name}{'(ì—­ë°©í–¥)' if is_reversed else ''}
ìœ„ì¹˜: {position}
ìŠ¤í”„ë ˆë“œ: {spread_title}
ì§ˆë¬¸: {user_question or "ì¼ë°˜ ìš´ì„¸"}

ì¹´ë“œ ì •ë³´:
{json.dumps(card_info, ensure_ascii=False)[:800]}

ì‹¬ë¦¬í•™ì  í†µì°°:
{json.dumps(insights, ensure_ascii=False)[:500]}

ì¢‹ì€ ì˜ˆì‹œ: "ì—¬ì‚¬ì œê°€ ë‘ ê¸°ë‘¥ ì‚¬ì´ì— ì•‰ì•„ ìˆë‹¤â€”Bì™€ J, ë°ìŒê³¼ ì–´ë‘ ì˜ ê²½ê³„. ë’¤ì˜ ë² ì¼ ë„ˆë¨¸ì—” ë°”ë‹¤ê°€ ë¹„ì¹œë‹¤. ì•Œê³  ìˆì§€ë§Œ ë§í•˜ì§€ ì•ŠëŠ” ê²ƒì´ ìˆë‹¤."
í”¼í•  ê²ƒ: "ì´ ì¹´ë“œëŠ” ì§ê´€ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ë‚´ë©´ì˜ ëª©ì†Œë¦¬ì— ê·€ ê¸°ìš¸ì´ì‹œë©´ ì¢‹ê² ìŠµë‹ˆë‹¤."

í•´ì„ ë°©í–¥:
- ì¹´ë“œ ê·¸ë¦¼ì˜ êµ¬ì²´ì  ìƒì§• (ì¸ë¬¼ ìì„¸, ë°°ê²½, ë¬¼ê±´)
- {position} ìœ„ì¹˜ì—ì„œì˜ ì˜ë¯¸
- 2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ"""

                    card_stream = openai_client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=[{"role": "user", "content": card_prompt}],
                        temperature=0.8,
                        max_tokens=250,
                        stream=True
                    )

                    card_text = ""
                    for chunk in card_stream:
                        if chunk.choices[0].delta.content:
                            content = chunk.choices[0].delta.content
                            card_text += content
                            yield f"data: {json.dumps({'section': 'card_insight', 'index': i, 'content': content})}\n\n"

                    # Include extra insights
                    extra = {
                        "spirit_animal": insights.get("jungian", {}).get("archetype"),
                        "chakra": insights.get("chakra"),
                        "element": insights.get("astrology", {}).get("element")
                    }

                    yield f"data: {json.dumps({'section': 'card_insight', 'index': i, 'status': 'done', 'full_text': card_text, 'extras': extra})}\n\n"

                # === SECTION 3: Guidance (streaming) ===
                yield f"data: {json.dumps({'section': 'guidance', 'status': 'start'})}\n\n"

                guidance_prompt = f"""ë‹¹ì‹ ì€ íƒ€ë¡œ ë¦¬ë”ì…ë‹ˆë‹¤. ì´ ë¦¬ë”©ì—ì„œ ë„ì¶œëœ ì‹¤ì§ˆì ì¸ ì¡°ì–¸ì„ ì „ë‹¬í•˜ì„¸ìš”.

ì¹´ë“œ: {cards_str}
ì „ì²´ ë©”ì‹œì§€: {overall_text[:500]}

ì¢‹ì€ ì˜ˆì‹œ: "ì „ì°¨ì˜ ë‘ ìŠ¤í•‘í¬ìŠ¤ê°€ ë‹¤ë¥¸ ë°©í–¥ìœ¼ë¡œ ë‹¹ê¸°ê³  ìˆë‹¤â€”ìƒë°˜ëœ í˜ì„ ì¡°ìœ¨í•´ì•¼ í•  ë•Œë‹¤. ì–´ëŠ í•œìª½ë§Œ ì„ íƒí•˜ì§€ ë§ê³ , ë‘˜ ë‹¤ ëŒê³  ê°€ë¼."
í”¼í•  ê²ƒ: "ìì‹ ê°ì„ ê°€ì§€ì‹œë©´ ì¢‹ê² ìŠµë‹ˆë‹¤. ì¢‹ì€ ê²°ê³¼ê°€ ìˆì„ ê±°ì˜ˆìš”."

ì¡°ì–¸ ë°©í–¥:
- ì¹´ë“œ ìƒì§•ì—ì„œ ì§ì ‘ ë„ì¶œëœ êµ¬ì²´ì  í–‰ë™
- 2-3ë¬¸ì¥ìœ¼ë¡œ ëª…í™•í•˜ê²Œ"""

                guidance_stream = openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[{"role": "user", "content": guidance_prompt}],
                    temperature=0.8,
                    max_tokens=200,
                    stream=True
                )

                guidance_text = ""
                for chunk in guidance_stream:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        guidance_text += content
                        yield f"data: {json.dumps({'section': 'guidance', 'content': content})}\n\n"

                yield f"data: {json.dumps({'section': 'guidance', 'status': 'done', 'full_text': guidance_text})}\n\n"

                # === SECTION 4: Followup Questions ===
                followup = hybrid_rag.advanced_rules.get_followup_questions(category, "neutral") if hasattr(hybrid_rag, 'advanced_rules') else []
                yield f"data: {json.dumps({'section': 'followup', 'questions': followup[:5]})}\n\n"

                # === DONE ===
                yield f"data: {json.dumps({'done': True})}\n\n"

            except Exception as stream_error:
                logger.exception(f"[TAROT_STREAM] Error: {stream_error}")
                yield f"data: {json.dumps({'error': str(stream_error)})}\n\n"

        return Response(
            generate_stream(),
            mimetype='text/event-stream',
            headers={
                'Cache-Control': 'no-cache',
                'Connection': 'keep-alive',
                'X-Accel-Buffering': 'no'
            }
        )

    except Exception as e:
        logger.exception(f"[ERROR] /api/tarot/interpret-stream failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/api/tarot/chat", methods=["POST"])
def tarot_chat():
    """
    Tarot chat consultation - follow-up questions about a reading.
    """
    if not HAS_TAROT:
        return jsonify({"status": "error", "message": "Tarot module not available"}), 501

    try:
        data = request.get_json(force=True)
        logger.info(f"[TAROT_CHAT] id={g.request_id} Processing chat message")

        messages = data.get("messages", [])
        context = data.get("context", {})
        language = data.get("language", "ko")

        if not messages:
            return jsonify({"status": "error", "message": "No messages provided"}), 400

        start_time = time.time()
        hybrid_rag = get_tarot_hybrid_rag()

        # Get Jung psychological insights for tarot
        jung_insight = ""
        if HAS_CORPUS_RAG:
            try:
                corpus_rag = get_corpus_rag()
                last_msg = messages[-1].get("content", "") if messages else ""
                # Search for relevant Jung quotes based on user's question + card context
                card_names = [c.get('name', '') for c in context.get("cards", [])]
                jung_query = f"{last_msg} {' '.join(card_names[:3])}"
                jung_quotes = corpus_rag.search(jung_query, top_k=2, min_score=0.2)
                if jung_quotes:
                    jung_insight = "\n".join([f"â€¢ \"{q['quote'][:150]}...\" - ì¹¼ ìœµ" for q in jung_quotes[:2]])
            except Exception as jung_e:
                logger.debug(f"[TAROT_CHAT] Jung RAG failed: {jung_e}")

        # Build context string from reading
        spread_title = context.get("spread_title", "")
        cards = context.get("cards", [])
        overall_message = context.get("overall_message", "")
        guidance = context.get("guidance", "")

        # Build detailed cards info with position, name, meaning
        cards_details = []
        for c in cards:
            name = c.get('name', '')
            is_reversed = c.get('is_reversed', False)
            position = c.get('position', '')
            meaning = c.get('meaning', '')
            keywords = c.get('keywords', [])
            keywords_str = ', '.join(keywords[:3]) if keywords else ''

            card_info = f"- {position}: {name}{'(ì—­ë°©í–¥)' if is_reversed else ''}"
            if keywords_str:
                card_info += f" [{keywords_str}]"
            if meaning:
                card_info += f" - {meaning[:150]}"
            cards_details.append(card_info)

        cards_detail_str = "\n".join(cards_details) if cards_details else "ì¹´ë“œ ì •ë³´ ì—†ìŒ"

        # Simple comma list for reference
        cards_str = ", ".join([
            f"{c.get('name', '')}{'(ì—­ë°©í–¥)' if c.get('is_reversed') else ''}"
            for c in cards
        ])

        # Build conversation for Gemini
        conversation_history = []
        for msg in messages:
            role = msg.get("role", "user")
            content = msg.get("content", "")
            conversation_history.append(f"{'ì‚¬ìš©ì' if role == 'user' else 'AI'}: {content}")

        last_user_message = messages[-1].get("content", "") if messages else ""

        # Check for specific intents
        wants_more_cards = any(kw in last_user_message.lower() for kw in ["ë” ë½‘", "ì¶”ê°€", "more card", "draw more"])
        asks_about_timing = any(kw in last_user_message.lower() for kw in ["ì–¸ì œ", "ì‹œê¸°", "when", "timing"])

        # Current date for contextual responses
        now = datetime.now()
        is_korean = language == "ko"
        weekday_names_ko = ["ì›”ìš”ì¼", "í™”ìš”ì¼", "ìˆ˜ìš”ì¼", "ëª©ìš”ì¼", "ê¸ˆìš”ì¼", "í† ìš”ì¼", "ì¼ìš”ì¼"]
        if is_korean:
            date_str = f"{now.year}ë…„ {now.month}ì›” {now.day}ì¼ ({weekday_names_ko[now.weekday()]})"
        else:
            date_str = now.strftime("%B %d, %Y (%A)")

        # Generate response using GPT-4o-mini for fast, counselor-like responses
        chat_prompt = f"""ë‹¹ì‹ ì€ ê²½í—˜ ë§ì€ íƒ€ë¡œ ë¦¬ë”ì…ë‹ˆë‹¤. ì¹´ë“œì˜ ìƒì§•ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ì§ì ‘ì ì´ê³  ì‹¤ì§ˆì ì¸ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.

## ì˜¤ëŠ˜: {date_str}

## ë¦¬ë”© ì •ë³´
ìŠ¤í”„ë ˆë“œ: {spread_title}
í•µì‹¬ ë©”ì‹œì§€: {overall_message[:300] if overall_message else '(ì—†ìŒ)'}

## ì¹´ë“œ ìƒì„¸
{cards_detail_str}

## ê°€ì´ë“œ
{guidance if guidance else '(ì—†ìŒ)'}

## ëŒ€í™”
{chr(10).join(conversation_history[-6:])}

## ì§ˆë¬¸
{last_user_message}

{'ğŸ’¡ í˜„ì¬ ì¹´ë“œë“¤ì´ ì´ë¯¸ ì¶©ë¶„í•œ ë©”ì‹œì§€ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. ì´ ë¦¬ë”©ì—ì„œ ë” ê¹Šì´ ë“¤ì—¬ë‹¤ë³¼ ë¶€ë¶„ì´ ìˆë‹¤ë©´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.' if wants_more_cards else ''}
{'â° ì‹œê¸°ì— ëŒ€í•œ ì§ˆë¬¸ì´ë„¤ìš”. ì¹´ë“œì˜ íë¦„ì—ì„œ ì½íˆëŠ” íƒ€ì´ë°ì„ ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.' if asks_about_timing else ''}

{'## ì‹¬ë¦¬í•™ì  í†µì°°' + chr(10) + jung_insight if jung_insight else ''}

## ì¢‹ì€ ë‹µë³€ ì˜ˆì‹œ
"ì£½ìŒ ì¹´ë“œê°€ ë‚˜ì™”ë‹¤ê³  í–ˆëŠ”ë°, ì‹¤ì œ ì£½ìŒì´ ì•„ë‹ˆë¼ ë³€í˜ì´ë‹¤. ì°½ë°±í•œ ê¸°ìˆ˜ê°€ ì§€ë‚˜ê°€ë©´ ì™•ë„ ì“°ëŸ¬ì§„ë‹¤â€”ì§€ìœ„ì™€ ìƒê´€ì—†ì´ ë³€í™”ëŠ” ì˜¨ë‹¤. ì§€ê¸ˆ ëë‚´ì•¼ í•  ê²Œ ë­”ì§€ ì´ë¯¸ ì•Œê³  ìˆì„ ê²ƒì´ë‹¤."

## í”¼í•´ì•¼ í•  ë‹µë³€
"ê±±ì •í•˜ì§€ ë§ˆì„¸ìš”. ì¢‹ì€ ë°©í–¥ìœ¼ë¡œ í˜ëŸ¬ê°ˆ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ê¸ì •ì ì¸ ë§ˆìŒì„ ê°€ì§€ì‹œë©´ ì¢‹ê² ì–´ìš”."

## ë‹µë³€ ë°©í–¥
- ì§ˆë¬¸ì— ì§ì ‘ ì—°ê²°ëœ ì¹´ë“œ ìƒì§• ì–¸ê¸‰
- êµ¬ì²´ì ì¸ ì´ë¯¸ì§€ ë¬˜ì‚¬
- 3-4ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ"""

        try:
            # GPT-4o-mini for fast, natural counselor responses (skip refine for speed)
            reply = _generate_with_gpt4(chat_prompt, max_tokens=400, temperature=0.8, use_mini=True)
            # Apply post-processing to remove AI-sounding phrases
            reply = _clean_ai_phrases(reply)
        except Exception as llm_e:
            logger.warning(f"[TAROT_CHAT] GPT-4 failed: {llm_e}")
            reply = f"í˜„ì¬ ë¦¬ë”©ì—ì„œ {cards_str}ì´(ê°€) ë‚˜ì™”ìŠµë‹ˆë‹¤. {guidance}"

        duration_ms = int((time.time() - start_time) * 1000)
        logger.info(f"[TAROT_CHAT] id={g.request_id} completed in {duration_ms}ms")

        return jsonify({
            "reply": reply,
            "performance": {"duration_ms": duration_ms}
        })

    except Exception as e:
        logger.exception(f"[ERROR] /api/tarot/chat failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/api/tarot/chat-stream", methods=["POST"])
def tarot_chat_stream():
    """
    Streaming tarot chat consultation - real-time response using GPT-4o-mini.
    Returns Server-Sent Events (SSE) for real-time text streaming.
    """
    if not HAS_TAROT:
        return jsonify({"status": "error", "message": "Tarot module not available"}), 501

    try:
        data = request.get_json(force=True)
        logger.info(f"[TAROT_CHAT_STREAM] id={g.request_id} Processing streaming chat")

        messages = data.get("messages", [])
        context = data.get("context", {})
        language = data.get("language", "ko")

        if not messages:
            return jsonify({"status": "error", "message": "No messages provided"}), 400

        # Build context (same as non-streaming)
        spread_title = context.get("spread_title", "")
        cards = context.get("cards", [])
        overall_message = context.get("overall_message", "")
        guidance = context.get("guidance", "")

        cards_details = []
        for c in cards:
            name = c.get('name', '')
            is_reversed = c.get('is_reversed', False)
            position = c.get('position', '')
            meaning = c.get('meaning', '')
            keywords = c.get('keywords', [])
            keywords_str = ', '.join(keywords[:3]) if keywords else ''
            card_info = f"- {position}: {name}{'(ì—­ë°©í–¥)' if is_reversed else ''}"
            if keywords_str:
                card_info += f" [{keywords_str}]"
            if meaning:
                card_info += f" - {meaning[:150]}"
            cards_details.append(card_info)

        cards_detail_str = "\n".join(cards_details) if cards_details else "ì¹´ë“œ ì •ë³´ ì—†ìŒ"

        conversation_history = []
        for msg in messages:
            role = msg.get("role", "user")
            content = msg.get("content", "")
            conversation_history.append(f"{'ì‚¬ìš©ì' if role == 'user' else 'AI'}: {content}")

        last_user_message = messages[-1].get("content", "") if messages else ""

        now = datetime.now()
        is_korean = language == "ko"
        weekday_names_ko = ["ì›”ìš”ì¼", "í™”ìš”ì¼", "ìˆ˜ìš”ì¼", "ëª©ìš”ì¼", "ê¸ˆìš”ì¼", "í† ìš”ì¼", "ì¼ìš”ì¼"]
        if is_korean:
            date_str = f"{now.year}ë…„ {now.month}ì›” {now.day}ì¼ ({weekday_names_ko[now.weekday()]})"
        else:
            date_str = now.strftime("%B %d, %Y (%A)")

        chat_prompt = f"""## ì˜¤ëŠ˜: {date_str}

## ë¦¬ë”© ì •ë³´
ìŠ¤í”„ë ˆë“œ: {spread_title}
í•µì‹¬ ë©”ì‹œì§€: {overall_message[:300] if overall_message else '(ì—†ìŒ)'}

## ì¹´ë“œ ìƒì„¸
{cards_detail_str}

## ê°€ì´ë“œ
{guidance if guidance else '(ì—†ìŒ)'}

## ëŒ€í™”
{chr(10).join(conversation_history[-6:])}

## ì§ˆë¬¸
{last_user_message}"""

        system_prompt = """ë‹¹ì‹ ì€ ê²½í—˜ ë§ì€ íƒ€ë¡œ ë¦¬ë”ì…ë‹ˆë‹¤. ì¹´ë“œì˜ ìƒì§•ê³¼ ì´ë¯¸ì§€ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.

ì¢‹ì€ ì˜ˆì‹œ: "í˜ ì¹´ë“œì—ì„œ ì—¬ì¸ì´ ì‚¬ìì˜ ì…ì„ ë‹«ëŠ”ë‹¤â€”ì–µì§€ë¡œ ë°€ì–´ë¶™ì´ëŠ” ê²Œ ì•„ë‹ˆë¼ ë¶€ë“œëŸ½ê²Œ. ì§€ê¸ˆ ìƒí™©ë„ ë§ˆì°¬ê°€ì§€ë‹¤. í˜ìœ¼ë¡œ í•´ê²°í•˜ë ¤ í•˜ì§€ ë§ˆë¼."
í”¼í•  ê²ƒ: "í˜ ì¹´ë“œê°€ ë‚˜ì™”ë„¤ìš”. ë‚´ë©´ì˜ í˜ì„ ë¯¿ìœ¼ì‹œë©´ ì¢‹ê² ìŠµë‹ˆë‹¤. ì˜ ë  ê±°ì˜ˆìš”."

ë‹µë³€ ìŠ¤íƒ€ì¼:
- ì¹´ë“œ ê·¸ë¦¼ì˜ êµ¬ì²´ì  ìƒì§• ì–¸ê¸‰
- ì§ˆë¬¸ê³¼ ì§ì ‘ ì—°ê²°
- 3-4ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ"""

        def generate_stream():
            """Generator for SSE streaming"""
            try:
                # Use GPT-4o-mini with streaming for fast response
                if not OPENAI_AVAILABLE or not openai_client:
                    yield f"data: {json.dumps({'error': 'OpenAI not available'})}\n\n"
                    return

                stream = openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": chat_prompt}
                    ],
                    temperature=0.8,
                    max_tokens=400,
                    stream=True
                )

                for chunk in stream:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        # Send each chunk as SSE data
                        yield f"data: {json.dumps({'content': content})}\n\n"

                # Send completion signal
                yield f"data: {json.dumps({'done': True})}\n\n"

            except Exception as stream_error:
                logger.exception(f"[TAROT_CHAT_STREAM] Streaming error: {stream_error}")
                yield f"data: {json.dumps({'error': str(stream_error)})}\n\n"

        return Response(
            generate_stream(),
            mimetype='text/event-stream',
            headers={
                'Cache-Control': 'no-cache',
                'Connection': 'keep-alive',
                'X-Accel-Buffering': 'no'
            }
        )

    except Exception as e:
        logger.exception(f"[ERROR] /api/tarot/chat-stream failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/api/tarot/themes", methods=["GET"])
def tarot_themes():
    """Get available tarot themes and spreads."""
    if not HAS_TAROT:
        return jsonify({"status": "error", "message": "Tarot module not available"}), 501

    try:
        hybrid_rag = get_tarot_hybrid_rag()
        themes = hybrid_rag.get_available_themes()

        result = []
        for theme in themes:
            sub_topics = hybrid_rag.get_sub_topics(theme)
            result.append({
                "id": theme,
                "sub_topics": sub_topics
            })

        return jsonify({
            "status": "success",
            "themes": result
        })

    except Exception as e:
        logger.exception(f"[ERROR] /api/tarot/themes failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/api/tarot/search", methods=["GET"])
def tarot_search():
    """Semantic search across tarot knowledge."""
    if not HAS_TAROT:
        return jsonify({"status": "error", "message": "Tarot module not available"}), 501

    try:
        query = request.args.get("q", "")
        top_k = int(request.args.get("top_k", 5))
        category = request.args.get("category")

        hybrid_rag = get_tarot_hybrid_rag()
        results = hybrid_rag.search_advanced_rules(query, top_k=top_k, category=category)

        return jsonify({
            "status": "success",
            "results": results
        })

    except Exception as e:
        logger.exception(f"[ERROR] /api/tarot/search failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


# ===============================================================
# TAROT TOPIC DETECTION (ì±„íŒ… ê¸°ë°˜ íƒ€ë¡œ ì£¼ì œ ìë™ ê°ì§€)
# ===============================================================

# Sub-topic keyword mappings for each theme
_TAROT_TOPIC_KEYWORDS = {
    "career": {
        "job_search": {
            "keywords": ["ì·¨ì—…", "êµ¬ì§", "ì¼ìë¦¬", "ì§ì¥ êµ¬í•˜", "ì·¨ì§", "ì…ì‚¬", "ì‹ ì…", "ì²« ì§ì¥", "job", "employment"],
            "korean": "ì·¨ì—…ì€ ì–¸ì œ",
            "priority": 10
        },
        "interview": {
            "keywords": ["ë©´ì ‘", "ì¸í„°ë·°", "í•©ê²©", "ë¶ˆí•©ê²©", "ì„œë¥˜", "ì±„ìš©", "interview"],
            "korean": "ë©´ì ‘ ê²°ê³¼",
            "priority": 9
        },
        "job_change": {
            "keywords": ["ì´ì§", "í‡´ì‚¬", "ì§ì¥ ì˜®ê¸°", "íšŒì‚¬ ë°”ê¾¸", "ì „ì§", "ìƒˆ ì§ì¥", "career change"],
            "korean": "ì´ì§í•´ì•¼ í• ê¹Œ",
            "priority": 10
        },
        "promotion": {
            "keywords": ["ìŠ¹ì§„", "ì§„ê¸‰", "ìŠ¹ê¸‰", "ì„ì›", "íŒ€ì¥", "ê³¼ì¥", "ë¶€ì¥", "promotion"],
            "korean": "ìŠ¹ì§„ ê°€ëŠ¥ì„±",
            "priority": 8
        },
        "business": {
            "keywords": ["ì‚¬ì—…", "ì°½ì—…", "ìŠ¤íƒ€íŠ¸ì—…", "ìì˜ì—…", "ê°œì—…", "ì‚¬ì¥", "CEO", "business", "startup"],
            "korean": "ì‚¬ì—… ì‹œì‘/í™•ì¥",
            "priority": 9
        },
        "side_hustle": {
            "keywords": ["ë¶€ì—…", "íˆ¬ì¡", "ì•Œë°”", "ì•„ë¥´ë°”ì´íŠ¸", "ë¶€ìˆ˜ì…", "side job"],
            "korean": "ë¶€ì—…/íˆ¬ì¡",
            "priority": 7
        },
        "career_path": {
            "keywords": ["ì§„ë¡œ", "ì ì„±", "ì–´ë–¤ ì§ì—…", "ë¬´ìŠ¨ ì¼", "ì í•©í•œ ì§ì—…", "ë§ëŠ” ì§ì—…", "career path", "aptitude"],
            "korean": "ë‚˜ì—ê²Œ ë§ëŠ” ì§ì—…",
            "priority": 8
        },
        "workplace": {
            "keywords": ["ì§ì¥ ìƒí™œ", "íšŒì‚¬ ìƒí™œ", "ë™ë£Œ", "ìƒì‚¬", "ì§ì¥ ë‚´", "ì‚¬ë‚´", "workplace"],
            "korean": "ì§ì¥ ë‚´ ê´€ê³„/ìƒí™©",
            "priority": 6
        },
        "salary": {
            "keywords": ["ì—°ë´‰", "ê¸‰ì—¬", "ì›”ê¸‰", "ì„ê¸ˆ", "ëˆ", "ì¸ìƒ", "í˜‘ìƒ", "salary"],
            "korean": "ì—°ë´‰ í˜‘ìƒ/ì¸ìƒ",
            "priority": 7
        },
        "project": {
            "keywords": ["í”„ë¡œì íŠ¸", "ì—…ë¬´", "ê³¼ì œ", "ì¼ ì˜", "ì„±ê³¼", "project"],
            "korean": "í”„ë¡œì íŠ¸ ì„±ê³µ",
            "priority": 6
        }
    },
    "love": {
        "secret_admirer": {
            "keywords": ["ë‚˜ë¥¼ ì¢‹ì•„í•˜ëŠ”", "ë‚  ì¢‹ì•„í•˜ëŠ”", "ê´€ì‹¬ ìˆëŠ” ì‚¬ëŒ", "ëˆ„ê°€ ì¢‹ì•„", "secret admirer"],
            "korean": "ë‚˜ë¥¼ ì¢‹ì•„í•˜ëŠ” ì¸ì—°",
            "priority": 8
        },
        "current_partner": {
            "keywords": ["ì—°ì¸", "ë‚¨ì¹œ", "ì—¬ì¹œ", "ë‚¨ìì¹œêµ¬", "ì—¬ìì¹œêµ¬", "ì• ì¸", "partner"],
            "korean": "ì§€ê¸ˆ ì—°ì¸ì˜ ì†ë§ˆìŒ",
            "priority": 9
        },
        "crush": {
            "keywords": ["ì§ì‚¬ë‘", "ì¢‹ì•„í•˜ëŠ” ì‚¬ëŒ", "ë§ˆìŒì— ë“œëŠ”", "ê³ ë°±", "crush"],
            "korean": "ì§ì‚¬ë‘ ìƒëŒ€ì˜ ë§ˆìŒ",
            "priority": 8
        },
        "reconciliation": {
            "keywords": ["ì¬íšŒ", "ë‹¤ì‹œ ë§Œë‚˜", "í—¤ì–´ì§„", "ì „ ë‚¨ì¹œ", "ì „ ì—¬ì¹œ", "ëŒì•„ì˜¬", "reconciliation", "ex"],
            "korean": "í—¤ì–´ì§„ ì—°ì¸ê³¼ì˜ ì¬íšŒ",
            "priority": 9
        },
        "situationship": {
            "keywords": ["ì¸", "ì¸íƒ€ëŠ”", "ë°€ë‹¹", "ê´€ê³„ ì§„ì „", "situationship"],
            "korean": "ì¸íƒ€ëŠ” ìƒëŒ€",
            "priority": 8
        },
        "marriage": {
            "keywords": ["ê²°í˜¼", "ê²°í˜¼ìš´", "ë°°ìš°ì", "ì‹ ë‘", "ì‹ ë¶€", "í˜¼ì¸", "ì›¨ë”©", "marriage", "wedding"],
            "korean": "ê²°í˜¼ìš´",
            "priority": 10
        },
        "breakup": {
            "keywords": ["ì´ë³„", "í—¤ì–´ì§ˆ", "í—¤ì–´ì ¸ì•¼", "ëë‚´ì•¼", "ê·¸ë§Œ ë§Œë‚˜", "breakup"],
            "korean": "ì´ë³„í•´ì•¼ í• ê¹Œ",
            "priority": 9
        },
        "new_love": {
            "keywords": ["ìƒˆë¡œìš´ ì¸ì—°", "ìƒˆ ì‚¬ë‘", "ì–¸ì œ ì—°ì• ", "ì¸ì—°ì´ ì–¸ì œ", "new love"],
            "korean": "ìƒˆë¡œìš´ ì‚¬ë‘ì€ ì–¸ì œ",
            "priority": 8
        },
        "cheating": {
            "keywords": ["ë°”ëŒ", "ì™¸ë„", "ë¶ˆë¥œ", "ì–‘ë‹¤ë¦¬", "cheating", "affair", "ë°”ëŒí”¼"],
            "korean": "ìƒëŒ€ê°€ ë°”ëŒí”¼ìš°ëŠ”ì§€",
            "priority": 11
        },
        "soulmate": {
            "keywords": ["ì†Œìš¸ë©”ì´íŠ¸", "ìš´ëª…", "ì§„ì •í•œ ì‚¬ë‘", "soulmate", "destiny"],
            "korean": "ì†Œìš¸ë©”ì´íŠ¸ ë¦¬ë”©",
            "priority": 7
        }
    },
    "wealth": {
        "money_luck": {
            "keywords": ["ì¬ë¬¼ìš´", "ê¸ˆì „ìš´", "ëˆ ìš´", "ë¶€ì", "wealth", "money luck"],
            "korean": "ì¬ë¬¼ìš´",
            "priority": 9
        },
        "investment": {
            "keywords": ["íˆ¬ì", "ì£¼ì‹", "ì½”ì¸", "ë¶€ë™ì‚°", "í€ë“œ", "investment", "stock"],
            "korean": "íˆ¬ì ê²°ì •",
            "priority": 9
        },
        "debt": {
            "keywords": ["ë¹š", "ëŒ€ì¶œ", "ë¶€ì±„", "ê°š", "loan", "debt"],
            "korean": "ë¹š/ëŒ€ì¶œ",
            "priority": 8
        },
        "windfall": {
            "keywords": ["ë³µê¶Œ", "ë¡œë˜", "íš¡ì¬", "lottery", "windfall"],
            "korean": "íš¡ì¬ìš´",
            "priority": 7
        }
    },
    "health": {
        "general_health": {
            "keywords": ["ê±´ê°•", "ê±´ê°•ìš´", "ëª¸", "ì•„í”„", "ë³‘", "health"],
            "korean": "ê±´ê°•ìš´",
            "priority": 9
        },
        "mental_health": {
            "keywords": ["ì •ì‹  ê±´ê°•", "ìŠ¤íŠ¸ë ˆìŠ¤", "ìš°ìš¸", "ë¶ˆì•ˆ", "mental health"],
            "korean": "ì •ì‹  ê±´ê°•",
            "priority": 8
        },
        "recovery": {
            "keywords": ["íšŒë³µ", "ì¹˜ë£Œ", "ì™„ì¹˜", "recovery"],
            "korean": "íšŒë³µ",
            "priority": 8
        }
    },
    "family": {
        "parent": {
            "keywords": ["ë¶€ëª¨", "ì—„ë§ˆ", "ì•„ë¹ ", "ì–´ë¨¸ë‹ˆ", "ì•„ë²„ì§€", "parent"],
            "korean": "ë¶€ëª¨ë‹˜ê³¼ì˜ ê´€ê³„",
            "priority": 8
        },
        "children": {
            "keywords": ["ìë…€", "ì•„ì´", "ì•„ë“¤", "ë”¸", "ì„ì‹ ", "children", "pregnancy"],
            "korean": "ìë…€ìš´",
            "priority": 9
        },
        "sibling": {
            "keywords": ["í˜•ì œ", "ìë§¤", "ì˜¤ë¹ ", "ì–¸ë‹ˆ", "ë™ìƒ", "sibling"],
            "korean": "í˜•ì œ/ìë§¤ ê´€ê³„",
            "priority": 7
        }
    },
    "spiritual": {
        "life_purpose": {
            "keywords": ["ì‚¶ì˜ ëª©ì ", "ì¸ìƒì˜ ì˜ë¯¸", "ì™œ ì‚¬ëŠ”", "purpose"],
            "korean": "ì‚¶ì˜ ëª©ì ",
            "priority": 8
        },
        "karma": {
            "keywords": ["ì „ìƒ", "ì¹´ë¥´ë§ˆ", "ì—…", "karma", "past life"],
            "korean": "ì „ìƒ/ì¹´ë¥´ë§ˆ",
            "priority": 7
        },
        "spiritual_growth": {
            "keywords": ["ì˜ì  ì„±ì¥", "ê¹¨ë‹¬ìŒ", "ëª…ìƒ", "spiritual"],
            "korean": "ì˜ì  ì„±ì¥",
            "priority": 7
        }
    },
    "life_path": {
        "general": {
            "keywords": ["ì¸ìƒ", "ì•ìœ¼ë¡œ", "ë¯¸ë˜", "ìš´ì„¸", "ì „ë°˜ì ", "life", "future"],
            "korean": "ì¸ìƒ ì „ë°˜",
            "priority": 5
        },
        "decision": {
            "keywords": ["ê²°ì •", "ì„ íƒ", "ì–´ë–»ê²Œ í•´ì•¼", "ë­˜ í•´ì•¼", "decision"],
            "korean": "ê²°ì •/ì„ íƒ",
            "priority": 6
        }
    }
}

# Cache for spread configurations (loaded once)
_SPREAD_CONFIG_CACHE = {}

def _load_spread_config(theme: str) -> dict:
    """Load and cache spread configuration for a theme."""
    if theme in _SPREAD_CONFIG_CACHE:
        return _SPREAD_CONFIG_CACHE[theme]

    spread_file = os.path.join(
        os.path.dirname(os.path.dirname(__file__)),
        "data", "graph", "rules", "tarot", "spreads",
        f"{theme}_spreads.json"
    )

    try:
        if os.path.exists(spread_file):
            with open(spread_file, "r", encoding="utf-8") as f:
                _SPREAD_CONFIG_CACHE[theme] = json.load(f)
                return _SPREAD_CONFIG_CACHE[theme]
    except Exception as e:
        logger.warning(f"Could not load spread file {spread_file}: {e}")

    return {}


def detect_tarot_topic(text: str) -> dict:
    """
    Analyze chat text and detect the most relevant tarot theme and sub-topic.

    Args:
        text: Chat message or conversation text to analyze

    Returns:
        {
            "theme": "career",
            "sub_topic": "job_search",
            "korean": "ì·¨ì—…ì€ ì–¸ì œ",
            "confidence": 0.85,
            "card_count": 10,
            "matched_keywords": ["ì·¨ì—…", "ì§ì¥"]
        }
    """
    text_lower = text.lower()

    # Collect all matches with scores
    all_matches = []

    # Score each theme and sub-topic
    for theme, sub_topics in _TAROT_TOPIC_KEYWORDS.items():
        for sub_topic_id, sub_topic_data in sub_topics.items():
            matched = []
            for keyword in sub_topic_data["keywords"]:
                if keyword.lower() in text_lower or keyword in text:
                    matched.append(keyword)

            if matched:
                # Calculate raw score (not capped) for comparison
                # - Base priority score (0.1 per priority point)
                # - Keyword matches (0.2 per match)
                # - Specificity bonus: longer keywords are more specific
                priority_score = sub_topic_data["priority"] * 0.1
                match_score = len(matched) * 0.2
                avg_keyword_len = sum(len(k) for k in matched) / len(matched)
                specificity_bonus = min(avg_keyword_len * 0.02, 0.2)

                raw_score = priority_score + match_score + specificity_bonus

                all_matches.append({
                    "theme": theme,
                    "sub_topic": sub_topic_id,
                    "korean": sub_topic_data["korean"],
                    "confidence": round(min(raw_score, 1.0), 2),
                    "_raw_score": raw_score,  # Internal, removed before return
                    "_priority": sub_topic_data["priority"],  # Internal
                    "matched_keywords": matched,
                })

    # Sort by raw_score (desc), then by priority (desc) for tie-breaking
    all_matches.sort(key=lambda x: (x["_raw_score"], x["_priority"]), reverse=True)

    if all_matches:
        best_match = all_matches[0]
        # Remove internal fields
        del best_match["_raw_score"]
        del best_match["_priority"]
    else:
        best_match = {
            "theme": "life_path",
            "sub_topic": "general",
            "korean": "ì¸ìƒ ì „ë°˜",
            "confidence": 0.0,
            "matched_keywords": []
        }

    # Load spread configuration to get card count (cached)
    spread_data = _load_spread_config(best_match["theme"])
    sub_topic_config = spread_data.get("sub_topics", {}).get(best_match["sub_topic"], {})

    best_match["card_count"] = sub_topic_config.get("card_count", 3)
    best_match["spread_name"] = sub_topic_config.get("spread_name", "")
    best_match["positions"] = sub_topic_config.get("positions", [])

    return best_match


@app.route("/api/tarot/detect-topic", methods=["POST"])
def tarot_detect_topic():
    """
    Detect tarot theme and sub-topic from chat conversation.
    Used when user clicks "íƒ€ë¡œ ë¦¬ë”© ë°›ê¸°" from destiny-map counselor chat.

    Request body:
        {
            "messages": [
                {"role": "user", "content": "ì–¸ì œ ì·¨ì—…í•  ìˆ˜ ìˆì„ê¹Œìš”?"},
                {"role": "assistant", "content": "..."}
            ]
        }
        OR
        {
            "text": "ì–¸ì œ ì·¨ì—…í•  ìˆ˜ ìˆì„ê¹Œìš”?"
        }

    Response:
        {
            "status": "success",
            "detected": {
                "theme": "career",
                "sub_topic": "job_search",
                "korean": "ì·¨ì—…ì€ ì–¸ì œ",
                "confidence": 0.85,
                "card_count": 10,
                "spread_name": "Job Search Spread",
                "positions": [...],
                "matched_keywords": ["ì·¨ì—…"]
            }
        }
    """
    try:
        data = request.get_json(force=True)

        # Support both message list and plain text
        if "messages" in data:
            # Combine recent user messages for analysis
            user_messages = [
                m.get("content", "")
                for m in data["messages"]
                if m.get("role") == "user"
            ]
            # Focus on last 3 user messages
            text = " ".join(user_messages[-3:])
        else:
            text = data.get("text", "")

        if not text:
            return jsonify({
                "status": "error",
                "message": "No text provided for analysis"
            }), 400

        detected = detect_tarot_topic(text)

        logger.info(f"[TAROT-DETECT] Detected {detected['theme']}/{detected['sub_topic']} "
                   f"(confidence: {detected['confidence']}) from: {text[:100]}...")

        return jsonify({
            "status": "success",
            "detected": detected
        })

    except Exception as e:
        logger.exception(f"[ERROR] /api/tarot/detect-topic failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


# ===============================================================
# JUNGIAN COUNSELING ENDPOINTS (ì‹¬ë¦¬ìƒë‹´)
# ===============================================================

@app.route("/api/counseling/session", methods=["POST"])
def counseling_session():
    """
    Create or continue a counseling session.
    ìœµ ì‹¬ë¦¬í•™ ê¸°ë°˜ í†µí•© ì‹¬ë¦¬ìƒë‹´ ì„¸ì…˜.
    """
    if not HAS_COUNSELING:
        return jsonify({"status": "error", "message": "Counseling module not available"}), 501

    try:
        data = request.get_json(force=True)
        message = data.get("message", "")
        session_id = data.get("session_id")
        divination_context = data.get("divination_context")  # ì‚¬ì£¼/ì ì„±/íƒ€ë¡œ ì»¨í…ìŠ¤íŠ¸

        if not message:
            return jsonify({"status": "error", "message": "Message is required"}), 400

        engine = get_counseling_engine()

        # ì„¸ì…˜ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
        session = None
        if session_id:
            session = engine.get_session(session_id)

        # ë©”ì‹œì§€ ì²˜ë¦¬
        result = engine.process_message(
            user_message=message,
            session=session,
            divination_context=divination_context
        )

        return jsonify({
            "status": "success",
            "response": result["response"],
            "session_id": result["session_id"],
            "phase": result.get("phase", "opening"),
            "crisis_detected": result.get("crisis_detected", False),
            "severity": result.get("severity"),
            "should_continue": result.get("should_continue", True)
        })

    except Exception as e:
        logger.exception(f"[ERROR] /api/counseling/session failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/api/counseling/crisis-check", methods=["POST"])
def counseling_crisis_check():
    """
    Check text for crisis indicators.
    ìœ„ê¸° ì‹ í˜¸ ê°ì§€ (ìì‚´/ìí•´ ë“±).
    """
    if not HAS_COUNSELING:
        return jsonify({"status": "error", "message": "Counseling module not available"}), 501

    try:
        data = request.get_json(force=True)
        text = data.get("text", "")

        if not text:
            return jsonify({"status": "error", "message": "Text is required"}), 400

        result = CrisisDetector.detect_crisis(text)

        response_data = {
            "status": "success",
            "is_crisis": result["is_crisis"],
            "max_severity": result["max_severity"],
            "requires_immediate_action": result["requires_immediate_action"]
        }

        # ìœ„ê¸° ìƒí™©ì´ë©´ ë¦¬ì†ŒìŠ¤ ì •ë³´ ì¶”ê°€
        if result["is_crisis"]:
            response_data["resources"] = CrisisDetector.EMERGENCY_RESOURCES.get("ko", {})
            response_data["crisis_response"] = CrisisDetector.get_crisis_response(
                result["max_severity"]
            )

        return jsonify(response_data)

    except Exception as e:
        logger.exception(f"[ERROR] /api/counseling/crisis-check failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/api/counseling/therapeutic-question", methods=["GET"])
def counseling_therapeutic_question():
    """
    Get a therapeutic question.
    ì¹˜ë£Œì  ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°.
    """
    if not HAS_COUNSELING:
        return jsonify({"status": "error", "message": "Counseling module not available"}), 501

    try:
        theme = request.args.get("theme")  # love, career, identity, etc.
        archetype = request.args.get("archetype")  # shadow, anima, persona, etc.
        question_type = request.args.get("type", "deepening")  # deepening, challenging, shadow, etc.

        engine = get_counseling_engine()
        question = engine.get_therapeutic_question(
            theme=theme,
            archetype=archetype,
            question_type=question_type
        )

        return jsonify({
            "status": "success",
            "question": question,
            "theme": theme,
            "archetype": archetype,
            "type": question_type
        })

    except Exception as e:
        logger.exception(f"[ERROR] /api/counseling/therapeutic-question failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/api/counseling/emotional-response", methods=["POST"])
def counseling_emotional_response():
    """
    Get an emotional/empathic response.
    ê°ë™ì ì¸ ê³µê° ì‘ë‹µ ìƒì„±.
    """
    if not HAS_COUNSELING:
        return jsonify({"status": "error", "message": "Counseling module not available"}), 501

    try:
        data = request.get_json(force=True)
        emotion = data.get("emotion", "")
        situation = data.get("situation", "")

        if not emotion:
            return jsonify({"status": "error", "message": "Emotion is required"}), 400

        engine = get_counseling_engine()
        response = engine.get_emotional_response(emotion, situation)

        return jsonify({
            "status": "success",
            "responses": response
        })

    except Exception as e:
        logger.exception(f"[ERROR] /api/counseling/emotional-response failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/api/counseling/integrated", methods=["POST"])
def counseling_integrated():
    """
    Integrated counseling with saju/astrology/tarot context.
    ì‚¬ì£¼+ì ì„±+íƒ€ë¡œ í†µí•© ì‹¬ë¦¬ìƒë‹´.
    """
    if not HAS_COUNSELING:
        return jsonify({"status": "error", "message": "Counseling module not available"}), 501

    try:
        data = request.get_json(force=True)
        message = data.get("message", "")
        session_id = data.get("session_id")

        # ì ìˆ  ë°ì´í„°
        saju_data = data.get("saju") or {}
        astro_data = data.get("astro")
        tarot_data = data.get("tarot")

        # Normalize dayMaster structure (nested -> flat)
        saju_data = normalize_day_master(saju_data)

        if not message:
            return jsonify({"status": "error", "message": "Message is required"}), 400

        engine = get_counseling_engine()

        # ì„¸ì…˜ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
        session = None
        if session_id:
            session = engine.get_session(session_id)

        # ì ìˆ  ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        divination_context = {}
        if saju_data:
            divination_context["saju"] = str(saju_data)
        if astro_data:
            divination_context["astrology"] = str(astro_data)
        if tarot_data:
            divination_context["tarot"] = str(tarot_data)

        # ë©”ì‹œì§€ ì²˜ë¦¬
        result = engine.process_message(
            user_message=message,
            session=session,
            divination_context=divination_context if divination_context else None
        )

        return jsonify({
            "status": "success",
            "response": result["response"],
            "session_id": result["session_id"],
            "phase": result.get("phase", "opening"),
            "crisis_detected": result.get("crisis_detected", False),
            "should_continue": result.get("should_continue", True)
        })

    except Exception as e:
        logger.exception(f"[ERROR] /api/counseling/integrated failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


# ===============================================================
# RLHF FEEDBACK LEARNING ENDPOINTS
# ===============================================================

@app.route("/rlhf/stats", methods=["GET"])
def rlhf_stats():
    """Get RLHF feedback statistics."""
    if not HAS_RLHF:
        return jsonify({"status": "error", "message": "RLHF module not available"}), 501

    try:
        fl = get_feedback_learning()
        stats = fl.get_stats()

        return jsonify({
            "status": "success",
            "stats": stats,
        })
    except Exception as e:
        logger.exception(f"[ERROR] /rlhf/stats failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/rlhf/analyze", methods=["GET"])
def rlhf_analyze():
    """Analyze feedback patterns to identify improvement areas."""
    if not HAS_RLHF:
        return jsonify({"status": "error", "message": "RLHF module not available"}), 501

    try:
        theme = request.args.get("theme")
        days = int(request.args.get("days", 30))

        fl = get_feedback_learning()
        analysis = fl.analyze_feedback_patterns(theme=theme, days=days)

        return jsonify({
            "status": "success",
            "analysis": analysis,
        })
    except Exception as e:
        logger.exception(f"[ERROR] /rlhf/analyze failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/rlhf/suggestions", methods=["GET"])
def rlhf_suggestions():
    """Get improvement suggestions based on feedback analysis."""
    if not HAS_RLHF:
        return jsonify({"status": "error", "message": "RLHF module not available"}), 501

    try:
        fl = get_feedback_learning()
        suggestions = fl.get_improvement_suggestions()

        return jsonify({
            "status": "success",
            "suggestions": suggestions,
        })
    except Exception as e:
        logger.exception(f"[ERROR] /rlhf/suggestions failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/rlhf/fewshot", methods=["GET"])
def rlhf_fewshot():
    """Get Few-shot examples for a theme."""
    if not HAS_RLHF:
        return jsonify({"status": "error", "message": "RLHF module not available"}), 501

    try:
        theme = request.args.get("theme", "life_path")
        locale = request.args.get("locale", "ko")
        top_k = int(request.args.get("top_k", 3))

        fl = get_feedback_learning()
        examples = fl.get_fewshot_examples(theme, locale, top_k)
        formatted = fl.format_fewshot_prompt(theme, locale, top_k)

        return jsonify({
            "status": "success",
            "examples": examples,
            "formatted_prompt": formatted,
        })
    except Exception as e:
        logger.exception(f"[ERROR] /rlhf/fewshot failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/rlhf/export", methods=["GET"])
def rlhf_export():
    """Export training data for fine-tuning."""
    if not HAS_RLHF:
        return jsonify({"status": "error", "message": "RLHF module not available"}), 501

    try:
        min_rating = int(request.args.get("min_rating", 4))
        limit = int(request.args.get("limit", 500))

        fl = get_feedback_learning()
        training_data = fl.export_training_data(min_rating=min_rating, limit=limit)

        return jsonify({
            "status": "success",
            "count": len(training_data),
            "training_data": training_data,
        })
    except Exception as e:
        logger.exception(f"[ERROR] /rlhf/export failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/rlhf/feedback", methods=["POST"])
def rlhf_record_feedback():
    """
    Record feedback directly to RLHF system with full consultation context.

    This is the enhanced version of /memory/feedback that captures
    more context for learning.
    """
    if not HAS_RLHF:
        return jsonify({"status": "error", "message": "RLHF module not available"}), 501

    try:
        data = request.get_json(force=True)

        record_id = data.get("record_id", "")
        user_id = data.get("user_id", "anonymous")
        rating = data.get("rating")
        feedback_text = data.get("feedback", "")

        # Full consultation context for learning
        consultation_data = {
            "theme": data.get("theme", "unknown"),
            "locale": data.get("locale", "ko"),
            "service_type": data.get("service_type", "fusion"),
            "summary": data.get("summary", ""),
            "key_insights": data.get("key_insights", []),
            "prompt": data.get("user_question", ""),
            "context": data.get("context", ""),
        }

        if not record_id or rating is None:
            return jsonify({
                "status": "error",
                "message": "record_id and rating are required"
            }), 400

        fl = get_feedback_learning()
        result = fl.record_feedback(
            record_id=record_id,
            user_id=user_id,
            rating=rating,
            feedback_text=feedback_text,
            consultation_data=consultation_data,
        )

        # Handle return value (may include badges)
        if isinstance(result, tuple):
            feedback_id, new_badges = result
        else:
            feedback_id = result
            new_badges = []

        # Also update rule weights if rules were used
        rules_used = data.get("rules_used", [])
        if rules_used and rating:
            fl.adjust_rule_weights(
                theme=consultation_data["theme"],
                rules_used=rules_used,
                rating=rating,
            )

        logger.info(f"[RLHF] Recorded feedback {feedback_id}: rating={rating}, theme={consultation_data['theme']}")

        # Build response with badge info
        response = {
            "status": "success",
            "feedback_id": feedback_id,
            "message": "Feedback recorded for RLHF learning",
        }

        # Include new badges if any were earned
        if new_badges:
            locale = data.get("locale", "ko")
            response["new_badges"] = [
                {
                    "id": b.id,
                    "name": b.name_ko if locale == "ko" else b.name_en,
                    "description": b.description_ko if locale == "ko" else b.description_en,
                    "rarity": b.rarity.value,
                    "image_path": b.image_path,
                    "points": b.points,
                }
                for b in new_badges
            ]
            response["badges_earned_count"] = len(new_badges)

        return jsonify(response)
    except Exception as e:
        logger.exception(f"[ERROR] /rlhf/feedback failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/rlhf/weights", methods=["GET"])
def rlhf_weights():
    """Get adjusted rule weights for a theme."""
    if not HAS_RLHF:
        return jsonify({"status": "error", "message": "RLHF module not available"}), 501

    try:
        theme = request.args.get("theme")

        fl = get_feedback_learning()
        weights = fl.get_rule_weights(theme)

        return jsonify({
            "status": "success",
            "theme": theme,
            "weights": weights,
        })
    except Exception as e:
        logger.exception(f"[ERROR] /rlhf/weights failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/rlhf/analytics", methods=["GET"])
def rlhf_analytics():
    """
    Get feedback analytics for counseling quality improvement.
    ìƒë‹´ í’ˆì§ˆ ê°œì„ ì„ ìœ„í•œ í”¼ë“œë°± ë¶„ì„ í†µê³„.

    Query params:
    - days: Number of days to analyze (default: 30)
    - theme: Filter by theme (optional)
    """
    if not HAS_RLHF:
        return jsonify({"status": "error", "message": "RLHF module not available"}), 501

    try:
        days = request.args.get("days", 30, type=int)
        theme_filter = request.args.get("theme")

        fl = get_feedback_learning()

        # Get feedback data
        from datetime import datetime, timedelta
        cutoff_date = datetime.now() - timedelta(days=days)

        # Aggregate statistics
        stats = {
            "total_feedbacks": 0,
            "average_rating": 0.0,
            "rating_distribution": {1: 0, 2: 0, 3: 0, 4: 0, 5: 0},
            "theme_breakdown": {},
            "top_positive_themes": [],
            "needs_improvement_themes": [],
            "common_feedback_keywords": [],
            "trend": "stable",
        }

        # Access feedback storage (if available)
        if hasattr(fl, '_feedback_storage') and fl._feedback_storage:
            feedbacks = fl._feedback_storage
            filtered = []

            for fb in feedbacks:
                if isinstance(fb, dict):
                    fb_date = fb.get("timestamp")
                    fb_theme = fb.get("theme", "unknown")

                    # Apply filters
                    if theme_filter and fb_theme != theme_filter:
                        continue

                    if fb_date and isinstance(fb_date, str):
                        try:
                            fb_datetime = datetime.fromisoformat(fb_date.replace("Z", "+00:00"))
                            if fb_datetime < cutoff_date:
                                continue
                        except:
                            pass

                    filtered.append(fb)

            stats["total_feedbacks"] = len(filtered)

            if filtered:
                # Calculate average rating
                ratings = [fb.get("rating", 3) for fb in filtered if fb.get("rating")]
                if ratings:
                    stats["average_rating"] = round(sum(ratings) / len(ratings), 2)

                    # Rating distribution
                    for r in ratings:
                        if 1 <= r <= 5:
                            stats["rating_distribution"][r] += 1

                # Theme breakdown
                theme_ratings = {}
                for fb in filtered:
                    t = fb.get("theme", "unknown")
                    r = fb.get("rating", 3)
                    if t not in theme_ratings:
                        theme_ratings[t] = []
                    theme_ratings[t].append(r)

                for t, rs in theme_ratings.items():
                    avg = round(sum(rs) / len(rs), 2) if rs else 0
                    stats["theme_breakdown"][t] = {
                        "count": len(rs),
                        "average_rating": avg,
                    }

                # Top positive and needs improvement
                sorted_themes = sorted(
                    [(t, d["average_rating"], d["count"]) for t, d in stats["theme_breakdown"].items()],
                    key=lambda x: (-x[1], -x[2])
                )

                stats["top_positive_themes"] = [
                    {"theme": t, "avg_rating": r, "count": c}
                    for t, r, c in sorted_themes[:3] if r >= 4.0
                ]

                stats["needs_improvement_themes"] = [
                    {"theme": t, "avg_rating": r, "count": c}
                    for t, r, c in reversed(sorted_themes) if r < 3.5
                ][:3]

                # Extract common keywords from negative feedback
                negative_texts = [
                    fb.get("feedback_text", "")
                    for fb in filtered
                    if fb.get("rating", 5) <= 2 and fb.get("feedback_text")
                ]

                keyword_counts = {}
                negative_keywords = ["ì• ë§¤", "ë¶€ì •í™•", "ì¼ë°˜ì ", "ë„ì›€", "ì•ˆ ë¨", "ë³„ë¡œ", "ì•„ì‰¬", "ì§§", "êµ¬ì²´"]
                for text in negative_texts:
                    text_lower = text.lower()
                    for kw in negative_keywords:
                        if kw in text_lower:
                            keyword_counts[kw] = keyword_counts.get(kw, 0) + 1

                stats["common_feedback_keywords"] = [
                    {"keyword": k, "count": c}
                    for k, c in sorted(keyword_counts.items(), key=lambda x: -x[1])[:5]
                ]

                # Calculate trend (compare first half vs second half)
                mid = len(ratings) // 2
                if mid > 5:
                    first_half_avg = sum(ratings[:mid]) / mid
                    second_half_avg = sum(ratings[mid:]) / (len(ratings) - mid)
                    diff = second_half_avg - first_half_avg
                    if diff > 0.3:
                        stats["trend"] = "improving"
                    elif diff < -0.3:
                        stats["trend"] = "declining"
                    else:
                        stats["trend"] = "stable"

        # Quality insights
        insights = []
        if stats["average_rating"] < 3.5:
            insights.append("ì „ë°˜ì ì¸ ë§Œì¡±ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ìƒë‹´ ì‘ë‹µ í’ˆì§ˆ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        elif stats["average_rating"] >= 4.5:
            insights.append("ë§¤ìš° ë†’ì€ ë§Œì¡±ë„ë¥¼ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤!")

        if stats["needs_improvement_themes"]:
            themes_str = ", ".join([t["theme"] for t in stats["needs_improvement_themes"]])
            insights.append(f"ê°œì„ ì´ í•„ìš”í•œ í…Œë§ˆ: {themes_str}")

        if stats["common_feedback_keywords"]:
            kws = ", ".join([k["keyword"] for k in stats["common_feedback_keywords"][:3]])
            insights.append(f"ë¶€ì •ì  í”¼ë“œë°±ì—ì„œ ìì£¼ ë“±ì¥í•˜ëŠ” í‚¤ì›Œë“œ: {kws}")

        stats["insights"] = insights

        return jsonify({
            "status": "success",
            "period_days": days,
            "theme_filter": theme_filter,
            **stats
        })

    except Exception as e:
        logger.exception(f"[ERROR] /rlhf/analytics failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


# ===============================================================
# BADGE SYSTEM ENDPOINTS
# ===============================================================

@app.route("/badges/all", methods=["GET"])
def badges_all():
    """Get all available badges."""
    if not HAS_BADGES:
        return jsonify({"status": "error", "message": "Badge system not available"}), 501

    try:
        locale = request.args.get("locale", "ko")
        badge_system = get_badge_system()
        badges = badge_system.get_all_badges(locale)

        return jsonify({
            "status": "success",
            "badges": badges,
            "total": len(badges),
        })
    except Exception as e:
        logger.exception(f"[ERROR] /badges/all failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/badges/user", methods=["POST"])
def badges_user():
    """Get user's badge summary."""
    if not HAS_BADGES:
        return jsonify({"status": "error", "message": "Badge system not available"}), 501

    try:
        data = request.get_json(force=True)
        user_id = data.get("user_id", "")
        locale = data.get("locale", "ko")

        # Can also generate user_id from birth data
        if not user_id and data.get("birth"):
            from backend_ai.app.user_memory import generate_user_id
            user_id = generate_user_id(data["birth"])

        if not user_id:
            return jsonify({"status": "error", "message": "user_id or birth data required"}), 400

        badge_system = get_badge_system()
        summary = badge_system.get_user_badge_summary(user_id, locale)

        return jsonify({
            "status": "success",
            **summary,
        })
    except Exception as e:
        logger.exception(f"[ERROR] /badges/user failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/badges/midjourney-prompts", methods=["GET"])
def badges_midjourney():
    """Get Midjourney prompts for badge images."""
    if not HAS_BADGES:
        return jsonify({"status": "error", "message": "Badge system not available"}), 501

    try:
        prompts = get_midjourney_prompts()

        return jsonify({
            "status": "success",
            "prompts": prompts,
            "count": len(prompts),
            "usage": "Copy each prompt to Midjourney to generate badge images. Save as /public/badges/{badge_id}.png",
        })
    except Exception as e:
        logger.exception(f"[ERROR] /badges/midjourney-prompts failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


# ===============================================================
# AGENTIC RAG ENDPOINTS (Next Level Features)
# ===============================================================

@app.route("/agentic/query", methods=["POST"])
def agentic_rag_query():
    """
    Execute agentic RAG query with all next-level features:
    - Entity Extraction (NER)
    - Deep Graph Traversal (Multi-hop)
    - Agentic Workflow (LangGraph-style)

    Request body:
    {
        "query": "ëª©ì„±ì´ ì‚¬ìˆ˜ìë¦¬ì— ìˆì„ ë•Œ 9í•˜ìš°ìŠ¤ì˜ ì˜í–¥ì€?",
        "facts": {...},  // Optional: Saju/Astro facts
        "locale": "ko",
        "theme": "life_path"
    }
    """
    if not HAS_AGENTIC:
        return jsonify({"status": "error", "message": "Agentic RAG module not available"}), 501

    try:
        data = request.get_json(force=True)

        query = data.get("query", "")
        facts = data.get("facts", {})
        locale = data.get("locale", "ko")
        theme = data.get("theme", "life_path")

        if not query:
            return jsonify({"status": "error", "message": "query is required"}), 400

        result = agentic_query(
            query=query,
            facts=facts,
            locale=locale,
            theme=theme,
        )

        return jsonify(result)

    except Exception as e:
        logger.exception(f"[ERROR] /agentic/query failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/agentic/extract-entities", methods=["POST"])
def agentic_extract_entities():
    """
    Extract entities from text using NER.

    Request body:
    {
        "text": "Jupiter in Sagittarius in the 9th house"
    }
    """
    if not HAS_AGENTIC:
        return jsonify({"status": "error", "message": "Agentic RAG module not available"}), 501

    try:
        data = request.get_json(force=True)
        text = data.get("text", "")

        if not text:
            return jsonify({"status": "error", "message": "text is required"}), 400

        extractor = get_entity_extractor()
        entities = extractor.extract(text)
        relations = extractor.extract_relations(text)

        return jsonify({
            "status": "success",
            "entities": [
                {
                    "text": e.text,
                    "type": e.type.value,
                    "normalized": e.normalized,
                    "confidence": e.confidence,
                }
                for e in entities
            ],
            "relations": [
                {
                    "source": r[0].normalized,
                    "relation": r[1],
                    "target": r[2].normalized,
                }
                for r in relations
            ],
            "stats": {
                "entities_count": len(entities),
                "relations_count": len(relations),
                "entity_types": list(set(e.type.value for e in entities)),
            },
        })

    except Exception as e:
        logger.exception(f"[ERROR] /agentic/extract-entities failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/agentic/deep-traverse", methods=["POST"])
def agentic_deep_traverse():
    """
    Perform multi-hop graph traversal.

    Request body:
    {
        "start_entities": ["Jupiter", "Sagittarius"],
        "max_depth": 3,
        "max_paths": 5
    }
    """
    if not HAS_AGENTIC:
        return jsonify({"status": "error", "message": "Agentic RAG module not available"}), 501

    try:
        data = request.get_json(force=True)

        start_entities = data.get("start_entities", [])
        max_depth = data.get("max_depth", 3)
        max_paths = data.get("max_paths", 10)

        if not start_entities:
            return jsonify({"status": "error", "message": "start_entities is required"}), 400

        traversal = get_deep_traversal()
        if not traversal:
            return jsonify({"status": "error", "message": "Graph not available for traversal"}), 501

        paths = traversal.traverse(
            start_entities=start_entities,
            max_depth=max_depth,
            max_paths=max_paths,
        )

        return jsonify({
            "status": "success",
            "paths": [
                {
                    "nodes": p.nodes,
                    "edges": p.edges,
                    "context": p.context,
                    "weight": p.total_weight,
                }
                for p in paths
            ],
            "stats": {
                "paths_count": len(paths),
                "max_path_length": max(len(p.nodes) for p in paths) if paths else 0,
                "start_entities": start_entities,
            },
        })

    except Exception as e:
        logger.exception(f"[ERROR] /agentic/deep-traverse failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/agentic/find-connections", methods=["POST"])
def agentic_find_connections():
    """
    Find all paths connecting two entities.

    Example: Find how Jupiter connects to Philosophy
    Jupiter â†’ Sagittarius â†’ 9th House â†’ Philosophy

    Request body:
    {
        "entity1": "Jupiter",
        "entity2": "Philosophy",
        "max_depth": 4
    }
    """
    if not HAS_AGENTIC:
        return jsonify({"status": "error", "message": "Agentic RAG module not available"}), 501

    try:
        data = request.get_json(force=True)

        entity1 = data.get("entity1", "")
        entity2 = data.get("entity2", "")
        max_depth = data.get("max_depth", 4)

        if not entity1 or not entity2:
            return jsonify({"status": "error", "message": "entity1 and entity2 are required"}), 400

        traversal = get_deep_traversal()
        if not traversal:
            return jsonify({"status": "error", "message": "Graph not available for traversal"}), 501

        paths = traversal.find_connections(
            entity1=entity1,
            entity2=entity2,
            max_depth=max_depth,
        )

        return jsonify({
            "status": "success",
            "entity1": entity1,
            "entity2": entity2,
            "paths": [
                {
                    "nodes": p.nodes,
                    "edges": p.edges,
                    "context": p.context,
                    "weight": p.total_weight,
                    "path_string": " â†’ ".join(p.nodes),
                }
                for p in paths
            ],
            "connections_found": len(paths),
        })

    except Exception as e:
        logger.exception(f"[ERROR] /agentic/find-connections failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


# ===============================================================
# PREDICTION ENGINE ENDPOINTS (v5.0)
# ëŒ€ìš´/ì„¸ìš´ + íŠ¸ëœì§“ ê¸°ë°˜ ì˜ˆì¸¡ ì‹œìŠ¤í…œ
# ===============================================================

@app.route("/api/prediction/luck", methods=["POST"])
def prediction_luck():
    """
    ëŒ€ìš´/ì„¸ìš´ ê¸°ë°˜ ìš´ì„¸ ì˜ˆì¸¡.
    í–¥í›„ Në…„ê°„ì˜ ìš´ì„¸ íë¦„ ë¶„ì„.
    """
    if not HAS_PREDICTION:
        return jsonify({"status": "error", "message": "Prediction engine not available"}), 501

    try:
        data = request.get_json(force=True)
        birth_info = {
            "year": data.get("year"),
            "month": data.get("month"),
            "day": data.get("day", 15),
            "hour": data.get("hour", 12),
            "gender": data.get("gender", "unknown")
        }
        years_ahead = data.get("years_ahead", 5)

        if not birth_info.get("year") or not birth_info.get("month"):
            return jsonify({"status": "error", "message": "year and month are required"}), 400

        forecasts = predict_luck(birth_info, years_ahead)

        return jsonify({
            "status": "success",
            "birth_info": birth_info,
            "years_ahead": years_ahead,
            "forecasts": forecasts
        })

    except Exception as e:
        logger.exception(f"[ERROR] /api/prediction/luck failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/api/prediction/timing", methods=["POST"])
def prediction_timing():
    """
    'ì–¸ì œê°€ ì¢‹ì„ê¹Œ?' ì§ˆë¬¸ì— ë‹µë³€.
    ìµœì ì˜ ë‚ ì§œ/ì‹œê¸° ì¶”ì²œ.
    """
    if not HAS_PREDICTION:
        return jsonify({"status": "error", "message": "Prediction engine not available"}), 501

    try:
        data = request.get_json(force=True)
        question = data.get("question", "")

        if not question:
            return jsonify({"status": "error", "message": "question is required"}), 400

        # ìƒë…„ì›”ì¼ ì •ë³´ (ì„ íƒ)
        birth_info = None
        if data.get("year") and data.get("month"):
            birth_info = {
                "year": data.get("year"),
                "month": data.get("month"),
                "day": data.get("day", 15),
                "hour": data.get("hour", 12),
                "gender": data.get("gender", "unknown")
            }

        result = find_best_date(question, birth_info)

        return jsonify({
            "status": "success",
            **result
        })

    except Exception as e:
        logger.exception(f"[ERROR] /api/prediction/timing failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/api/prediction/forecast", methods=["POST"])
def prediction_forecast():
    """
    ì¢…í•© ì˜ˆì¸¡ - ëŒ€ìš´/ì„¸ìš´/íŠ¸ëœì§“ í†µí•© ë¶„ì„.
    AI í•´ì„ í¬í•¨.
    """
    if not HAS_PREDICTION:
        return jsonify({"status": "error", "message": "Prediction engine not available"}), 501

    try:
        data = request.get_json(force=True)
        birth_info = {
            "year": data.get("year"),
            "month": data.get("month"),
            "day": data.get("day", 15),
            "hour": data.get("hour", 12),
            "gender": data.get("gender", "unknown")
        }
        question = data.get("question")
        include_timing = data.get("include_timing", True)

        if not birth_info.get("year") or not birth_info.get("month"):
            return jsonify({"status": "error", "message": "year and month are required"}), 400

        result = get_full_forecast(birth_info, question)

        return jsonify({
            "status": "success",
            **result
        })

    except Exception as e:
        logger.exception(f"[ERROR] /api/prediction/forecast failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/api/prediction/daeun", methods=["POST"])
def prediction_daeun():
    """
    í˜„ì¬ ëŒ€ìš´ ìƒì„¸ ì •ë³´.
    """
    if not HAS_PREDICTION:
        return jsonify({"status": "error", "message": "Prediction engine not available"}), 501

    try:
        data = request.get_json(force=True)
        birth_info = {
            "year": data.get("year"),
            "month": data.get("month"),
            "day": data.get("day", 15),
            "hour": data.get("hour", 12),
            "gender": data.get("gender", "unknown")
        }
        target_year = data.get("target_year")

        if not birth_info.get("year") or not birth_info.get("month"):
            return jsonify({"status": "error", "message": "year and month are required"}), 400

        engine = get_prediction_engine()
        daeun = engine.luck_predictor.calculate_daeun(
            birth_info["year"],
            birth_info["month"],
            birth_info["day"],
            birth_info["hour"],
            birth_info["gender"],
            target_year
        )

        return jsonify({
            "status": "success",
            "daeun": {
                "period_type": daeun.period_type,
                "start_year": daeun.start_year,
                "end_year": daeun.end_year,
                "dominant_god": daeun.dominant_god,
                "element": daeun.element,
                "polarity": daeun.polarity,
                "overall_rating": round(daeun.overall_rating, 1),
                "themes": daeun.themes,
                "opportunities": daeun.opportunities,
                "challenges": daeun.challenges
            }
        })

    except Exception as e:
        logger.exception(f"[ERROR] /api/prediction/daeun failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/api/prediction/seun", methods=["POST"])
def prediction_seun():
    """
    íŠ¹ì • ì—°ë„ì˜ ì„¸ìš´ ì •ë³´.
    """
    if not HAS_PREDICTION:
        return jsonify({"status": "error", "message": "Prediction engine not available"}), 501

    try:
        data = request.get_json(force=True)
        birth_year = data.get("year")
        birth_month = data.get("month")
        target_year = data.get("target_year")

        if not birth_year or not birth_month:
            return jsonify({"status": "error", "message": "year and month are required"}), 400

        engine = get_prediction_engine()
        seun = engine.luck_predictor.calculate_seun(
            birth_year,
            birth_month,
            target_year
        )

        return jsonify({
            "status": "success",
            "seun": {
                "period_type": seun.period_type,
                "year": seun.start_year,
                "dominant_god": seun.dominant_god,
                "element": seun.element,
                "polarity": seun.polarity,
                "overall_rating": round(seun.overall_rating, 1),
                "themes": seun.themes,
                "opportunities": seun.opportunities,
                "challenges": seun.challenges
            }
        })

    except Exception as e:
        logger.exception(f"[ERROR] /api/prediction/seun failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/api/prediction/event-types", methods=["GET"])
def prediction_event_types():
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ ì´ë²¤íŠ¸ ìœ í˜• ëª©ë¡.
    """
    if not HAS_PREDICTION:
        return jsonify({"status": "error", "message": "Prediction engine not available"}), 501

    event_types = [
        {"id": "career", "name_ko": "ì§ì—…/ì‚¬ì—…", "name_en": "Career/Business"},
        {"id": "relationship", "name_ko": "ì—°ì• /ê²°í˜¼", "name_en": "Love/Marriage"},
        {"id": "finance", "name_ko": "ì¬ë¬¼/íˆ¬ì", "name_en": "Finance/Investment"},
        {"id": "health", "name_ko": "ê±´ê°•", "name_en": "Health"},
        {"id": "education", "name_ko": "í•™ì—…/ì‹œí—˜", "name_en": "Education/Exam"},
        {"id": "travel", "name_ko": "ì—¬í–‰/ì´ì‚¬", "name_en": "Travel/Moving"},
        {"id": "contract", "name_ko": "ê³„ì•½/í˜‘ìƒ", "name_en": "Contract/Negotiation"},
        {"id": "general", "name_ko": "ì¼ë°˜", "name_en": "General"}
    ]

    return jsonify({
        "status": "success",
        "event_types": event_types
    })


# ===============================================================
# THEME CROSS-REFERENCE FILTER ENDPOINTS (v5.1)
# í…Œë§ˆë³„ ì‚¬ì£¼+ì ì„± êµì°¨ì  ë¶„ì„
# ===============================================================

@app.route("/api/theme/filter", methods=["POST"])
def theme_filter():
    """
    í…Œë§ˆë³„ ì‚¬ì£¼+ì ì„± êµì°¨ì  í•„í„°ë§.
    í…Œë§ˆì— ë§ëŠ” ë°ì´í„°ë§Œ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜.
    """
    if not HAS_THEME_FILTER:
        return jsonify({"status": "error", "message": "Theme filter not available"}), 501

    try:
        data = request.get_json(force=True)
        theme = data.get("theme", "overall")
        saju_data = data.get("saju", {})
        astro_data = data.get("astro", {})

        result = filter_data_by_theme(theme, saju_data, astro_data)

        return jsonify({
            "status": "success",
            **result
        })

    except Exception as e:
        logger.exception(f"[ERROR] /api/theme/filter failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/api/theme/cross-points", methods=["POST"])
def theme_cross_points():
    """
    í…Œë§ˆë³„ ì‚¬ì£¼-ì ì„± êµì°¨ì  ìƒì„¸ ë¶„ì„.
    êµì°¨ì , ì¤‘ìš” ë‚ ì§œ, í•˜ì´ë¼ì´íŠ¸ í¬í•¨.
    """
    if not HAS_THEME_FILTER:
        return jsonify({"status": "error", "message": "Theme filter not available"}), 501

    try:
        data = request.get_json(force=True)
        theme = data.get("theme", "overall")
        saju_data = data.get("saju", {})
        astro_data = data.get("astro", {})

        theme_filter_engine = get_theme_filter()
        summary = theme_filter_engine.get_theme_summary(theme, saju_data, astro_data)

        return jsonify({
            "status": "success",
            "theme": theme,
            "relevance_score": summary.get("relevance_score", 0),
            "highlights": summary.get("highlights", []),
            "intersections": summary.get("intersections", []),
            "important_dates": summary.get("important_dates", []),
            "saju_factors": summary.get("saju_factors", []),
            "astro_factors": summary.get("astro_factors", [])
        })

    except Exception as e:
        logger.exception(f"[ERROR] /api/theme/cross-points failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/api/theme/prompt-context", methods=["POST"])
def theme_prompt_context():
    """
    AI í”„ë¡¬í”„íŠ¸ìš© í…Œë§ˆë³„ ì»¨í…ìŠ¤íŠ¸ ìƒì„±.
    í•„í„°ë§ëœ ë°ì´í„°ë¥¼ í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í˜•ì‹ìœ¼ë¡œ ë°˜í™˜.
    """
    if not HAS_THEME_FILTER:
        return jsonify({"status": "error", "message": "Theme filter not available"}), 501

    try:
        data = request.get_json(force=True)
        theme = data.get("theme", "overall")
        saju_data = data.get("saju", {})
        astro_data = data.get("astro", {})

        context = get_theme_prompt_context(theme, saju_data, astro_data)

        return jsonify({
            "status": "success",
            "theme": theme,
            "prompt_context": context
        })

    except Exception as e:
        logger.exception(f"[ERROR] /api/theme/prompt-context failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/api/theme/important-dates", methods=["POST"])
def theme_important_dates():
    """
    í…Œë§ˆë³„ ì¤‘ìš” ë‚ ì§œë§Œ ë°˜í™˜.
    """
    if not HAS_THEME_FILTER:
        return jsonify({"status": "error", "message": "Theme filter not available"}), 501

    try:
        data = request.get_json(force=True)
        theme = data.get("theme", "overall")
        saju_data = data.get("saju", {})
        astro_data = data.get("astro", {})

        theme_filter_engine = get_theme_filter()
        summary = theme_filter_engine.get_theme_summary(theme, saju_data, astro_data)

        # ë‚ ì§œë§Œ ì¶”ì¶œ
        dates = summary.get("important_dates", [])

        # ì¢‹ì€ ë‚ ì§œì™€ ì£¼ì˜ ë‚ ì§œ ë¶„ë¦¬
        auspicious = [d for d in dates if d.get("is_auspicious", True)]
        caution = [d for d in dates if not d.get("is_auspicious", True)]

        return jsonify({
            "status": "success",
            "theme": theme,
            "auspicious_dates": auspicious,
            "caution_dates": caution,
            "total_count": len(dates)
        })

    except Exception as e:
        logger.exception(f"[ERROR] /api/theme/important-dates failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/api/theme/available", methods=["GET"])
def theme_available():
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ í…Œë§ˆ ëª©ë¡.
    """
    themes = [
        {"id": "love", "name_ko": "ì—°ì• /ê²°í˜¼", "name_en": "Love/Marriage", "icon": "ğŸ’•"},
        {"id": "career", "name_ko": "ì§ì—…/ì‚¬ì—…", "name_en": "Career/Business", "icon": "ğŸ’¼"},
        {"id": "wealth", "name_ko": "ì¬ë¬¼/íˆ¬ì", "name_en": "Wealth/Finance", "icon": "ğŸ’°"},
        {"id": "health", "name_ko": "ê±´ê°•", "name_en": "Health", "icon": "ğŸ¥"},
        {"id": "family", "name_ko": "ê°€ì¡±/ê´€ê³„", "name_en": "Family/Relations", "icon": "ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦"},
        {"id": "education", "name_ko": "í•™ì—…/ì‹œí—˜", "name_en": "Education/Exam", "icon": "ğŸ“š"},
        {"id": "overall", "name_ko": "ì „ì²´ ìš´ì„¸", "name_en": "Overall Fortune", "icon": "ğŸ”®"},
        {"id": "monthly", "name_ko": "ì›”ìš´", "name_en": "Monthly Fortune", "icon": "ğŸ“…"},
        {"id": "yearly", "name_ko": "ì—°ìš´", "name_en": "Yearly Fortune", "icon": "ğŸ—“ï¸"},
        {"id": "daily", "name_ko": "ì¼ìš´", "name_en": "Daily Fortune", "icon": "â˜€ï¸"}
    ]

    return jsonify({
        "status": "success",
        "themes": themes
    })


# =============================================================================
# FORTUNE SCORE API (v1.0) - Real-time Saju+Astrology Unified Score
# =============================================================================

@app.route("/api/fortune/score", methods=["POST"])
def fortune_score():
    """
    ì‹¤ì‹œê°„ í†µí•© ìš´ì„¸ ì ìˆ˜ ê³„ì‚°.
    ì‚¬ì£¼ + ì ì„±í•™ ëª¨ë“  ë°ì´í„°ë¥¼ êµì°¨ ë¶„ì„í•˜ì—¬ 0-100 ì ìˆ˜ ì‚°ì¶œ.

    Request body:
    {
        "saju": { full saju data },
        "astro": { full astrology data }
    }

    Response:
    {
        "status": "success",
        "score": {
            "total": 87,
            "saju": { "total": 45, "iljin": 12, ... },
            "astro": { "total": 42, "transit": 15, ... },
            "cross_bonus": 3,
            "alerts": [...]
        }
    }
    """
    if not HAS_FORTUNE_SCORE:
        return jsonify({"status": "error", "message": "Fortune score engine not available"}), 501

    try:
        data = request.get_json(force=True)
        saju_data = data.get("saju", {})
        astro_data = data.get("astro", {})

        if not saju_data and not astro_data:
            return jsonify({
                "status": "error",
                "message": "At least one of saju or astro data is required"
            }), 400

        start_time = time.time()
        score_result = calculate_fortune_score(saju_data, astro_data)
        elapsed = time.time() - start_time

        logger.info(f"[FORTUNE] id={g.request_id} Score calculated: {score_result['total']}/100 in {elapsed:.3f}s")

        return jsonify({
            "status": "success",
            "score": score_result,
            "timestamp": datetime.utcnow().isoformat(),
            "processing_time_ms": round(elapsed * 1000, 2)
        })

    except Exception as e:
        logger.exception(f"[ERROR] /api/fortune/score failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/api/fortune/score/breakdown", methods=["POST"])
def fortune_score_breakdown():
    """
    ìƒì„¸ ì ìˆ˜ ë‚´ì—­ê³¼ í•¨ê»˜ ì ìˆ˜ ê³„ì‚°.
    ê° í•­ëª©ë³„ ê°€ì¤‘ì¹˜ì™€ ê³„ì‚° ë¡œì§ì„ í¬í•¨.
    """
    if not HAS_FORTUNE_SCORE:
        return jsonify({"status": "error", "message": "Fortune score engine not available"}), 501

    try:
        data = request.get_json(force=True)
        saju_data = data.get("saju", {})
        astro_data = data.get("astro", {})

        engine = get_fortune_score_engine()
        breakdown = engine.calculate_score(saju_data, astro_data)

        # Add detailed breakdown info
        result = breakdown.to_dict()
        result["weights"] = {
            "saju_max": 50,
            "astro_max": 50,
            "cross_bonus_range": [-10, 10],
            "components": {
                "saju": {
                    "iljin": {"max": 12, "desc": "ì¼ì§„ ê¶í•©"},
                    "wolun": {"max": 10, "desc": "ì›”ìš´ íë¦„"},
                    "yongsin": {"max": 10, "desc": "ìš©ì‹  í™œì„±"},
                    "geokguk": {"max": 8, "desc": "ê²©êµ­ ì—ë„ˆì§€"},
                    "sibsin": {"max": 5, "desc": "ì‹­ì‹  ê· í˜•"},
                    "hyeongchung": {"range": [-5, 5], "desc": "í˜•ì¶©íšŒí•©"},
                },
                "astro": {
                    "transit": {"range": [-10, 15], "desc": "ì£¼ìš” íŠ¸ëœì§“"},
                    "moon": {"max": 10, "desc": "ë‹¬ ìœ„ìƒ/ì‚¬ì¸"},
                    "planetary_hour": {"max": 8, "desc": "í–‰ì„±ì‹œ"},
                    "voc": {"range": [-5, 0], "desc": "VOC ê³µí—ˆì‹œê°„"},
                    "retrograde": {"range": [-5, 0], "desc": "ì—­í–‰ ì˜í–¥"},
                    "aspects": {"range": [-5, 10], "desc": "í˜„ì¬ aspects"},
                    "progression": {"max": 7, "desc": "progressions"},
                },
            },
        }

        return jsonify({
            "status": "success",
            "breakdown": result,
            "timestamp": datetime.utcnow().isoformat(),
        })

    except Exception as e:
        logger.exception(f"[ERROR] /api/fortune/score/breakdown failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


# =========================================================
# ê°„ì´ ë§Œì„¸ë ¥ ê³„ì‚° (Daily Fortuneìš©)
# =========================================================
def _calculate_simple_saju(birth_date: str, birth_time: str = "12:00") -> dict:
    """
    ìƒë…„ì›”ì¼ì‹œë¡œ ê¸°ë³¸ ì‚¬ì£¼ ë°ì´í„° ê³„ì‚° (ë§Œì„¸ë ¥ ê°„ì´ ë²„ì „)
    """
    from datetime import datetime as dt_module

    # ì²œê°„/ì§€ì§€ ë°ì´í„°
    STEMS = ["ç”²", "ä¹™", "ä¸™", "ä¸", "æˆŠ", "å·±", "åºš", "è¾›", "å£¬", "ç™¸"]
    BRANCHES = ["å­", "ä¸‘", "å¯…", "å¯", "è¾°", "å·³", "åˆ", "æœª", "ç”³", "é…‰", "æˆŒ", "äº¥"]
    STEM_ELEMENTS = {"ç”²": "æœ¨", "ä¹™": "æœ¨", "ä¸™": "ç«", "ä¸": "ç«", "æˆŠ": "åœŸ",
                     "å·±": "åœŸ", "åºš": "é‡‘", "è¾›": "é‡‘", "å£¬": "æ°´", "ç™¸": "æ°´"}
    BRANCH_ELEMENTS = {"å­": "æ°´", "ä¸‘": "åœŸ", "å¯…": "æœ¨", "å¯": "æœ¨", "è¾°": "åœŸ", "å·³": "ç«",
                       "åˆ": "ç«", "æœª": "åœŸ", "ç”³": "é‡‘", "é…‰": "é‡‘", "æˆŒ": "åœŸ", "äº¥": "æ°´"}

    # ì‹­ì‹  ê³„ì‚° í—¬í¼
    def get_sibsin(day_stem: str, target_stem: str) -> str:
        dm_idx = STEMS.index(day_stem)
        t_idx = STEMS.index(target_stem)
        diff = (t_idx - dm_idx) % 10
        sibsin_map = {0: "ë¹„ê²¬", 1: "ê²ì¬", 2: "ì‹ì‹ ", 3: "ìƒê´€", 4: "í¸ì¬",
                      5: "ì •ì¬", 6: "í¸ê´€", 7: "ì •ê´€", 8: "í¸ì¸", 9: "ì •ì¸"}
        return sibsin_map.get(diff, "ë¹„ê²¬")

    try:
        # Parse birth date
        bd = dt_module.strptime(birth_date, "%Y-%m-%d")
        year, month, day = bd.year, bd.month, bd.day

        # Parse birth time
        hour = 12
        if birth_time:
            try:
                hour = int(birth_time.split(":")[0])
            except:
                hour = 12

        # ë…„ì£¼ ê³„ì‚° (1984=ç”²å­ ê¸°ì¤€)
        year_offset = (year - 1984) % 60
        year_stem = STEMS[year_offset % 10]
        year_branch = BRANCHES[year_offset % 12]

        # ì›”ì£¼ ê³„ì‚° (ê°„ëµí™” - ì‹¤ì œë¡œëŠ” ì ˆê¸° ê³ ë ¤ í•„ìš”)
        month_branch_idx = (month + 1) % 12  # å¯…ì›”(1ì›”)ë¶€í„° ì‹œì‘
        month_branch = BRANCHES[month_branch_idx]
        # ì›”ê°„ ê³„ì‚° (ë…„ê°„ ê¸°ì¤€)
        year_stem_idx = STEMS.index(year_stem)
        month_stem_idx = (year_stem_idx * 2 + month) % 10
        month_stem = STEMS[month_stem_idx]

        # ì¼ì£¼ ê³„ì‚° (JDN ê¸°ë°˜)
        a = (14 - month) // 12
        y = year + 4800 - a
        m = month + 12 * a - 3
        jdn = day + (153 * m + 2) // 5 + 365 * y + y // 4 - y // 100 + y // 400 - 32045
        day_offset = (jdn - 11) % 60  # ç”²å­ì¼ ë³´ì •
        day_stem = STEMS[day_offset % 10]
        day_branch = BRANCHES[day_offset % 12]

        # ì‹œì£¼ ê³„ì‚°
        hour_branch_idx = ((hour + 1) // 2) % 12
        hour_branch = BRANCHES[hour_branch_idx]
        day_stem_idx = STEMS.index(day_stem)
        hour_stem_idx = (day_stem_idx * 2 + hour_branch_idx) % 10
        hour_stem = STEMS[hour_stem_idx]

        # ì¼ê°„ (day master)
        dm_element = STEM_ELEMENTS[day_stem]

        # ì‹­ì‹  ë¶„í¬ ê³„ì‚°
        sibsin_dist = {}
        for stem in [year_stem, month_stem, hour_stem]:
            s = get_sibsin(day_stem, stem)
            sibsin_dist[s] = sibsin_dist.get(s, 0) + 1

        # ì˜¤ëŠ˜ ì¼ì§„ ê³„ì‚°
        today = dt_module.now()
        today_jdn = today.day + (153 * ((today.month + 12 * ((14 - today.month) // 12) - 3)) + 2) // 5 + \
                    365 * (today.year + 4800 - ((14 - today.month) // 12)) + \
                    (today.year + 4800 - ((14 - today.month) // 12)) // 4 - \
                    (today.year + 4800 - ((14 - today.month) // 12)) // 100 + \
                    (today.year + 4800 - ((14 - today.month) // 12)) // 400 - 32045
        today_offset = (today_jdn - 11) % 60
        today_stem = STEMS[today_offset % 10]
        today_branch = BRANCHES[today_offset % 12]
        today_element = STEM_ELEMENTS[today_stem]

        # í˜•ì¶©íšŒí•© ê°„ì´ ê³„ì‚°
        CHONG_PAIRS = [("å­", "åˆ"), ("ä¸‘", "æœª"), ("å¯…", "ç”³"), ("å¯", "é…‰"), ("è¾°", "æˆŒ"), ("å·³", "äº¥")]
        HAP_PAIRS = [("å­", "ä¸‘"), ("å¯…", "äº¥"), ("å¯", "æˆŒ"), ("è¾°", "é…‰"), ("å·³", "ç”³"), ("åˆ", "æœª")]

        natal_branches = [year_branch, month_branch, day_branch, hour_branch]
        chung_list = []
        hap_list = []
        for b in natal_branches:
            if (b, today_branch) in CHONG_PAIRS or (today_branch, b) in CHONG_PAIRS:
                chung_list.append(f"{b}-{today_branch}")
            if (b, today_branch) in HAP_PAIRS or (today_branch, b) in HAP_PAIRS:
                hap_list.append(f"{b}-{today_branch}")

        return {
            "dayMaster": {"name": day_stem, "element": dm_element},
            "pillars": {
                "year": year_stem + year_branch,
                "month": month_stem + month_branch,
                "day": day_stem + day_branch,
                "time": hour_stem + hour_branch,
            },
            "unse": {
                "iljin": [{"gan": today_stem, "ji": today_branch, "element": today_element}],
                "monthly": [{"element": STEM_ELEMENTS.get(month_stem, "åœŸ")}],
                "annual": [{"element": STEM_ELEMENTS.get(year_stem, "åœŸ")}],
            },
            "advancedAnalysis": {
                "sibsin": {"distribution": sibsin_dist},
                "hyeongchung": {"chung": chung_list, "hap": hap_list},
                "yongsin": {"primary": {"element": dm_element}},  # ê°„ì´ ìš©ì‹ 
                "geokguk": {"grade": "ì¤‘"},
            },
        }
    except Exception as e:
        logger.warning(f"[SimpleSaju] Calculation error: {e}")
        # Fallback minimal data
        return {
            "dayMaster": {"name": "ç”²", "element": "æœ¨"},
            "pillars": {"year": "ç”²å­", "month": "ç”²å¯…", "day": "ç”²åˆ", "time": "ç”²å­"},
            "unse": {"iljin": [{"element": "æœ¨"}], "monthly": [{"element": "æœ¨"}], "annual": [{"element": "æœ¨"}]},
            "advancedAnalysis": {
                "sibsin": {"distribution": {}},
                "hyeongchung": {"chung": [], "hap": []},
            },
        }


@app.route("/api/fortune/daily", methods=["POST"])
def fortune_daily():
    """
    ì¼ì¼ ìš´ì„¸ ì ìˆ˜ (ê°„ë‹¨í•œ ë²„ì „).
    ìƒë…„ì›”ì¼ë§Œìœ¼ë¡œ ë¹ ë¥´ê²Œ ì ìˆ˜ ê³„ì‚°.
    """
    if not HAS_FORTUNE_SCORE:
        return jsonify({"status": "error", "message": "Fortune score engine not available"}), 501

    try:
        data = request.get_json(force=True)
        birth_date = data.get("birthDate")  # YYYY-MM-DD
        birth_time = data.get("birthTime")  # HH:MM (optional)

        if not birth_date:
            return jsonify({"status": "error", "message": "birthDate is required"}), 400

        # Calculate saju data from birth info (simplified backend calculation)
        saju_data = _calculate_simple_saju(birth_date, birth_time or "12:00")

        # Get REAL-TIME astrology data
        realtime_transits = get_current_transits()
        moon_data = realtime_transits.get("moon", {})
        retrogrades = realtime_transits.get("retrogrades", [])
        aspects = realtime_transits.get("aspects", [])
        planets = realtime_transits.get("planets", [])

        # Determine planetary hour from current hour
        from datetime import datetime as dt_module
        current_hour = dt_module.now().hour
        planetary_hours = ["Saturn", "Jupiter", "Mars", "Sun", "Venus", "Mercury", "Moon"]
        planetary_hour_ruler = planetary_hours[current_hour % 7]

        # Build astro_data with real values
        astro_data = {
            "planets": planets,
            "transits": [{"planet": a["planet1"], "aspect": a["aspect"], "natalPlanet": a["planet2"]} for a in aspects[:5]],
            "aspects": aspects,
            "electional": {
                "moonPhase": {"phase": moon_data.get("phase_name", "Unknown")},
                "planetaryHour": {"planet": planetary_hour_ruler},
                "voidOfCourse": {"isVoid": False},  # TODO: implement VOC calculation
                "retrograde": retrogrades,
            }
        }

        score_result = calculate_fortune_score(saju_data, astro_data)

        # Extract score breakdown
        saju_breakdown = score_result.get("saju", {})
        astro_breakdown = score_result.get("astro", {})
        total_score = score_result["total"]

        # =====================================================
        # ì˜ì—­ë³„ ì ìˆ˜ ê³„ì‚° (ì‚¬ì£¼ ì‹­ì‹  + ì˜¤í–‰ + ì ì„±ìˆ  êµì°¨ ë¶„ì„)
        # =====================================================

        # Get day master and current unse elements
        day_master = saju_data.get("dayMaster", {})
        dm_element = day_master.get("element", "æœ¨") if isinstance(day_master, dict) else "æœ¨"

        # Get today's pillar element from unse
        unse = saju_data.get("unse", {})
        iljin = unse.get("iljin", [{}])
        today_element = iljin[0].get("element", "æœ¨") if iljin else "æœ¨"

        # Get sibsin distribution
        adv = saju_data.get("advancedAnalysis", {})
        sibsin = adv.get("sibsin", {})
        sibsin_dist = sibsin.get("distribution", {}) or sibsin.get("counts", {})

        # ì˜ì—­ë³„ ê´€ë ¨ ì‹­ì„± ë° ì˜¤í–‰ (ì‚¬ì£¼ ì „í†µ ì´ë¡  ê¸°ë°˜)
        AREA_CONFIG = {
            "love": {
                "boost_sibsin": ["ì •ê´€", "ì •ì¬", "ì‹ì‹ "],  # ì •ê´€=ë°°ìš°ì(ì—¬), ì •ì¬=ë°°ìš°ì(ë‚¨), ì‹ì‹ =ë§¤ë ¥
                "penalty_sibsin": ["í¸ê´€", "ìƒê´€"],  # í¸ê´€=ë¶ˆì•ˆì •, ìƒê´€=êµ¬ì„¤
                "related_elements": ["ç«", "æœ¨"],  # í™”=ì—´ì •, ëª©=ì„±ì¥
                "astro_boost": ["Venus", "Moon"],  # ê¸ˆì„±=ì‚¬ë‘, ë‹¬=ê°ì •
            },
            "career": {
                "boost_sibsin": ["ì •ê´€", "í¸ê´€", "ì •ì¸"],  # ê´€ì„±=ì§ì¥, ì¸ì„±=ê¶Œìœ„
                "penalty_sibsin": ["ìƒê´€"],  # ìƒê´€=ìƒì‚¬ì¶©ëŒ
                "related_elements": ["é‡‘", "åœŸ"],  # ê¸ˆ=ê²°ë‹¨, í† =ì•ˆì •
                "astro_boost": ["Saturn", "Jupiter", "Sun"],  # í† ì„±=ì±…ì„, ëª©ì„±=ì„±ê³µ, íƒœì–‘=ëª…ì˜ˆ
            },
            "wealth": {
                "boost_sibsin": ["ì •ì¬", "í¸ì¬", "ì‹ì‹ "],  # ì¬ì„±=ì¬ë¬¼, ì‹ì‹ =ìƒì‚°
                "penalty_sibsin": ["ê²ì¬", "ë¹„ê²¬"],  # ë¹„ê²=ê²½ìŸ/ì†ì¬
                "related_elements": ["åœŸ", "é‡‘"],  # í† =ì¶•ì , ê¸ˆ=ê°€ì¹˜
                "astro_boost": ["Jupiter", "Venus"],  # ëª©ì„±=í™•ì¥, ê¸ˆì„±=ê°€ì¹˜
            },
            "health": {
                "boost_sibsin": ["ì •ì¸", "ë¹„ê²¬"],  # ì¸ì„±=ë³´í˜¸, ë¹„ê²¬=ì²´ë ¥
                "penalty_sibsin": ["í¸ê´€", "ìƒê´€"],  # ê´€ì„±=ìŠ¤íŠ¸ë ˆìŠ¤, ìƒê´€=ì†Œëª¨
                "related_elements": ["æœ¨", "æ°´"],  # ëª©=ìƒê¸°, ìˆ˜=ìœ ì—°
                "astro_boost": ["Moon", "Sun"],  # ë‹¬=ë¦¬ë“¬, íƒœì–‘=í™œë ¥
            },
        }

        # ì˜¤í–‰ ìƒìƒìƒê·¹ ê´€ê³„
        ELEMENT_GENERATING = {"æœ¨": "ç«", "ç«": "åœŸ", "åœŸ": "é‡‘", "é‡‘": "æ°´", "æ°´": "æœ¨"}
        ELEMENT_CONTROLLING = {"æœ¨": "åœŸ", "åœŸ": "æ°´", "æ°´": "ç«", "ç«": "é‡‘", "é‡‘": "æœ¨"}

        # í–‰ì„±ë³„ ìœ ë¦¬í•œ/ë¶ˆë¦¬í•œ ì‚¬ì¸ (Dignity/Detriment)
        PLANET_DIGNITY = {
            "Venus": {"dignity": ["Taurus", "Libra"], "detriment": ["Scorpio", "Aries"]},
            "Mars": {"dignity": ["Aries", "Scorpio"], "detriment": ["Libra", "Taurus"]},
            "Jupiter": {"dignity": ["Sagittarius", "Pisces"], "detriment": ["Gemini", "Virgo"]},
            "Saturn": {"dignity": ["Capricorn", "Aquarius"], "detriment": ["Cancer", "Leo"]},
            "Mercury": {"dignity": ["Gemini", "Virgo"], "detriment": ["Sagittarius", "Pisces"]},
            "Sun": {"dignity": ["Leo"], "detriment": ["Aquarius"]},
            "Moon": {"dignity": ["Cancer"], "detriment": ["Capricorn"]},
        }

        # Aspect scores
        ASPECT_SCORES = {
            "conjunction": 3, "trine": 4, "sextile": 2,
            "square": -3, "opposition": -2,
        }

        # ì˜ì—­ë³„ ê´€ë ¨ í•˜ìš°ìŠ¤/ì‚¬ì¸
        AREA_ASTRO_SIGNS = {
            "love": ["Libra", "Taurus", "Cancer", "Pisces"],  # 7H, Venus ruled, emotional
            "career": ["Capricorn", "Leo", "Aries", "Virgo"],  # 10H, Sun ruled, achievement
            "wealth": ["Taurus", "Scorpio", "Cancer", "Capricorn"],  # 2H, 8H, material
            "health": ["Virgo", "Aries", "Scorpio", "Leo"],  # 6H, vitality signs
        }

        def calc_area_score(area: str) -> int:
            config = AREA_CONFIG[area]
            score = 50  # ê¸°ë³¸ì ìˆ˜

            # ========== ì‚¬ì£¼ ìš”ì†Œ (50%) ==========

            # 1. ì‹­ì‹  ê°€ì‚°/ê°ì‚° - ìµœëŒ€ Â±15ì 
            for boost in config["boost_sibsin"]:
                if sibsin_dist.get(boost, 0) > 0:
                    score += 4 * min(sibsin_dist.get(boost, 0), 3)
            for penalty in config["penalty_sibsin"]:
                if sibsin_dist.get(penalty, 0) > 1:
                    score -= 3 * (sibsin_dist.get(penalty, 0) - 1)

            # 2. ì˜¤ëŠ˜ ìš´ì„¸ ì˜¤í–‰ê³¼ ì˜ì—­ ê´€ë ¨ ì˜¤í–‰ ë§¤ì¹­ - ìµœëŒ€ +12ì 
            if today_element in config["related_elements"]:
                score += 12

            # 3. ì¼ê°„ê³¼ ì˜¤ëŠ˜ ì˜¤í–‰ì˜ ê´€ê³„ - ìµœëŒ€ Â±10ì 
            if today_element == dm_element:
                score += 4  # ë¹„í™”
            elif ELEMENT_GENERATING.get(today_element) == dm_element:
                score += 10  # ìƒì¡°
            elif ELEMENT_CONTROLLING.get(today_element) == dm_element:
                score -= 8  # ê·¹ì…
            elif ELEMENT_GENERATING.get(dm_element) == today_element:
                score -= 4  # ì„¤ê¸°

            # 4. í˜•ì¶©íšŒí•© - ìµœëŒ€ Â±8ì 
            hc = adv.get("hyeongchung", {})
            if area == "love":
                score += len(hc.get("hap", [])) * 3
                score -= len(hc.get("chung", [])) * 4
            elif area == "career":
                score += len(hc.get("samhap", [])) * 2  # ì‚¼í•©=í° ì„±ê³¼
                score -= len(hc.get("hyeong", [])) * 2  # í˜•=ê°ˆë“±

            # ========== ì ì„±ìˆ  ìš”ì†Œ (50%) ==========

            # 5. ê´€ë ¨ í–‰ì„± ìƒíƒœ (ìˆœí–‰/ì—­í–‰ + Dignity) - ìµœëŒ€ Â±15ì 
            for planet in planets:
                planet_name = planet.get("name", "")
                planet_sign = planet.get("sign", "")

                if planet_name in config["astro_boost"]:
                    # ìˆœí–‰/ì—­í–‰
                    if not planet.get("retrograde"):
                        score += 3
                    else:
                        score -= 2

                    # Dignity/Detriment (í–‰ì„±ì´ ìœ ë¦¬í•œ ì‚¬ì¸ì— ìˆëŠ”ì§€)
                    dignity_info = PLANET_DIGNITY.get(planet_name, {})
                    if planet_sign in dignity_info.get("dignity", []):
                        score += 5  # ë³¸ìœ„ì¹˜ = ê°•í™”
                    elif planet_sign in dignity_info.get("detriment", []):
                        score -= 3  # ë¶ˆë¦¬í•œ ìœ„ì¹˜

            # 6. í˜„ì¬ í–‰ì„±ì´ ì˜ì—­ ê´€ë ¨ ì‚¬ì¸ì— ìˆëŠ”ì§€ - ìµœëŒ€ +10ì 
            area_signs = AREA_ASTRO_SIGNS.get(area, [])
            for planet in planets[:5]:  # ê°œì¸í–‰ì„±ë§Œ (Sun~Mars)
                if planet.get("sign") in area_signs:
                    score += 2

            # 7. íŠ¸ëœì§“ Aspects ë¶„ì„ - ìµœëŒ€ Â±12ì 
            for asp in aspects:
                p1 = asp.get("planet1", "")
                p2 = asp.get("planet2", "")
                asp_type = asp.get("aspect", "").lower()

                # ì˜ì—­ ê´€ë ¨ í–‰ì„±ì´ í¬í•¨ëœ aspect
                if p1 in config["astro_boost"] or p2 in config["astro_boost"]:
                    asp_score = ASPECT_SCORES.get(asp_type, 0)
                    score += asp_score

            # 8. ë‹¬ ìœ„ìƒ - ìµœëŒ€ Â±8ì  (ëª¨ë“  ì˜ì—­ì— ì˜í–¥)
            moon_phase = moon_data.get("phase_name", "")
            moon_scores = {
                "Full Moon": 8, "Waxing Gibbous": 5, "First Quarter": 3,
                "Waxing Crescent": 2, "New Moon": -3, "Waning Crescent": -2,
                "Last Quarter": 0, "Waning Gibbous": 1,
            }
            base_moon = moon_scores.get(moon_phase, 0)
            # ì—°ì• /ê±´ê°•ì€ ë‹¬ ì˜í–¥ ë” ë°›ìŒ
            if area in ["love", "health"]:
                score += int(base_moon * 1.2)
            else:
                score += int(base_moon * 0.7)

            # 9. ì—­í–‰ ì˜í–¥ (ì˜ì—­ë³„ ì°¨ë“±) - ìµœëŒ€ -8ì 
            if "Mercury" in retrogrades:
                if area == "career":
                    score -= 5  # ì†Œí†µ/ê³„ì•½ ë¬¸ì œ
                elif area == "wealth":
                    score -= 4  # ê±°ë˜ ì§€ì—°
            if "Venus" in retrogrades:
                if area == "love":
                    score -= 6  # ì—°ì•  ì—­í–‰
                elif area == "wealth":
                    score -= 3  # ê¸ˆì „ ê°€ì¹˜ í˜¼ë€
            if "Mars" in retrogrades:
                if area == "career":
                    score -= 4  # ì¶”ì§„ë ¥ ì•½í™”
                elif area == "health":
                    score -= 3  # ì—ë„ˆì§€ ì €í•˜
            if "Jupiter" in retrogrades:
                if area in ["wealth", "career"]:
                    score -= 3  # í™•ì¥ ì§€ì—°

            return max(0, min(100, score))

        love_score = calc_area_score("love")
        career_score = calc_area_score("career")
        wealth_score = calc_area_score("wealth")
        health_score = calc_area_score("health")

        # Overall = ì˜ì—­ë³„ ê°€ì¤‘ í‰ê·  + FortuneScoreEngine cross_bonus ë°˜ì˜
        cross_bonus = score_result.get("cross_bonus", 0)
        overall_score = int((love_score + career_score + wealth_score + health_score) / 4 + cross_bonus)
        overall_score = max(0, min(100, overall_score))

        return jsonify({
            "status": "success",
            "fortune": {
                "overall": overall_score,
                "love": love_score,
                "career": career_score,
                "wealth": wealth_score,
                "health": health_score,
            },
            "breakdown": score_result,
            "realtime_astro": {
                "moon_phase": moon_data.get("phase_name"),
                "moon_illumination": moon_data.get("illumination"),
                "retrogrades": retrogrades,
                "planetary_hour": planetary_hour_ruler,
            },
            "alerts": score_result.get("alerts", []),
            "timestamp": datetime.utcnow().isoformat(),
        })

    except Exception as e:
        logger.exception(f"[ERROR] /api/fortune/daily failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/api/search/domain", methods=["POST"])
def domain_rag_search():
    """
    Lightweight domain search over precomputed embeddings.
    body: { "domain": "destiny_map|tarot|dream|iching", "query": "...", "top_k": 5 }
    """
    if not HAS_DOMAIN_RAG:
        return jsonify({"status": "error", "message": "DomainRAG not available"}), 501

    try:
        data = request.get_json(force=True)
        domain = (data.get("domain") or "").strip()
        query = (data.get("query") or "").strip()
        top_k = int(data.get("top_k", 5))
        top_k = max(1, min(top_k, 20))

        if not query:
            return jsonify({"status": "error", "message": "query is required"}), 400
        if not domain or domain not in DOMAIN_RAG_DOMAINS:
            return jsonify({
                "status": "error",
                "message": f"domain must be one of {DOMAIN_RAG_DOMAINS}",
            }), 400

        rag = get_domain_rag()
        rag.load_domain(domain)

        results = rag.search(domain, query, top_k=top_k)
        context = rag.get_context(domain, query, top_k=min(top_k, 3), max_chars=1500)

        return jsonify({
            "status": "success",
            "domain": domain,
            "query": query,
            "results": results,
            "context": context,
        })

    except Exception as e:
        logger.exception(f"[ERROR] /api/search/domain failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/api/search/hybrid", methods=["POST"])
def hybrid_rag_search():
    """
    Hybrid search (vector + BM25 + graph, optional rerank).
    body: { "query": "...", "top_k": 8, "rerank": true, "graph_root": "<optional>" }
    """
    if not HAS_HYBRID_RAG:
        return jsonify({"status": "error", "message": "Hybrid RAG not available"}), 501

    try:
        data = request.get_json(force=True)
        query = (data.get("query") or "").strip()
        top_k = int(data.get("top_k", 8))
        top_k = max(1, min(top_k, 30))
        rerank = bool(data.get("rerank", True))
        graph_root = data.get("graph_root")

        if not query:
            return jsonify({"status": "error", "message": "query is required"}), 400

        results = hybrid_search(
            query=query,
            top_k=top_k,
            use_reranking=rerank,
            graph_root=graph_root,
        )
        context = build_rag_context(query, top_k=min(12, max(top_k, 6)))

        return jsonify({
            "status": "success",
            "query": query,
            "top_k": top_k,
            "rerank": rerank,
            "results": results,
            "context": context,
        })

    except Exception as e:
        logger.exception(f"[ERROR] /api/search/hybrid failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/api/compatibility", methods=["POST"])
def compatibility_analysis():
    """
    Relationship compatibility (Saju + Astrology fusion with GPT).
    Accepts 2~4 people; uses group mode for 3-4 people.
    """
    if not HAS_COMPATIBILITY:
        return jsonify({"status": "error", "message": "Compatibility engine not available"}), 501

    try:
        data = request.get_json(force=True)
        people = data.get("people") or []

        # Backward compatibility: allow person1/person2 fields
        if not people:
            p1 = data.get("person1") or {}
            p2 = data.get("person2") or {}
            if p1 and p2:
                people = [p1, p2]

        relationship_type = data.get("relationship_type") or data.get("relationshipType") or "lover"
        locale = data.get("locale", "ko")

        if len(people) < 2:
            return jsonify({"status": "error", "message": "At least two people are required"}), 400
        if len(people) > 5:
            return jsonify({"status": "error", "message": "Maximum 5 people supported"}), 400

        if len(people) <= 2:
            result = interpret_compatibility(people, relationship_type, locale)
        else:
            result = interpret_compatibility_group(people, relationship_type, locale)

        status_code = 200 if result.get("status") == "success" else 500
        return jsonify(result), status_code

    except Exception as e:
        logger.exception(f"[ERROR] /api/compatibility failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/api/compatibility/chat", methods=["POST"])
def compatibility_chat():
    """
    Compatibility chat consultation - follow-up questions about a compatibility reading.
    """
    if not HAS_COMPATIBILITY:
        return jsonify({"status": "error", "message": "Compatibility engine not available"}), 501

    try:
        data = request.get_json(force=True)
        logger.info(f"[COMPAT_CHAT] id={g.request_id} Processing chat message")

        persons = data.get("persons", [])
        question = data.get("question", "")
        history = data.get("history", [])
        locale = data.get("locale", "ko")
        compatibility_context = data.get("compatibility_context", "")
        prompt = data.get("prompt", "")

        if not persons or len(persons) < 2:
            return jsonify({"status": "error", "message": "At least 2 persons required"}), 400

        if not question and not prompt:
            return jsonify({"status": "error", "message": "No question provided"}), 400

        start_time = time.time()
        is_korean = locale == "ko"

        # Current date for contextual responses
        now = datetime.now()
        weekday_names_ko = ["ì›”ìš”ì¼", "í™”ìš”ì¼", "ìˆ˜ìš”ì¼", "ëª©ìš”ì¼", "ê¸ˆìš”ì¼", "í† ìš”ì¼", "ì¼ìš”ì¼"]
        if is_korean:
            date_str = f"{now.year}ë…„ {now.month}ì›” {now.day}ì¼ ({weekday_names_ko[now.weekday()]})"
        else:
            date_str = now.strftime("%B %d, %Y (%A)")

        # Format persons info
        persons_info = []
        for i, p in enumerate(persons):
            name = p.get("name") or f"Person {i + 1}"
            birth_date = p.get("birthDate") or p.get("date", "")
            birth_time = p.get("birthTime") or p.get("time", "")
            relation = p.get("relation", "")
            persons_info.append(f"- {name}: {birth_date} {birth_time}" + (f" ({relation})" if relation else ""))

        persons_str = "\n".join(persons_info)

        # Build conversation history
        conversation_history = []
        for msg in history[-6:]:  # Last 6 messages
            role = msg.get("role", "user")
            content = msg.get("content", "")
            if role != "system":
                conversation_history.append(f"{'ì‚¬ìš©ì' if role == 'user' else 'AI'}: {content[:300]}")

        history_str = "\n".join(conversation_history) if conversation_history else "(ì²« ì§ˆë¬¸)"

        # Build chat prompt - counselor style with GPT-4o-mini for speed
        if is_korean:
            system_instruction = """ë‹¹ì‹ ì€ ë”°ëœ»í•˜ê³  ê³µê° ëŠ¥ë ¥ì´ ë›°ì–´ë‚œ ê¶í•© ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.
ë§ˆì¹˜ ì˜¤ëœ ì–¸ë‹ˆ/ì˜¤ë¹ ì²˜ëŸ¼ í¸ì•ˆí•˜ê²Œ ëŒ€í™”í•˜ë©´ì„œ, ë‘ ì‚¬ëŒì˜ ê´€ê³„ì— ëŒ€í•´ ì§„ì‹¬ ì–´ë¦° ì¡°ì–¸ì„ í•´ì£¼ì„¸ìš”.

ìƒë‹´ ìŠ¤íƒ€ì¼:
- ê³µê°í•˜ë©° ê²½ì²­í•˜ëŠ” ë§íˆ¬ ("ê·¸ëŸ¬ì‹œêµ°ìš”", "ì´í•´í•´ìš”", "~í•˜ì‹¤ ìˆ˜ ìˆì–´ìš”")
- ì‚¬ì£¼Â·ì ì„±í•™ ì „ë¬¸ ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…
- ë‹¨ì •ì  íŒë‹¨ë³´ë‹¤ëŠ” ê°€ëŠ¥ì„±ê³¼ ë…¸ë ¥ì˜ ë°©í–¥ ì œì‹œ
- ê´€ê³„ì˜ ê°•ì ì„ ë¨¼ì € ì§šì–´ì£¼ê³ , ê°œì„ ì ì€ ê±´ì„¤ì ìœ¼ë¡œ
- 3-4ë¬¸ì¥ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ë“¯ ë‹µë³€"""
        else:
            system_instruction = """You are a warm and empathetic relationship counselor.
Talk like a trusted friend while sharing genuine insights about their relationship.

Counseling style:
- Use empathetic, listening language
- Explain Saju/Astrology terms simply
- Focus on possibilities rather than definitive judgments
- Highlight relationship strengths first, then constructive improvements
- Answer naturally in 3-4 sentences like a conversation"""

        chat_prompt = f"""{system_instruction}

## ì˜¤ëŠ˜: {date_str}

## ë¶„ì„ ëŒ€ìƒ
{persons_str}

## ê¶í•© ë¶„ì„ ê²°ê³¼
{compatibility_context[:1500] if compatibility_context else '(ë¶„ì„ ê²°ê³¼ ì—†ìŒ)'}

## ëŒ€í™”
{history_str}

## ì§ˆë¬¸
{question or prompt}"""

        try:
            # GPT-4o-mini for fast, natural counselor responses (skip refine for speed)
            reply = _generate_with_gpt4(chat_prompt, max_tokens=400, temperature=0.5, use_mini=True)
        except Exception as llm_e:
            logger.warning(f"[COMPAT_CHAT] GPT-4 failed: {llm_e}")
            if is_korean:
                reply = "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ AI ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
            else:
                reply = "Sorry, unable to generate AI response at the moment. Please try again later."

        duration_ms = int((time.time() - start_time) * 1000)
        logger.info(f"[COMPAT_CHAT] id={g.request_id} completed in {duration_ms}ms")

        return jsonify({
            "status": "success",
            "response": reply,
            "data": {
                "response": reply,
            },
            "performance": {"duration_ms": duration_ms}
        })

    except Exception as e:
        logger.exception(f"[ERROR] /api/compatibility/chat failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


# System capabilities
@app.route("/capabilities", methods=["GET"])
def get_capabilities():
    """Get system capabilities (what's enabled)."""
    return jsonify({
        "status": "success",
        "capabilities": {
            "realtime_transits": HAS_REALTIME,
            "chart_generation": HAS_CHARTS,
            "user_memory": HAS_USER_MEMORY,
            "iching_premium": HAS_ICHING,
            "persona_embeddings": HAS_PERSONA_EMBED,
            "tarot_premium": HAS_TAROT,
            "rlhf_learning": HAS_RLHF,
            "badge_system": HAS_BADGES,
            "agentic_rag": HAS_AGENTIC,
            "jungian_counseling": HAS_COUNSELING,
            "prediction_engine": HAS_PREDICTION,
            "theme_cross_filter": HAS_THEME_FILTER,
            "fortune_score": HAS_FORTUNE_SCORE,
            "hybrid_rag": HAS_HYBRID_RAG,
            "domain_rag": HAS_DOMAIN_RAG,
            "compatibility": HAS_COMPATIBILITY,
            "numerology": HAS_NUMEROLOGY,
            "icp": HAS_ICP,
        },
        "version": "5.3.0-numerology-icp",
    })


# ===============================================================
# NUMEROLOGY ENDPOINTS
# ===============================================================

@app.route("/api/numerology/analyze", methods=["POST"])
def numerology_analyze():
    """
    Analyze numerology profile from birth date and name.

    Request body:
    {
        "birthDate": "YYYY-MM-DD",
        "englishName": "Full Name" (optional),
        "koreanName": "í•œê¸€ì´ë¦„" (optional),
        "locale": "ko" (optional)
    }
    """
    if not HAS_NUMEROLOGY:
        return jsonify({"error": "Numerology module not available"}), 503

    try:
        data = request.get_json() or {}
        birth_date = data.get("birthDate")
        if not birth_date:
            return jsonify({"error": "birthDate is required"}), 400

        result = analyze_numerology(
            birth_date=birth_date,
            english_name=data.get("englishName"),
            korean_name=data.get("koreanName"),
            locale=data.get("locale", "ko")
        )
        return jsonify(result)

    except Exception as e:
        logger.exception("[numerology_analyze] Error")
        return jsonify({"error": str(e)}), 500


@app.route("/api/numerology/compatibility", methods=["POST"])
def numerology_compatibility():
    """
    Analyze numerology compatibility between two people.

    Request body:
    {
        "person1": {"birthDate": "YYYY-MM-DD", "name": "Name"},
        "person2": {"birthDate": "YYYY-MM-DD", "name": "Name"},
        "locale": "ko"
    }
    """
    if not HAS_NUMEROLOGY:
        return jsonify({"error": "Numerology module not available"}), 503

    try:
        data = request.get_json() or {}
        p1 = data.get("person1", {})
        p2 = data.get("person2", {})

        if not p1.get("birthDate") or not p2.get("birthDate"):
            return jsonify({"error": "Both birthDates are required"}), 400

        result = analyze_numerology_compatibility(
            person1_birth=p1["birthDate"],
            person2_birth=p2["birthDate"],
            person1_name=p1.get("name"),
            person2_name=p2.get("name"),
            locale=data.get("locale", "ko")
        )
        return jsonify(result)

    except Exception as e:
        logger.exception("[numerology_compatibility] Error")
        return jsonify({"error": str(e)}), 500


# ===============================================================
# ICP (INTERPERSONAL CIRCUMPLEX) ENDPOINTS
# ===============================================================

@app.route("/api/icp/analyze", methods=["POST"])
def icp_analyze():
    """
    Analyze ICP interpersonal style from saju/astrology data.

    Request body:
    {
        "sajuData": {...},  (optional)
        "astroData": {...}, (optional)
        "locale": "ko"
    }
    """
    if not HAS_ICP:
        return jsonify({"error": "ICP module not available"}), 503

    try:
        data = request.get_json() or {}
        result = analyze_icp_style(
            saju_data=data.get("sajuData"),
            astro_data=data.get("astroData"),
            locale=data.get("locale", "ko")
        )
        return jsonify(result)

    except Exception as e:
        logger.exception("[icp_analyze] Error")
        return jsonify({"error": str(e)}), 500


@app.route("/api/icp/compatibility", methods=["POST"])
def icp_compatibility():
    """
    Analyze ICP compatibility between two people.

    Request body:
    {
        "person1": {"sajuData": {...}, "astroData": {...}},
        "person2": {"sajuData": {...}, "astroData": {...}},
        "locale": "ko"
    }
    """
    if not HAS_ICP:
        return jsonify({"error": "ICP module not available"}), 503

    try:
        data = request.get_json() or {}
        p1 = data.get("person1", {})
        p2 = data.get("person2", {})

        result = analyze_icp_compatibility(
            person1_saju=p1.get("sajuData"),
            person1_astro=p1.get("astroData"),
            person2_saju=p2.get("sajuData"),
            person2_astro=p2.get("astroData"),
            locale=data.get("locale", "ko")
        )
        return jsonify(result)

    except Exception as e:
        logger.exception("[icp_compatibility] Error")
        return jsonify({"error": str(e)}), 500


@app.route("/api/icp/questions", methods=["POST"])
def icp_questions():
    """
    Get therapeutic questions for an ICP style.

    Request body:
    {
        "style": "PA",  (ICP octant code)
        "locale": "ko"
    }
    """
    if not HAS_ICP:
        return jsonify({"error": "ICP module not available"}), 503

    try:
        data = request.get_json() or {}
        style = data.get("style", "LM")
        result = get_icp_questions(
            style=style,
            locale=data.get("locale", "ko")
        )
        return jsonify(result)

    except Exception as e:
        logger.exception("[icp_questions] Error")
        return jsonify({"error": str(e)}), 500


# ===============================================================
# SESSION SUMMARY API - Auto-generate counseling session summaries
# ===============================================================

@app.route("/api/counseling/session-summary", methods=["POST"])
def counseling_session_summary():
    """
    Generate a summary for a counseling session.
    ìƒë‹´ ì„¸ì…˜ ìš”ì•½ ìë™ ìƒì„± - ë‹¤ìŒ ì„¸ì…˜ ì—°ì†ì„±ì„ ìœ„í•´.

    Request body:
    {
        "messages": [{"role": "user/assistant", "content": "..."}, ...],
        "saju_data": {...},  // Optional
        "astro_data": {...},  // Optional
        "locale": "ko"  // Optional
    }

    Response:
    {
        "summary": "...",
        "key_topics": ["topic1", "topic2"],
        "emotional_journey": "...",
        "recommended_followup": ["question1", "question2"],
        "jung_insights": {...}
    }
    """
    try:
        data = request.get_json(force=True)
        messages = data.get("messages", [])
        locale = data.get("locale", "ko")
        saju_data = data.get("saju_data", {})
        astro_data = data.get("astro_data", {})

        if not messages or len(messages) < 2:
            return jsonify({"status": "error", "message": "At least 2 messages required for summary"}), 400

        # Extract user messages for analysis
        user_messages = [m["content"] for m in messages if m.get("role") == "user"]
        assistant_messages = [m["content"] for m in messages if m.get("role") == "assistant"]

        # Topic extraction
        topic_keywords = {
            "ì—°ì• /ê´€ê³„": ["ì—°ì• ", "ì‚¬ë‘", "ê²°í˜¼", "ì´ë³„", "ì¸", "ì§ì‚¬ë‘", "ì»¤í”Œ"],
            "ì»¤ë¦¬ì–´/ì§„ë¡œ": ["ì·¨ì—…", "ì´ì§", "ì§„ë¡œ", "ì‚¬ì—…", "í‡´ì‚¬", "íšŒì‚¬", "ì§ì¥"],
            "ê°€ì¡±": ["ë¶€ëª¨", "ì—„ë§ˆ", "ì•„ë¹ ", "ê°€ì¡±", "í˜•ì œ", "ìë§¤", "ìë…€"],
            "ìê¸°íƒìƒ‰": ["ì„±ê²©", "ë‚˜ëŠ”", "ì–´ë–¤ ì‚¬ëŒ", "ì¥ì ", "ë‹¨ì ", "ì •ì²´ì„±"],
            "ê±´ê°•/ìŠ¤íŠ¸ë ˆìŠ¤": ["í˜ë“¤", "ìš°ìš¸", "ì§€ì³", "ìŠ¤íŠ¸ë ˆìŠ¤", "ë¶ˆì•ˆ", "ê±±ì •"],
            "ì¬ì •": ["ëˆ", "ì¬ì •", "ê²½ì œ", "íˆ¬ì", "ë¶€ë™ì‚°"],
            "íƒ€ì´ë°/ì‹œê¸°": ["ì–¸ì œ", "ì‹œê¸°", "íƒ€ì´ë°", "ì˜¬í•´", "ë‚´ë…„"],
        }

        detected_topics = []
        all_user_text = " ".join(user_messages).lower()
        for topic, keywords in topic_keywords.items():
            if any(kw in all_user_text for kw in keywords):
                detected_topics.append(topic)

        # Emotional journey extraction
        emotions_timeline = []
        emotion_map = {
            "exhausted": "ì§€ì¹¨",
            "sad": "ìŠ¬í””",
            "anxious": "ë¶ˆì•ˆ",
            "angry": "ë¶„ë…¸",
            "lonely": "ì™¸ë¡œì›€",
            "hopeful": "í¬ë§",
            "confused": "í˜¼ë€",
            "relieved": "ì•ˆë„",
            "grateful": "ê°ì‚¬",
        }

        for msg in user_messages:
            msg_lower = msg.lower()
            for eng_emotion, kr_emotion in emotion_map.items():
                if any(k in msg_lower for k in [kr_emotion, eng_emotion]):
                    if kr_emotion not in emotions_timeline:
                        emotions_timeline.append(kr_emotion)

        # Generate summary using OpenAI
        summary_text = ""
        recommended_followup = []

        if OPENAI_AVAILABLE:
            try:
                # Build conversation context
                conv_text = "\n".join([
                    f"{'ì‚¬ìš©ì' if m['role'] == 'user' else 'ìƒë‹´ì‚¬'}: {m['content'][:300]}"
                    for m in messages[-10:]  # Last 10 messages
                ])

                summary_prompt = f"""ë‹¤ìŒ ìƒë‹´ ëŒ€í™”ë¥¼ ë¶„ì„í•˜ê³  ìš”ì•½í•´ì£¼ì„¸ìš”.

{conv_text}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
1. í•µì‹¬ ìš”ì•½ (2-3ë¬¸ì¥): ì´ ì„¸ì…˜ì—ì„œ ë‹¤ë£¬ ì£¼ìš” ë‚´ìš©
2. ê°ì • ì—¬ì •: ì‚¬ìš©ìì˜ ê°ì •ì´ ì–´ë–»ê²Œ ë³€í™”í–ˆëŠ”ì§€
3. í•µì‹¬ í†µì°°: ìƒë‹´ì—ì„œ ë°œê²¬í•œ ì¤‘ìš”í•œ ì¸ì‚¬ì´íŠ¸
4. ë‹¤ìŒ ì„¸ì…˜ ì¶”ì²œ ì§ˆë¬¸ (2ê°œ): í›„ì† ìƒë‹´ì—ì„œ ë‹¤ë£° ë§Œí•œ ì£¼ì œ

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{"summary": "...", "emotional_journey": "...", "key_insight": "...", "followup_questions": ["...", "..."]}}"""

                response = openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[{"role": "user", "content": summary_prompt}],
                    temperature=0.5,
                    max_tokens=500,
                )

                import json as json_mod
                try:
                    result = json_mod.loads(response.choices[0].message.content)
                    summary_text = result.get("summary", "")
                    emotional_journey = result.get("emotional_journey", "")
                    key_insight = result.get("key_insight", "")
                    recommended_followup = result.get("followup_questions", [])
                except:
                    summary_text = response.choices[0].message.content[:500]
                    emotional_journey = " â†’ ".join(emotions_timeline) if emotions_timeline else "íŒŒì•… ë¶ˆê°€"
                    key_insight = ""
                    recommended_followup = []

            except Exception as e:
                logger.warning(f"[SESSION-SUMMARY] OpenAI call failed: {e}")
                summary_text = f"ì£¼ìš” ì£¼ì œ: {', '.join(detected_topics[:3]) if detected_topics else 'ì¼ë°˜ ìƒë‹´'}"
                emotional_journey = " â†’ ".join(emotions_timeline) if emotions_timeline else "íŒŒì•… ë¶ˆê°€"
                key_insight = ""
        else:
            summary_text = f"ì£¼ìš” ì£¼ì œ: {', '.join(detected_topics[:3]) if detected_topics else 'ì¼ë°˜ ìƒë‹´'}"
            emotional_journey = " â†’ ".join(emotions_timeline) if emotions_timeline else "íŒŒì•… ë¶ˆê°€"
            key_insight = ""

        # Jung insights based on detected topics
        jung_insights = {}
        if "ì—°ì• /ê´€ê³„" in detected_topics:
            jung_insights["archetype"] = "ì•„ë‹ˆë§ˆ/ì•„ë‹ˆë¬´ìŠ¤"
            jung_insights["theme"] = "ê´€ê³„ íˆ¬ì‚¬ ì‘ì—…"
        elif "ìê¸°íƒìƒ‰" in detected_topics:
            jung_insights["archetype"] = "í˜ë¥´ì†Œë‚˜/ê·¸ë¦¼ì"
            jung_insights["theme"] = "ìê¸° í†µí•©"
        elif "ê°€ì¡±" in detected_topics:
            jung_insights["archetype"] = "ë¶€ëª¨ ì½¤í”Œë ‰ìŠ¤"
            jung_insights["theme"] = "ì›ê°€ì¡± ì‘ì—…"
        elif "ê±´ê°•/ìŠ¤íŠ¸ë ˆìŠ¤" in detected_topics:
            jung_insights["archetype"] = "ê·¸ë¦¼ì"
            jung_insights["theme"] = "ì–µì••ëœ ê°ì • ì‘ì—…"

        return jsonify({
            "status": "success",
            "summary": summary_text,
            "key_topics": detected_topics[:5],
            "emotional_journey": emotional_journey if isinstance(emotional_journey, str) else " â†’ ".join(emotions_timeline),
            "key_insight": key_insight if 'key_insight' in dir() else "",
            "recommended_followup": recommended_followup[:2],
            "jung_insights": jung_insights,
            "message_count": len(messages),
            "user_message_count": len(user_messages),
        })

    except Exception as e:
        logger.exception(f"[ERROR] /api/counseling/session-summary failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/api/counseling/active-imagination", methods=["POST"])
def counseling_active_imagination():
    """
    Get active imagination exercise prompts based on context.
    ì ê·¹ì  ìƒìƒ ê¸°ë²• ì•ˆë‚´ í”„ë¡¬í”„íŠ¸ ì œê³µ.
    """
    try:
        data = request.get_json(force=True)
        context = data.get("context", "")
        archetype = data.get("archetype", "")  # shadow, anima_animus, inner_child, wise_figure

        # Load jung data
        jung_data = _load_jung_data()
        ai_data = jung_data.get("active_imagination", {})

        if not ai_data:
            return jsonify({
                "status": "error",
                "message": "Active imagination data not available"
            }), 501

        # Get relevant prompts
        facilitation = ai_data.get("ai_facilitation_guide", {})
        practice_methods = ai_data.get("practice_methods", {})

        # Determine method based on context
        method = "dialogue_with_figure"  # Default
        context_lower = context.lower()

        if any(k in context_lower for k in ["ê¿ˆ", "ì•…ëª½"]):
            method = "dream_continuation"
        elif any(k in context_lower for k in ["ëª¸", "ì•„í”„", "í†µì¦", "ì¦ìƒ"]):
            method = "body_symptom_dialogue"
        elif any(k in context_lower for k in ["í™”ë‚˜", "ìŠ¬í¼", "ë‘ë ¤", "ê°ì •"]):
            method = "emotion_personification"

        method_data = practice_methods.get(method, {})

        # Get archetype-specific questions if available
        archetype_questions = []
        if archetype and method == "dialogue_with_figure":
            archetype_data = method_data.get("archetype_specific", {}).get(archetype, {})
            archetype_questions = archetype_data.get("questions", [])

        # Build response
        response = {
            "status": "success",
            "method": method_data.get("name_ko", method),
            "description": method_data.get("description", ""),
            "steps": method_data.get("steps", []),
            "suggested_questions": method_data.get("suggested_questions", archetype_questions),
            "opening_prompts": facilitation.get("opening_prompts", {}).get("general", []),
            "deepening_prompts": facilitation.get("deepening_prompts", [])[:3],
            "integration_prompts": facilitation.get("integration_prompts", [])[:2],
            "safety_notes": facilitation.get("safety_responses", {}).get("overwhelming", []),
        }

        # Add archetype approach if applicable
        if archetype:
            archetype_data = practice_methods.get("dialogue_with_figure", {}).get("archetype_specific", {}).get(archetype, {})
            if archetype_data:
                response["archetype_approach"] = archetype_data.get("approach", "")
                response["archetype_questions"] = archetype_data.get("questions", [])

        return jsonify(response)

    except Exception as e:
        logger.exception(f"[ERROR] /api/counseling/active-imagination failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/api/counseling/lifespan-guidance", methods=["GET"])
def counseling_lifespan_guidance():
    """
    Get age-appropriate psychological guidance.
    ìƒì• ì£¼ê¸°ë³„ ì‹¬ë¦¬ ë°œë‹¬ ê³¼ì œ ì•ˆë‚´.
    """
    try:
        birth_year = request.args.get("birth_year", type=int)

        if not birth_year:
            return jsonify({
                "status": "error",
                "message": "birth_year parameter required"
            }), 400

        guidance = get_lifespan_guidance(birth_year)

        if not guidance:
            return jsonify({
                "status": "error",
                "message": "Lifespan guidance data not available"
            }), 501

        return jsonify({
            "status": "success",
            **guidance
        })

    except Exception as e:
        logger.exception(f"[ERROR] /api/counseling/lifespan-guidance failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


# ============================================================
# SAJU-ONLY COUNSELOR ENDPOINTS
# ============================================================

@app.route("/saju/counselor/init", methods=["POST"])
def saju_counselor_init():
    """
    Initialize saju-only counselor session with pre-fetched RAG data.
    Similar to /counselor/init but focuses only on saju knowledge.
    """
    try:
        import json as json_mod
        raw_data = request.get_data(as_text=False)
        data = json_mod.loads(raw_data.decode('utf-8'))

        saju_data = data.get("saju") or {}
        theme = data.get("theme", "life")
        locale = data.get("locale", "ko")

        # Normalize dayMaster structure
        saju_data = normalize_day_master(saju_data)

        logger.info(f"[SAJU-COUNSELOR-INIT] id={g.request_id} theme={theme}")

        # Generate session ID
        session_id = str(uuid4())[:12]

        start_time = time.time()

        # Pre-fetch saju-specific RAG data only (no astrology)
        rag_data = {
            "graph_nodes": [],
            "corpus_quotes": [],
            "persona_context": {},
        }

        # Load saju-specific graph rules
        try:
            from backend_ai.app.graph_rag import get_graph_rag
            graph_rag = get_graph_rag()
            if graph_rag:
                # Query saju-specific rules
                day_master = saju_data.get("dayMaster", {}).get("heavenlyStem", "")
                queries = [
                    f"ì‚¬ì£¼ ì¼ê°„ {day_master} íŠ¹ì„±",
                    f"ì˜¤í–‰ ê· í˜• ë¶„ì„",
                    f"ëŒ€ìš´ ì„¸ìš´ í•´ì„",
                    f"ì‚¬ì£¼ {theme} ìš´ì„¸",
                ]
                for q in queries:
                    nodes = graph_rag.search(q, top_k=3)
                    rag_data["graph_nodes"].extend([n.get("text", "") for n in nodes if n.get("text")])
        except Exception as e:
            logger.warning(f"[SAJU-COUNSELOR-INIT] Graph RAG failed: {e}")

        prefetch_time_ms = int((time.time() - start_time) * 1000)
        rag_data["prefetch_time_ms"] = prefetch_time_ms

        # Store in session cache
        set_session_rag_cache(session_id, {
            "rag_data": rag_data,
            "saju_data": saju_data,
            "astro_data": {},  # No astrology data
            "theme": theme,
            "counselor_type": "saju",
        })

        return jsonify({
            "status": "success",
            "session_id": session_id,
            "prefetch_time_ms": prefetch_time_ms,
            "data_summary": {
                "graph_nodes": len(rag_data.get("graph_nodes", [])),
            }
        })

    except Exception as e:
        logger.exception(f"[ERROR] /saju/counselor/init failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/saju/ask-stream", methods=["POST"])
def saju_ask_stream():
    """
    Streaming chat for saju-only counselor.
    Uses Server-Sent Events (SSE) for real-time responses.
    Focuses exclusively on saju interpretation without astrology.
    """
    try:
        import json as json_mod
        raw_data = request.get_data(as_text=False)
        data = json_mod.loads(raw_data.decode('utf-8'))

        saju_data = data.get("saju") or {}
        birth_data = data.get("birth") or {}
        theme = data.get("theme", "life")
        locale = data.get("locale", "ko")
        prompt = (data.get("prompt") or "")[:1500]
        session_id = data.get("session_id")
        conversation_history = data.get("history") or []
        user_context = data.get("user_context") or {}

        # Normalize dayMaster structure
        saju_data = normalize_day_master(saju_data)

        logger.info(f"[SAJU-ASK-STREAM] id={g.request_id} theme={theme} locale={locale}")

        # Check for pre-fetched RAG data from session
        session_cache = None
        rag_context = ""
        if session_id:
            session_cache = get_session_rag_cache(session_id)
            if session_cache:
                if not saju_data:
                    saju_data = session_cache.get("saju_data", {})

                rag_data = session_cache.get("rag_data", {})
                if rag_data.get("graph_nodes"):
                    rag_context += "\n[ì‚¬ì£¼ ê´€ë ¨ ì§€ì‹]\n"
                    rag_context += "\n".join(rag_data["graph_nodes"][:8])

        # Compute saju if not provided
        if not saju_data and birth_data.get("date") and birth_data.get("time"):
            try:
                saju_data = calculate_saju_data(
                    birth_data["date"],
                    birth_data["time"],
                    birth_data.get("gender", "male")
                )
            except Exception as e:
                logger.warning(f"[SAJU-ASK-STREAM] Failed to compute saju: {e}")

        # Build detailed saju context (NO astrology)
        saju_detail = _build_detailed_saju(saju_data)

        # Current date
        from datetime import datetime
        now = datetime.now()
        weekdays_ko = ["ì›”ìš”ì¼", "í™”ìš”ì¼", "ìˆ˜ìš”ì¼", "ëª©ìš”ì¼", "ê¸ˆìš”ì¼", "í† ìš”ì¼", "ì¼ìš”ì¼"]
        current_date_str = f"ì˜¤ëŠ˜: {now.year}ë…„ {now.month}ì›” {now.day}ì¼ ({weekdays_ko[now.weekday()]})"

        # Build user context section
        user_context_section = ""
        if user_context:
            persona = user_context.get("persona", {})
            if persona.get("sessionCount", 0) > 0:
                user_context_section = f"\n[ì´ì „ ìƒë‹´]\nâ€¢ {persona.get('sessionCount', 0)}íšŒ ë°©ë¬¸ ê³ ê°\n"

        # Build saju-focused system prompt
        if locale == "ko":
            system_prompt = f"""ë„ˆëŠ” ì‚¬ì£¼(å››æŸ±) ì „ë¬¸ ìƒë‹´ì‚¬ë‹¤. ë™ì–‘ ëª…ë¦¬í•™ ì „ë¬¸ê°€ë¡œì„œ ìƒë‹´í•´.

ì ˆëŒ€ ê·œì¹™:
1. ì¸ì‚¬ ê¸ˆì§€ - ë°”ë¡œ ë¶„ì„ ì‹œì‘
2. ì‚¬ì£¼ ë¶„ì„ì—ë§Œ ì§‘ì¤‘ - ì„œì–‘ ì ì„±ìˆ  ì–¸ê¸‰ ê¸ˆì§€
3. ì œê³µëœ ëŒ€ìš´/ì„¸ìš´ ë°ì´í„°ë§Œ ì‚¬ìš©
4. í•œêµ­ ì‚¬ì£¼ ìš©ì–´ ì‚¬ìš© (ì¼ê°„, ìš©ì‹ , ëŒ€ìš´, ì„¸ìš´, ì˜¤í–‰ ë“±)

{current_date_str}

[ì‚¬ì£¼ ëª…ì‹]
{saju_detail}

{rag_context}
{user_context_section}

ì‘ë‹µ í˜•ì‹:
ã€ì¼ê°„ã€‘ ì¼ê°„ì˜ íŠ¹ì„±ê³¼ í˜„ì¬ ìƒíƒœ
ã€ëŒ€ìš´ã€‘ í˜„ì¬ ëŒ€ìš´ ë¶„ì„
ã€ì„¸ìš´ã€‘ ì˜¬í•´ ì„¸ìš´ ë¶„ì„
ã€ì˜¤í–‰ã€‘ ì˜¤í–‰ ê· í˜•ê³¼ ë³´ì™„ ë°©ë²•
ã€ì¡°ì–¸ã€‘ 2-3ê°œ ì‹¤ì²œ ì¡°ì–¸

200-300ë‹¨ì–´ë¡œ ë‹µë³€."""
        else:
            system_prompt = f"""You are a Saju (Four Pillars of Destiny) counselor specializing in Eastern fortune-telling.

RULES:
1. NO GREETING - Start directly with analysis
2. Focus ONLY on Saju - NO Western astrology
3. Use only provided daeun/seun data
4. Use proper Saju terminology

{current_date_str}

[Saju Chart]
{saju_detail}

{rag_context}
{user_context_section}

Response format:
ã€Day Masterã€‘ Characteristics and current state
ã€Major Luckã€‘ Current major luck cycle
ã€Annual Luckã€‘ This year's luck
ã€Five Elementsã€‘ Balance and recommendations
ã€Adviceã€‘ 2-3 practical actions

200-300 words."""

        # Full prompt
        full_prompt = f"{system_prompt}\n\nì‚¬ìš©ì ì§ˆë¬¸: {prompt}"

        # Streaming response
        def generate():
            try:
                response = openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": prompt}
                    ],
                    stream=True,
                    temperature=0.7,
                    max_tokens=800,
                )

                collected_text = ""
                for chunk in response:
                    if chunk.choices and chunk.choices[0].delta.content:
                        text = chunk.choices[0].delta.content
                        collected_text += text
                        yield f"data: {text}\n\n"

                # Add follow-up questions
                follow_ups = [
                    "ì˜¬í•´ ì„¸ìš´ì´ ì œ ìš´ì„¸ì— ì–´ë–¤ ì˜í–¥ì„ ì£¼ë‚˜ìš”?",
                    "ì œ ìš©ì‹ ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                    "ì˜¤í–‰ ê· í˜•ì„ ì–´ë–»ê²Œ ë§ì¶œ ìˆ˜ ìˆë‚˜ìš”?",
                ] if locale == "ko" else [
                    "How does this year's luck affect me?",
                    "What is my favorable element?",
                    "How can I balance my five elements?",
                ]
                yield f"data: ||FOLLOWUP||{json.dumps(follow_ups, ensure_ascii=False)}\n\n"
                yield "data: [DONE]\n\n"

            except Exception as e:
                logger.error(f"[SAJU-ASK-STREAM] Streaming error: {e}")
                yield f"data: ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\n\n"
                yield "data: [DONE]\n\n"

        return Response(
            stream_with_context(generate()),
            mimetype="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",
            }
        )

    except Exception as e:
        logger.exception(f"[ERROR] /saju/ask-stream failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


# ============================================================
# ASTROLOGY-ONLY COUNSELOR ENDPOINTS
# ============================================================

@app.route("/astrology/counselor/init", methods=["POST"])
def astrology_counselor_init():
    """
    Initialize astrology-only counselor session with pre-fetched RAG data.
    Similar to /counselor/init but focuses only on Western astrology.
    """
    try:
        import json as json_mod
        raw_data = request.get_data(as_text=False)
        data = json_mod.loads(raw_data.decode('utf-8'))

        astro_data = data.get("astro") or {}
        birth_data = data.get("birth") or {}
        theme = data.get("theme", "life")
        locale = data.get("locale", "ko")

        logger.info(f"[ASTROLOGY-COUNSELOR-INIT] id={g.request_id} theme={theme}")

        # Generate session ID
        session_id = str(uuid4())[:12]

        start_time = time.time()

        # Compute astrology if not provided but birth info is available
        if not astro_data and birth_data.get("date") and birth_data.get("time"):
            try:
                lat = birth_data.get("lat") or birth_data.get("latitude") or 37.5665
                lon = birth_data.get("lon") or birth_data.get("longitude") or 126.9780
                date_parts = birth_data["date"].split("-")
                time_parts = birth_data["time"].split(":")
                astro_data = calculate_astrology_data({
                    "year": int(date_parts[0]),
                    "month": int(date_parts[1]),
                    "day": int(date_parts[2]),
                    "hour": int(time_parts[0]),
                    "minute": int(time_parts[1]) if len(time_parts) > 1 else 0,
                    "latitude": lat,
                    "longitude": lon,
                })
            except Exception as e:
                logger.warning(f"[ASTROLOGY-COUNSELOR-INIT] Failed to compute astro: {e}")

        # Pre-fetch astrology-specific RAG data only (no saju)
        rag_data = {
            "graph_nodes": [],
            "corpus_quotes": [],
        }

        # Load astrology-specific graph rules
        try:
            from backend_ai.app.graph_rag import get_graph_rag
            graph_rag = get_graph_rag()
            if graph_rag:
                sun_sign = astro_data.get("sun", {}).get("sign", "")
                moon_sign = astro_data.get("moon", {}).get("sign", "")
                queries = [
                    f"íƒœì–‘ {sun_sign} íŠ¹ì„±",
                    f"ë‹¬ {moon_sign} ê°ì •",
                    f"í–‰ì„± íŠ¸ëœì§“ ì˜í–¥",
                    f"ì ì„±ìˆ  {theme} í•´ì„",
                ]
                for q in queries:
                    nodes = graph_rag.search(q, top_k=3)
                    rag_data["graph_nodes"].extend([n.get("text", "") for n in nodes if n.get("text")])
        except Exception as e:
            logger.warning(f"[ASTROLOGY-COUNSELOR-INIT] Graph RAG failed: {e}")

        prefetch_time_ms = int((time.time() - start_time) * 1000)
        rag_data["prefetch_time_ms"] = prefetch_time_ms

        # Store in session cache
        set_session_rag_cache(session_id, {
            "rag_data": rag_data,
            "saju_data": {},  # No saju data
            "astro_data": astro_data,
            "theme": theme,
            "counselor_type": "astrology",
        })

        return jsonify({
            "status": "success",
            "session_id": session_id,
            "astro": astro_data,  # Return computed astro data
            "prefetch_time_ms": prefetch_time_ms,
            "data_summary": {
                "graph_nodes": len(rag_data.get("graph_nodes", [])),
            }
        })

    except Exception as e:
        logger.exception(f"[ERROR] /astrology/counselor/init failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/astrology/ask-stream", methods=["POST"])
def astrology_ask_stream():
    """
    Streaming chat for astrology-only counselor.
    Uses Server-Sent Events (SSE) for real-time responses.
    Focuses exclusively on Western astrology without saju.
    """
    try:
        import json as json_mod
        raw_data = request.get_data(as_text=False)
        data = json_mod.loads(raw_data.decode('utf-8'))

        astro_data = data.get("astro") or {}
        birth_data = data.get("birth") or {}
        theme = data.get("theme", "life")
        locale = data.get("locale", "ko")
        prompt = (data.get("prompt") or "")[:1500]
        session_id = data.get("session_id")
        conversation_history = data.get("history") or []
        user_context = data.get("user_context") or {}

        logger.info(f"[ASTROLOGY-ASK-STREAM] id={g.request_id} theme={theme} locale={locale}")

        # Check for pre-fetched RAG data from session
        session_cache = None
        rag_context = ""
        if session_id:
            session_cache = get_session_rag_cache(session_id)
            if session_cache:
                if not astro_data:
                    astro_data = session_cache.get("astro_data", {})

                rag_data = session_cache.get("rag_data", {})
                if rag_data.get("graph_nodes"):
                    rag_context += "\n[ì ì„±ìˆ  ê´€ë ¨ ì§€ì‹]\n"
                    rag_context += "\n".join(rag_data["graph_nodes"][:8])

        # Compute astrology if not provided
        if not astro_data and birth_data.get("date") and birth_data.get("time"):
            try:
                lat = birth_data.get("lat") or birth_data.get("latitude") or 37.5665
                lon = birth_data.get("lon") or birth_data.get("longitude") or 126.9780
                date_parts = birth_data["date"].split("-")
                time_parts = birth_data["time"].split(":")
                astro_data = calculate_astrology_data({
                    "year": int(date_parts[0]),
                    "month": int(date_parts[1]),
                    "day": int(date_parts[2]),
                    "hour": int(time_parts[0]),
                    "minute": int(time_parts[1]) if len(time_parts) > 1 else 0,
                    "latitude": lat,
                    "longitude": lon,
                })
            except Exception as e:
                logger.warning(f"[ASTROLOGY-ASK-STREAM] Failed to compute astro: {e}")

        # Build detailed astrology context (NO saju)
        astro_detail = _build_detailed_astro(astro_data)

        # Current date
        from datetime import datetime
        now = datetime.now()
        weekdays_ko = ["ì›”ìš”ì¼", "í™”ìš”ì¼", "ìˆ˜ìš”ì¼", "ëª©ìš”ì¼", "ê¸ˆìš”ì¼", "í† ìš”ì¼", "ì¼ìš”ì¼"]
        current_date_str = f"ì˜¤ëŠ˜: {now.year}ë…„ {now.month}ì›” {now.day}ì¼ ({weekdays_ko[now.weekday()]})"

        # Build user context section
        user_context_section = ""
        if user_context:
            persona = user_context.get("persona", {})
            if persona.get("sessionCount", 0) > 0:
                user_context_section = f"\n[ì´ì „ ìƒë‹´]\nâ€¢ {persona.get('sessionCount', 0)}íšŒ ë°©ë¬¸ ê³ ê°\n"

        # Build astrology-focused system prompt
        if locale == "ko":
            system_prompt = f"""ë„ˆëŠ” ì„œì–‘ ì ì„±ìˆ  ì „ë¬¸ ìƒë‹´ì‚¬ë‹¤. ì¶œìƒ ì°¨íŠ¸ ë¶„ì„ê³¼ í–‰ì„± íŠ¸ëœì§“ ì „ë¬¸ê°€ì•¼.

ì ˆëŒ€ ê·œì¹™:
1. ì¸ì‚¬ ê¸ˆì§€ - ë°”ë¡œ ë¶„ì„ ì‹œì‘
2. ì„œì–‘ ì ì„±ìˆ ì—ë§Œ ì§‘ì¤‘ - ì‚¬ì£¼/ë™ì–‘ ì—­ìˆ  ì–¸ê¸‰ ê¸ˆì§€
3. ì ì„±ìˆ  ìš©ì–´ ì‚¬ìš© (ë³„ìë¦¬, í•˜ìš°ìŠ¤, ì• ìŠ¤í™íŠ¸, íŠ¸ëœì§“ ë“±)
4. êµ¬ì²´ì ì¸ í–‰ì„± ìœ„ì¹˜ì™€ ê°ë„ ì–¸ê¸‰

{current_date_str}

[ì¶œìƒ ì°¨íŠ¸]
{astro_detail}

{rag_context}
{user_context_section}

ì‘ë‹µ í˜•ì‹:
ã€íƒœì–‘/ë‹¬ã€‘ íƒœì–‘ê³¼ ë‹¬ ë³„ìë¦¬ì˜ í•µì‹¬ ì„±ê²©
ã€ìƒìŠ¹ê¶ã€‘ ì–´ì„¼ë˜íŠ¸ê°€ ì™¸ì  í˜ë¥´ì†Œë‚˜ì— ë¯¸ì¹˜ëŠ” ì˜í–¥
ã€íŠ¸ëœì§“ã€‘ í˜„ì¬ í–‰ì„± íŠ¸ëœì§“ê³¼ ê·¸ ì˜í–¥
ã€í•˜ìš°ìŠ¤ã€‘ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ í•˜ìš°ìŠ¤ ë°°ì¹˜
ã€ì¡°ì–¸ã€‘ 2-3ê°œ ì‹¤ì²œ ì¡°ì–¸

200-300ë‹¨ì–´ë¡œ ë‹µë³€."""
        else:
            system_prompt = f"""You are a Western Astrology counselor specializing in birth chart analysis.

RULES:
1. NO GREETING - Start directly with analysis
2. Focus ONLY on Western Astrology - NO Eastern fortune-telling
3. Use proper astrological terminology (signs, houses, aspects, transits)
4. Include specific planetary positions

{current_date_str}

[Birth Chart]
{astro_detail}

{rag_context}
{user_context_section}

Response format:
ã€Sun/Moonã€‘ Core personality from Sun and Moon signs
ã€Risingã€‘ Ascendant influence
ã€Transitsã€‘ Current planetary transits
ã€Housesã€‘ Relevant house placements
ã€Guidanceã€‘ 2-3 practical actions

200-300 words."""

        # Full prompt
        full_prompt = f"{system_prompt}\n\nì‚¬ìš©ì ì§ˆë¬¸: {prompt}"

        # Streaming response
        def generate():
            try:
                response = openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": prompt}
                    ],
                    stream=True,
                    temperature=0.7,
                    max_tokens=800,
                )

                collected_text = ""
                for chunk in response:
                    if chunk.choices and chunk.choices[0].delta.content:
                        text = chunk.choices[0].delta.content
                        collected_text += text
                        yield f"data: {text}\n\n"

                # Add follow-up questions
                follow_ups = [
                    "í˜„ì¬ í–‰ì„± íŠ¸ëœì§“ì´ ì œê²Œ ì–´ë–¤ ì˜í–¥ì„ ì£¼ë‚˜ìš”?",
                    "ì œ ìƒìŠ¹ê¶ì— ëŒ€í•´ ë” ì•Œë ¤ì£¼ì„¸ìš”",
                    "ì˜¬í•´ ì£¼ìš” ì ì„±ìˆ ì  ì´ë²¤íŠ¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
                ] if locale == "ko" else [
                    "How do current transits affect me?",
                    "Tell me more about my rising sign",
                    "What are the major astrological events this year?",
                ]
                yield f"data: ||FOLLOWUP||{json.dumps(follow_ups, ensure_ascii=False)}\n\n"
                yield "data: [DONE]\n\n"

            except Exception as e:
                logger.error(f"[ASTROLOGY-ASK-STREAM] Streaming error: {e}")
                yield f"data: ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\n\n"
                yield "data: [DONE]\n\n"

        return Response(
            stream_with_context(generate()),
            mimetype="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",
            }
        )

    except Exception as e:
        logger.exception(f"[ERROR] /astrology/ask-stream failed: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    logger.info(f"Flask server starting on http://127.0.0.1:{port}")
    logger.info(f"Capabilities: realtime={HAS_REALTIME}, charts={HAS_CHARTS}, memory={HAS_USER_MEMORY}, persona={HAS_PERSONA_EMBED}, tarot={HAS_TAROT}, rlhf={HAS_RLHF}, badges={HAS_BADGES}, agentic={HAS_AGENTIC}, prediction={HAS_PREDICTION}, theme_filter={HAS_THEME_FILTER}, fortune_score={HAS_FORTUNE_SCORE}, compatibility={HAS_COMPATIBILITY}, hybrid_rag={HAS_HYBRID_RAG}, domain_rag={HAS_DOMAIN_RAG}")

    # ğŸš€ Warmup models before accepting requests
    warmup_models()

    app.run(host="0.0.0.0", port=port, debug=True)
