##backend_ai/app/graph_rag.py

import os
import csv
import json
import networkx as nx
import torch
from sentence_transformers import SentenceTransformer, util


class GraphRAG:
    """
    GraphRAG: ì‚¬ì£¼ + ì ì„± + íƒ€ë¡œ + í¬ë¡œìŠ¤ ê·¸ë˜í”„ ìœµí•© ê²€ìƒ‰ ì—”ì§„
    ----------------------------------------------------------
    - graph/ : ê° ë¶„ì•¼ë³„ ë…¸ë“œÂ·ì—£ì§€ CSV (í•˜ìœ„ ì „ì²´ íƒìƒ‰)
    - rules/ : ë¶„ì•¼ë³„ í•´ì„ / ìƒí˜¸ ì—°ê²° ë£° (JSON)
    """

    def __init__(self, base_dir: str = "../"):
        # âœ… ì ˆëŒ€ê²½ë¡œ ë³´ì •
        base_dir = os.path.abspath(base_dir)
        if os.path.basename(base_dir) == "graph":
            self.graph_dir = base_dir
        else:
            self.graph_dir = os.path.join(base_dir, "graph")
        # prefer graph/rules, fallback to sibling rules
        preferred_rules = os.path.join(self.graph_dir, "rules")
        fallback_rules = os.path.join(base_dir, "rules")
        self.rules_dir = preferred_rules if os.path.isdir(preferred_rules) else fallback_rules

        # âœ… ë‚´ë¶€ êµ¬ì¡° ì´ˆê¸°í™”
        self.graph = nx.MultiDiGraph()
        self.rules = {}

        # âœ… SentenceTransformer ì´ˆê¸°í™” (CPU ê°•ì œ â€” meta tensor ì˜¤ë¥˜ ë°©ì§€)
        # PyTorch 2.6+ meta tensor compatibility fix
        os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"
        torch.set_default_device("cpu")
        self.embed_model = SentenceTransformer(
            "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
            device="cpu"
        )

        self.node_embeds = None
        self.node_texts = []

        # âœ… ì¡´ì¬ í™•ì¸
        if not os.path.exists(self.graph_dir):
            raise FileNotFoundError(f"[GraphRAG] âŒ ê·¸ë˜í”„ í´ë” ì—†ìŒ: {self.graph_dir}")
        if not os.path.exists(self.rules_dir):
            try:
                print(f"[GraphRAG] âš ï¸ rules í´ë” ì—†ìŒ: {self.rules_dir}".encode('utf-8', errors='replace').decode('utf-8'))
            except:
                print(f"[GraphRAG] Rules folder not found: {self.rules_dir}")

        # âœ… ì´ˆê¸° ë¡œë“œ
        self._load_all()
        self._prepare_embeddings()

    # =====================================================================
    # ğŸ“¦ ì „ì²´ ë¡œë“œ (ì¬ê·€ì )
    # =====================================================================
    def _load_all(self):
        """graph_dir í•˜ìœ„ ì „ì²´ ë…¸ë“œÂ·ì—£ì§€ CSV ë° rules í´ë” JSON ë¡œë“œ"""
        # 1ï¸âƒ£ ê·¸ë˜í”„ CSV ë¡œë“œ
        for root, _, files in os.walk(self.graph_dir):
            for file in files:
                path = os.path.join(root, file)
                if not file.lower().endswith(".csv"):
                    continue
                name = file.lower()
                try:
                    if "node" in name:
                        self._load_nodes(path)
                    elif any(x in name for x in ["edge", "relation", "link"]):
                        self._load_edges(path)
                except Exception as e:
                    try:
                        print(f"[GraphRAG] âš ï¸ CSV ë¡œë“œ ì‹¤íŒ¨({path}): {e}".encode('utf-8', errors='replace').decode('utf-8'))
                    except:
                        print(f"[GraphRAG] CSV load failed({path}): {e}")

        # 2ï¸âƒ£ ë£° JSON ë¡œë“œ
        if os.path.exists(self.rules_dir):
            for root, _, files in os.walk(self.rules_dir):
                for file in files:
                    if not file.lower().endswith(".json"):
                        continue
                    key = os.path.splitext(file)[0]
                    path = os.path.join(root, file)
                    try:
                        with open(path, encoding="utf-8") as f:
                            self.rules[key] = json.load(f)
                    except json.JSONDecodeError:
                        try:
                            print(f"[GraphRAG] âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜ â†’ {file}".encode('utf-8', errors='replace').decode('utf-8'))
                        except:
                            print(f"[GraphRAG] JSON parse error: {file}")
                    except Exception as e:
                        try:
                            print(f"[GraphRAG] âš ï¸ ê·œì¹™ ë¡œë“œ ì‹¤íŒ¨ â†’ {file}: {e}".encode('utf-8', errors='replace').decode('utf-8'))
                        except:
                            print(f"[GraphRAG] Rule load failed: {file}: {e}")

        try:
            print(
                f"[GraphRAG] âœ… ê·¸ë˜í”„ ë…¸ë“œ {len(self.graph.nodes)}ê°œ / ì—£ì§€ {len(self.graph.edges)}ê°œ ë¡œë“œ ì™„ë£Œ".encode('utf-8', errors='replace').decode('utf-8')
            )
        except:
            print(f"[GraphRAG] Graph nodes {len(self.graph.nodes)} / edges {len(self.graph.edges)} loaded")
        if self.rules:
            try:
                print(f"[GraphRAG] âœ… ê·œì¹™ ì„¸íŠ¸: {', '.join(sorted(self.rules.keys()))}".encode('utf-8', errors='replace').decode('utf-8'))
            except:
                print(f"[GraphRAG] Rules loaded: {', '.join(sorted(self.rules.keys()))}")
        else:
            try:
                print(f"[GraphRAG] âš ï¸ ë¡œë“œëœ ê·œì¹™ ì„¸íŠ¸ ì—†ìŒ".encode('utf-8', errors='replace').decode('utf-8'))
            except:
                print(f"[GraphRAG] No rules loaded")

    # =====================================================================
    # ğŸ§© Node / Edge ë¡œë”
    # =====================================================================
    def _load_nodes(self, path: str):
        """ë…¸ë“œ CSV ë¡œë“œ"""
        with open(path, encoding="utf-8-sig") as f:
            reader = csv.DictReader(f)
            for row in reader:
                node_id = row.get("id") or row.get("label") or row.get("name")
                if not node_id:
                    continue
                self.graph.add_node(node_id, **row)

    def _load_edges(self, path: str):
        """ì—£ì§€ CSV ë¡œë“œ"""
        with open(path, encoding="utf-8-sig") as f:
            reader = csv.DictReader(f)
            for row in reader:
                src = row.get("src") or row.get("source") or row.get("from")
                dst = row.get("dst") or row.get("target") or row.get("to")
                if not src or not dst:
                    continue
                rel = row.get("relation") or row.get("type") or "ì—°ê²°"
                desc = row.get("description") or row.get("desc") or ""
                weight = row.get("weight") or "1"
                self.graph.add_edge(src, dst, relation=rel, desc=desc, weight=weight)

    # =====================================================================
    # ğŸ§  ë…¸ë“œ ì„ë² ë”© ì¤€ë¹„
    # =====================================================================
    def _prepare_embeddings(self):
        """ë…¸ë“œ í…ìŠ¤íŠ¸ â†’ ì„ë² ë”© ìºì‹œ"""
        texts = []
        for n, d in self.graph.nodes(data=True):
            text = " ".join(
                filter(
                    None,
                    [
                        d.get("label"),
                        d.get("name"),
                        d.get("desc"),
                        d.get("element"),
                    ],
                )
            ).strip()
            texts.append(text)
        self.node_texts = texts
        if not texts:
            self.node_embeds = None
            try:
                print("[GraphRAG] âš ï¸ ì„ë² ë”© ëŒ€ìƒ ë…¸ë“œ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.".encode('utf-8', errors='replace').decode('utf-8'))
            except:
                print("[GraphRAG] No node text for embeddings")
            return

        self.node_embeds = self.embed_model.encode(
            texts,
            convert_to_tensor=True,
            normalize_embeddings=True,
        )
        try:
            print(
                f"[GraphRAG] ğŸ”¹ ì„ë² ë”© {self.node_embeds.size(0)}ê°œ ìƒì„± ë° ìºì‹œ ì™„ë£Œ".encode('utf-8', errors='replace').decode('utf-8')
            )
        except:
            print(f"[GraphRAG] Embeddings {self.node_embeds.size(0)} generated and cached")

    # =====================================================================
    # ğŸ” ì„ë² ë”© ê¸°ë°˜ ê²€ìƒ‰
    # =====================================================================
    def query(self, facts: dict, top_k: int = 8, domain_priority: str = "saju"):
        """ì…ë ¥ëœ facts ë”•ì…”ë„ˆë¦¬ë¥¼ ê·¸ë˜í”„ ë…¸ë“œ ì„ë² ë”©ê³¼ ë¹„êµ"""
        facts_str = json.dumps(facts, ensure_ascii=False)

        # âœ… í…ì„œì˜ bool í‰ê°€ ì—ëŸ¬ ë°©ì§€
        if self.node_embeds is None or self.node_embeds.size(0) == 0:
            return {
                "matched_nodes": [],
                "related_edges": [],
                "rule_summary": None,
                "context_text": "",
                "stats": {},
            }

        # ğŸ‘‰ ì§ˆì˜ ì„ë² ë”©
        query_emb = self.embed_model.encode(
            facts_str,
            convert_to_tensor=True,
            normalize_embeddings=True,
        )
        cos_scores = util.cos_sim(query_emb, self.node_embeds)[0]
        top_results = torch.topk(cos_scores, k=min(top_k, self.node_embeds.size(0)))

        matched_nodes = [self.node_texts[i] for i in top_results.indices]
        matched_score = [float(cos_scores[i]) for i in top_results.indices]

        # ê´€ë ¨ ì—£ì§€
        edges = [
            {
                "src": u,
                "dst": v,
                "rel": d.get("relation"),
                "desc": d.get("desc", ""),
            }
            for u, v, d in self.graph.edges(data=True)
            if any(n in (u, v) for n in matched_nodes)
        ]

        # ë£° ìš”ì•½
        rule_summary = (
            self._apply_rules(domain_priority, facts_str)
            if domain_priority in self.rules
            else None
        )

        # ì½˜í…ìŠ¤íŠ¸ í…ìŠ¤íŠ¸
        context_lines = [
            f"{matched_nodes[i]} (score: {matched_score[i]:.3f})"
            for i in range(len(matched_nodes))
        ]
        edge_lines = [f"{e['src']}â†’{e['dst']}({e['rel']})" for e in edges[:30]]
        context_text = "\n".join(context_lines + edge_lines)

        return {
            "matched_nodes": matched_nodes,
            "related_edges": edges,
            "rule_summary": rule_summary,
            "context_text": context_text,
            "stats": {"nodes": len(matched_nodes), "edges": len(edges)},
        }

    # =====================================================================
    # ğŸ§  ë£° ì ìš© (ê°„ë‹¨ ì¡°ê±´ ê¸°ë°˜)
    # =====================================================================
    def _apply_rules(self, domain: str, facts_str: str):
        """rules/*.json ì¡°ê±´ë¬¸ ì ìš©"""
        rulebook = self.rules.get(domain)
        if not rulebook:
            return None
        descs = []
        for key, rule in rulebook.items():
            if isinstance(rule, dict):
                cond = rule.get("when")
                msg = rule.get("text")
                if cond and cond in facts_str and msg:
                    descs.append(msg)
            elif isinstance(rule, str):
                if key in facts_str:
                    descs.append(rule)
        return descs[:5] if descs else None
