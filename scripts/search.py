import os
import sys
import torch
from sentence_transformers import util
from backend_ai.data.graph.utils import _load_graph_nodes, embed_text


def main():
    # ğŸ”¹ ìºì‹œëœ ì„ë² ë”© íŒŒì¼ ê²½ë¡œ
    graph_root = os.path.join(os.getcwd(), "backend_ai", "data", "graph")

    print("[GraphSearch] ğŸ’¾ Loading cached embeddings...")
    corpus_embeds = torch.load(os.path.join(graph_root, "corpus_embeds.pt"))
    nodes = _load_graph_nodes(graph_root)
    print(f"[GraphSearch] âœ… Loaded {len(nodes)} nodes with cached embeddings.")

    # ğŸ”¹ CLI ì¸ì ë˜ëŠ” ì…ë ¥ì°½ì—ì„œ ê²€ìƒ‰ì–´ ë°›ê¸°
    if len(sys.argv) > 1:
        query = " ".join(sys.argv[1:])
    else:
        query = input("\nSearch Query: ")

    print(f"[GraphSearch] ğŸ” Searching for: {query}")

    # ğŸ”¹ ì„ë² ë”© ë° ìœ ì‚¬ë„ ê³„ì‚°
    q_emb = embed_text(query)
    scores = util.cos_sim(q_emb, corpus_embeds)[0]
    best = torch.topk(scores, k=5)

    print("\nğŸ” Top 5 Results:")
    for i, v in zip(best.indices, best.values):
        node = nodes[int(i)]
        print(f"{v:.4f} | {node['label']} â†’ {node['description'][:80]}...")


if __name__ == "__main__":
    main()