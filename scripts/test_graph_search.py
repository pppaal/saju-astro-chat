# -------------------------------------------------------------
# test_graph_search.py
# GraphRAG Corpus í…ŒìŠ¤íŠ¸ìš© ê²€ìƒ‰ ì—”ì§„ (Full-field ë²„ì „, ì™„ë²½ë³¸)
# -------------------------------------------------------------
import torch
from sentence_transformers import SentenceTransformer, util
import csv, json, os, time

# ===============================================================
# ì„¤ì •
# ===============================================================
MODEL_NAME = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
BASE_DIR = os.path.join(os.getcwd(), "backend_ai", "data", "graph")
EMBED_FILE = os.path.join(BASE_DIR, "corpus_embeds.pt")

# ===============================================================
# ë°ì´í„° ë¡œë”: ëª¨ë“  CSV/JSONì˜ ëª¨ë“  í•„ë“œ ë¬¸ìì—´ ë³‘í•©
# ===============================================================
def load_all_texts(base_dir: str) -> list[str]:
    texts = []
    print(f"ğŸ“‚ ê·¸ë˜í”„ ë°ì´í„° ìŠ¤ìº” ì¤‘ â†’ {base_dir}")

    for root, _, files in os.walk(base_dir):
        for f in files:
            path = os.path.join(root, f)
            if f.endswith(".csv"):
                try:
                    with open(path, encoding="utf-8-sig") as fr:
                        reader = csv.DictReader(fr)
                        headers = reader.fieldnames or []
                        for row in reader:
                            vals = []
                            for h in headers:
                                val = row.get(h)
                                if isinstance(val, (str, int, float)):
                                    val = str(val).strip()
                                    if val:
                                        vals.append(val)
                            if vals:
                                texts.append(" | ".join(vals))
                except Exception as e:
                    print(f"âš ï¸ CSV ë¡œë“œ ì‹¤íŒ¨: {path} | {e}")
            elif f.endswith(".json"):
                try:
                    with open(path, encoding="utf-8-sig") as fr:
                        data = json.load(fr)
                    if isinstance(data, dict):
                        data = list(data.values())
                    if isinstance(data, list):
                        for n in data:
                            if isinstance(n, dict):
                                vals = []
                                for k, v in n.items():
                                    if isinstance(v, (str, int, float)):
                                        val = str(v).strip()
                                        if val:
                                            vals.append(val)
                                if vals:
                                    texts.append(" | ".join(vals))
                except Exception as e:
                    print(f"âš ï¸ JSON ë¡œë“œ ì‹¤íŒ¨: {path} | {e}")

    print(f"âœ… ì´ {len(texts)}ê°œì˜ í…ìŠ¤íŠ¸ í•­ëª© ë¡œë“œ ì™„ë£Œ\n")
    return texts

# ===============================================================
# ë©”ì¸ í•¨ìˆ˜
# ===============================================================
def main():
    print("ğŸ§  GraphRAG ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹œì‘")

    # 1ï¸âƒ£ ì„ë² ë”© íŒŒì¼ ë¡œë“œ
    start = time.time()
    if not os.path.exists(EMBED_FILE):
        print(f"âŒ ì„ë² ë”© íŒŒì¼ ì—†ìŒ: {EMBED_FILE}")
        return
    print("ğŸ’¾ ì„ë² ë”© ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
    embeds = torch.load(EMBED_FILE)
    print(f"âœ… ì„ë² ë”© ë¡œë“œ ì™„ë£Œ: {embeds.shape} ({time.time()-start:.1f}s)\n")

    # 2ï¸âƒ£ ëª¨ë¸ ë¡œë“œ
    print("ğŸ§  SentenceTransformer ëª¨ë¸ ë¡œë“œ ì¤‘...")
    model = SentenceTransformer(MODEL_NAME)
    print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {MODEL_NAME}\n")

    # 3ï¸âƒ£ í…ìŠ¤íŠ¸ ë¡œë“œ
    texts = load_all_texts(BASE_DIR)
    if not texts:
        print("âŒ í…ìŠ¤íŠ¸ ë°ì´í„° ì—†ìŒ â€” CSV/JSON í™•ì¸ í•„ìš”.")
        return

    # 4ï¸âƒ£ ì§ˆì˜ ì…ë ¥ ë£¨í”„
    while True:
        print("â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•")
        query = input("ğŸ¤” ê²€ìƒ‰í•  ì§ˆë¬¸ (ë˜ëŠ” exit ì…ë ¥â†’ì¢…ë£Œ): ").strip()
        if query.lower() in ["exit", "quit", "ì¢…ë£Œ"]:
            print("ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        if not query:
            continue

        # ğŸ” í‚¤ì›Œë“œ í•„í„°ë§ (ì„±ëŠ¥ í–¥ìƒìš©)
        keyword = None
        for kw in ["Sun", "Moon", "íƒœì–‘", "ë‹¬", "Jupiter", "Saturn", "ëª©ì„±", "í† ì„±"]:
            if kw.lower() in query.lower():
                keyword = kw
                break

        if keyword:
            filtered_indices = [i for i, t in enumerate(texts) if keyword.lower() in t.lower()]
            if filtered_indices:
                filtered_texts = [texts[i] for i in filtered_indices]
                filtered_embeds = embeds[filtered_indices]
                print(f"âš™ï¸ '{keyword}' ê´€ë ¨ {len(filtered_texts)}ê°œ ë°ì´í„°ë¡œ ì¶•ì†Œ ê²€ìƒ‰.\n")
            else:
                filtered_texts, filtered_embeds = texts, embeds
        else:
            filtered_texts, filtered_embeds = texts, embeds

        # 5ï¸âƒ£ ì¿¼ë¦¬ ì„ë² ë”© â†’ ìœ ì‚¬ë„ ê³„ì‚°
        query_emb = model.encode(query, convert_to_tensor=True, normalize_embeddings=True)
        cos_scores = util.cos_sim(query_emb, filtered_embeds)[0]
        top_results = torch.topk(cos_scores, k=min(5, len(filtered_texts)))

        print(f"ğŸ” ì§ˆë¬¸: {query}\n")
        for rank, (score, idx) in enumerate(zip(top_results.values, top_results.indices), start=1):
            print(f"{rank}. ğŸ’« ìœ ì‚¬ë„ {score:.4f}")
            print(filtered_texts[idx].replace("|", "\n"))
            print("--------------------------------------------------")
        print()

# ===============================================================
# ì‹¤í–‰ ì§„ì…ì 
# ===============================================================
if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ìˆ˜ë™ ì¢…ë£Œë¨.")